{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4859c937-c5ae-41c7-a301-d7000fe42021",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Retrieval-Augmented Generation (RAG)\n",
    "This is a notebook used for the 'Methods for Fintech and Artificial Intelligence in Finance'. The notebook experiment in different ways of adding valuable information to the answer generated by an LLM (retrieval-augmented generation, few shot learning). This notebook does not consider fine-tuning LLM as this typically comes with significant cost."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20b6dba5-73ca-46fb-b898-da362cf490d6",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Setting up the environment\n",
    "\n",
    "https://community.anaconda.cloud/t/how-do-i-use-an-existing-environment-on-a-new-computer/55641\n",
    "\n",
    "Load environment with conda\n",
    "* cd ~/affine\n",
    "\n",
    "* conda env create -f environment.yml\n",
    "\n",
    "(If fist time, install a kernel)\n",
    "\n",
    "* python -m ipykernel install --user --name=**kernel-name**\n",
    "\n",
    "\n",
    "Remove kernel from system\n",
    "* jupyter kernelspec list\n",
    "* jupyter kernelspec uninstall **kernel-name**\n",
    "\n",
    "Example code:\n",
    "\n",
    "conda env create -n affine-project-env -f environment.yml\n",
    "\n",
    "conda activate affine-project-env\n",
    "\n",
    "python -m ipykernel install --user --name=affine-project-kernel\n",
    "\n",
    "\n",
    "## Additional notes:\n",
    "Create venv able with kernel:\n",
    "* conda env export > environment.yml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c37947ad-62c5-4f55-bc11-c71e6606cc62",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pip 24.2 from /opt/miniconda3/envs/affine-project-env/lib/python3.12/site-packages/pip (python 3.12)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b4ef104-2191-4fd7-a7bf-2cb2e0bf0781",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#note: first we will use %pip install to test --> when package should be included in the environment use conda install\n",
    "#dotenv\n",
    "%pip install python-dotenv\n",
    "\n",
    "# langchain set-up packages\n",
    "%pip install --upgrade --quiet langchain\n",
    "%pip install -qU \"langchain-chroma>=0.1.2\"\n",
    "%pip install --upgrade --quiet  langchain-google-genai\n",
    "%pip install --upgrade --quiet langchain-openai\n",
    "%pip install --upgrade --quiet langchain-unstructured\n",
    "# %pip install \"unstructured[all-docs]\"\n",
    "#CHANGED BUT NOT TESTED YET\n",
    "%pip install --upgrade --quiet unstructured-client\n",
    "%pip install unstructured"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "93090cfe-1760-4513-9615-2a1091457578",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "langchain==0.3.2\n",
      "langchain-chroma==0.1.4\n",
      "langchain-core==0.3.9\n",
      "langchain-google-genai==2.0.0\n",
      "langchain-openai==0.2.2\n",
      "langchain-text-splitters==0.3.0\n",
      "langchain-unstructured==0.1.5\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip freeze | grep langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "08edb763-f7b6-41d1-baba-4debb88a37fd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from dotenv import dotenv_values\n",
    "ENV = dotenv_values(\".env\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e567291a-48fb-41c3-836a-b827ab1d1f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tutorial may be useful package to think about although langchain 0.2\n",
    "# import os\n",
    "# from langchain.vectorstores import Chroma\n",
    "# from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "# from langchain.schema.runnable import RunnablePassthrough\n",
    "# from langchain_core.output_parsers import StrOutputParser\n",
    "# from langchain.prompts import (\n",
    "#     ChatPromptTemplate,\n",
    "#     FewShotChatMessagePromptTemplate,\n",
    "# )\n",
    "# # from operator import itemgetter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a184539-e08f-41cc-860d-55d58c1906c0",
   "metadata": {
    "tags": [],
    "user_expressions": []
   },
   "source": [
    "# Prepare data\n",
    "The data contains apples: \n",
    "* 10-Q for Q2-2024 and Q3-2024*\n",
    "* Apples Q3 earnings call\n",
    "* 100 articles from last month related to Apple\n",
    "\n",
    "The 10-Q .pdf files have been converted to json files using high resolution models as the pdf contain tables, more information:\n",
    "* https://docs.unstructured.io/api-reference/how-to/choose-hi-res-model\n",
    "* Also see: preprocessing_10-Q.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c184e768-fb53-4a02-84fc-7d305c847bca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from langchain_unstructured import UnstructuredLoader\n",
    "# loader = UnstructuredLoader('book-Copy1.txt')\n",
    "# raw_doc = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "64110de8-30bf-421d-96c0-48839c72f457",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "# segmenting the document into segments\n",
    "\n",
    "def load_texts(document_path):\n",
    "  # Load an example document\n",
    "  with open(document_path) as f:\n",
    "      book = f.read()\n",
    "\n",
    "  text_splitter = CharacterTextSplitter(\n",
    "      separator=\"\\n\\n\",\n",
    "      chunk_size=1000,\n",
    "      chunk_overlap=200,\n",
    "      length_function=len,\n",
    "      is_separator_regex=False,\n",
    "  )\n",
    "  texts = text_splitter.create_documents([book])\n",
    "  return texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "c21f0f4f-8864-4f17-9d83-0621fb6a44ef",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'utf-8' codec can't decode byte 0xf6 in position 10: invalid start byte",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[89], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m texts \u001b[38;5;241m=\u001b[39m \u001b[43mload_texts\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m./rawdata/apple_10-Q-Q2-2024-As-Filed.pdf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[9], line 7\u001b[0m, in \u001b[0;36mload_texts\u001b[0;34m(document_path)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_texts\u001b[39m(document_path):\n\u001b[1;32m      5\u001b[0m   \u001b[38;5;66;03m# Load an example document\u001b[39;00m\n\u001b[1;32m      6\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(document_path) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m----> 7\u001b[0m       book \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m   text_splitter \u001b[38;5;241m=\u001b[39m CharacterTextSplitter(\n\u001b[1;32m     10\u001b[0m       separator\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     11\u001b[0m       chunk_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     14\u001b[0m       is_separator_regex\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     15\u001b[0m   )\n\u001b[1;32m     16\u001b[0m   texts \u001b[38;5;241m=\u001b[39m text_splitter\u001b[38;5;241m.\u001b[39mcreate_documents([book])\n",
      "File \u001b[0;32m/opt/miniconda3/envs/affine-project-env/lib/python3.12/codecs.py:322\u001b[0m, in \u001b[0;36mBufferedIncrementalDecoder.decode\u001b[0;34m(self, input, final)\u001b[0m\n\u001b[1;32m    319\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecode\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m, final\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m    320\u001b[0m     \u001b[38;5;66;03m# decode input (taking the buffer into account)\u001b[39;00m\n\u001b[1;32m    321\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuffer \u001b[38;5;241m+\u001b[39m \u001b[38;5;28minput\u001b[39m\n\u001b[0;32m--> 322\u001b[0m     (result, consumed) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_buffer_decode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfinal\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    323\u001b[0m     \u001b[38;5;66;03m# keep undecoded input until the next call\u001b[39;00m\n\u001b[1;32m    324\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuffer \u001b[38;5;241m=\u001b[39m data[consumed:]\n",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode byte 0xf6 in position 10: invalid start byte"
     ]
    }
   ],
   "source": [
    "texts = load_texts('./rawdata/apple_10-Q-Q2-2024-As-Filed.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9a1f65c8-ed30-42aa-a3e9-e06047fc8205",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain_openai import AzureOpenAIEmbeddings\n",
    "\n",
    "def text_embedding_3_small_azure():\n",
    "  AZURE_OPENAI_ENDPOINT = ENV.get('AZURE_OPENAI_ENDPOINT')\n",
    "  AZURE_OPENAI_API_KEY = ENV.get('AZURE_OPENAI_API_KEY')\n",
    "  AZURE_OPENAI_API_VERSION = ENV.get('AZURE_OPENAI_API_VERSION')\n",
    "\n",
    "  embedding_model = AzureOpenAIEmbeddings(\n",
    "      model=\"text-embedding-3-small\",\n",
    "      # dimensions: Optional[int] = None, # Can specify dimensions with new text-embedding-3 models\n",
    "      azure_endpoint=AZURE_OPENAI_ENDPOINT, #If not provided, will read env variable AZURE_OPENAI_ENDPOINT\n",
    "      api_key=AZURE_OPENAI_API_KEY, # Can provide an API key directly. If missing read env variable AZURE_OPENAI_API_KEY\n",
    "      openai_api_version=AZURE_OPENAI_API_VERSION, # If not provided, will read env variable AZURE_OPENAI_API_VERSION\n",
    "  )\n",
    "  return embedding_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4fc5a676-2c22-40b0-b2c4-234a056e5523",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# DOCS:\n",
    "# please be aware that chroma uses the embedding model in creating the vector store as well as the query\n",
    "from langchain_chroma import Chroma\n",
    "# Document Embedding with Chromadb\n",
    "\n",
    "def create_vector_store(texts, embedding_model, persist_directory):\n",
    "  vector_store = Chroma.from_documents(texts, embedding_model, persist_directory=persist_directory)\n",
    "  return vector_store\n",
    "\n",
    "def load_vector_store(embedding_model, persist_directory):\n",
    "  vector_store = Chroma(embedding_function=embedding_model, persist_directory=persist_directory)\n",
    "  return vector_store\n",
    "\n",
    "#Chroma class https://python.langchain.com/api_reference/chroma/vectorstores/langchain_chroma.vectorstores.Chroma.html\n",
    "def retrieve_relevant_chunks(chroma_vector_store, query):\n",
    "  # Connection to query with Chroma indexing using a retriever\n",
    "  retriever = chroma_vector_store.as_retriever(\n",
    "      search_type=\"similarity\",\n",
    "      search_kwargs={'k':4}\n",
    "  )\n",
    "  \n",
    "  chunks = retriever.invoke(query)\n",
    "  return chunks\n",
    "\n",
    "def print_chunks(chunks):\n",
    "  for d in docs:\n",
    "    print('--------------------------------NEW DOCS ----------------------------------------')\n",
    "    print(d.page_content)\n",
    "\n",
    "# Function to add all docs returned by retriever\n",
    "\n",
    "# def format_docs(docs):\n",
    "#   return \"\\n\\n\".join(doc.page_content for doc in docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0825d242-f3fd-41a7-bd2e-e34d92a0507b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# creating a new vector database\n",
    "def create_vector_store_test_pipeline(document_path, persist_directory):\n",
    "  texts = load_texts(document_path)\n",
    "  embedding_model = text_embedding_3_small_azure()\n",
    "  vector_store = Chroma.from_documents(texts, embedding_model, persist_directory=persist_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c34e0aaa-c3d8-49bc-b7a8-08141c9ce25b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vector_store = create_vector_store_test_pipeline(\"pipeline-test.txt\", \"./chroma_langchain_db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "bd397155-8700-4252-8591-fc591b306a57",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "vector_store = load_vector_store(text_embedding_3_small_azure(), \"./chroma_langchain_db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "110d4899-df45-4de6-b300-a6d3d6ebcca5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: HTTP Request: POST https://graphraq-affine-us.openai.azure.com//openai/deployments/text-embedding-3-small/embeddings?api-version=2023-05-15 \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Document(metadata={}, page_content=\"'Many can't go there; and many would rather die.'\\n\\n'If they would rather die,' said Scrooge, 'they had better do it, and\\ndecrease the surplus population. Besides--excuse me--I don't know that.'\\n\\n'But you might know it,' observed the gentleman.\\n\\n'It's not my business,' Scrooge returned. 'It's enough for a man to\\nunderstand his own business, and not to interfere with other people's.\\nMine occupies me constantly. Good afternoon, gentlemen!'\\n\\nSeeing clearly that it would be useless to pursue their point, the\\ngentlemen withdrew. Scrooge resumed his labours with an improved opinion\\nof himself, and in a more facetious temper than was usual with him.\"),\n",
       " Document(metadata={}, page_content=\"'You'll want all day to-morrow, I suppose?' said Scrooge.\\n\\n'If quite convenient, sir.'\\n\\n'It's not convenient,' said Scrooge, 'and it's not fair. If I was to\\nstop half-a-crown for it, you'd think yourself ill used, I'll be bound?'\\n\\nThe clerk smiled faintly.\\n\\n'And yet,' said Scrooge, 'you don't think _me_ ill used when I pay a\\nday's wages for no work.'\\n\\n[Illustration: _Bob Cratchit went down a slide on Cornhill, at the end\\nof a lane of boys, twenty times, in honour of its being Christmas\\nEve_]\\n\\nThe clerk observed that it was only once a year.\\n\\n'A poor excuse for picking a man's pocket every twenty-fifth of\\nDecember!' said Scrooge, buttoning his greatcoat to the chin. 'But I\\nsuppose you must have the whole day. Be here all the earlier next\\nmorning.'\"),\n",
       " Document(metadata={}, page_content=\"Meanwhile the fog and darkness thickened so, that people ran about with\\nflaring links, proffering their services to go before horses in\\ncarriages, and conduct them on their way. The ancient tower of a church,\\nwhose gruff old bell was always peeping slyly down at Scrooge out of a\\nGothic window in the wall, became invisible, and struck the hours and\\nquarters in the clouds, with tremulous vibrations afterwards, as if its\\nteeth were chattering in its frozen head up there. The cold became\\nintense. In the main street, at the corner of the court, some labourers\\nwere repairing the gas-pipes, and had lighted a great fire in a brazier,\\nround which a party of ragged men and boys were gathered: warming their\\nhands and winking their eyes before the blaze in rapture. The water-plug\\nbeing left in solitude, its overflowings suddenly congealed, and turned\\nto misanthropic ice. The brightness of the shops, where holly sprigs and\\nberries crackled in the lamp heat of the windows, made pale faces ruddy\\nas they passed. Poulterers' and grocers' trades became a splendid joke:\\na glorious pageant, with which it was next to impossible to believe that\\nsuch dull principles as bargain and sale had anything to do. The Lord\\nMayor, in the stronghold of the mighty Mansion House, gave orders to his\\nfifty cooks and butlers to keep Christmas as a Lord Mayor's household\\nshould; and even the little tailor, whom he had fined five shillings on\\nthe previous Monday for being drunk and bloodthirsty in the streets,\\nstirred up to-morrow's pudding in his garret, while his lean wife and\\nthe baby sallied out to buy the beef.\"),\n",
       " Document(metadata={}, page_content=\"Foggier yet, and colder! Piercing, searching, biting cold. If the good\\nSt. Dunstan had but nipped the Evil Spirit's nose with a touch of such\\nweather as that, instead of using his familiar weapons, then indeed he\\nwould have roared to lusty purpose. The owner of one scant young nose,\\ngnawed and mumbled by the hungry cold as bones are gnawed by dogs,\\nstooped down at Scrooge's keyhole to regale him with a Christmas carol;\\nbut, at the first sound of\\n\\n  'God bless you, merry gentleman,\\n  May nothing you dismay!'\\n\\nScrooge seized the ruler with such energy of action that the singer fled\\nin terror, leaving the keyhole to the fog, and even more congenial\\nfrost.\\n\\nAt length the hour of shutting up the counting-house arrived. With an\\nill-will Scrooge dismounted from his stool, and tacitly admitted the\\nfact to the expectant clerk in the tank, who instantly snuffed his\\ncandle out, and put on his hat.\\n\\n'You'll want all day to-morrow, I suppose?' said Scrooge.\\n\\n'If quite convenient, sir.'\")]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieve_relevant_chunks(vector_store, 'Why are apples red?')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1651a35a-bf3f-4f8f-830d-498294a69518",
   "metadata": {
    "tags": [],
    "user_expressions": []
   },
   "source": [
    "# See difference in answer with context and no context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "51a468e0-4d4b-4e71-92b5-468ebc52a3bc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: HTTP Request: POST https://graphraq-affine-us.openai.azure.com//openai/deployments/text-embedding-3-small/embeddings?api-version=2023-05-15 \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "from langchain_google_genai import GoogleGenerativeAI\n",
    "GEMINI_API_KEY = ENV.get('GEMINI_API_KEY')\n",
    "# initializing the LLM\n",
    "\n",
    "query = \"Who are the main characters of the book A Christmas Carol\"\n",
    "\n",
    "llm = GoogleGenerativeAI(model=\"models/gemini-1.5-flash\", api_key=GEMINI_API_KEY)\n",
    "response_without_context = llm.invoke(query)\n",
    "\n",
    "chunks = retrieve_relevant_chunks(vectorstore, query)\n",
    "first_chunk = chunks[0]\n",
    "rag_query = \"\\n\\n\".join([first_chunk.page_content, \"\\n\\n\", query])\n",
    "response_with_context = llm.invoke(rag_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "9048020b-5e0e-4b27-8275-40d6e65d75a1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The main characters of Charles Dickens' *A Christmas Carol* are:\\n\\n* **Ebenezer Scrooge:** The central character, a miserly and bitter old man who despises Christmas and everything it represents. He undergoes a profound transformation throughout the story.\\n* **The Ghosts:**\\n    * **The Ghost of Christmas Past:** Shows Scrooge his own past and the events that shaped him into the man he is.\\n    * **The Ghost of Christmas Present:** Shows Scrooge the present-day lives of those around him, including his clerk, Bob Cratchit, and his nephew, Fred.\\n    * **The Ghost of Christmas Yet to Come:** Shows Scrooge a bleak vision of his future if he does not change his ways.\\n* **Bob Cratchit:** Scrooge's loyal and kind-hearted clerk who struggles to provide for his family, including his beloved son, Tiny Tim.\\n* **Fred:** Scrooge's nephew, a cheerful and optimistic man who invites Scrooge to Christmas dinner despite his uncle's aversion to the holiday.\\n* **The Cratchit Family:** Bob's wife, Mrs. Cratchit, and their children, including Tiny Tim, who represent the warmth and love that Scrooge lacks in his life.\\n\\nThese are the main characters, but there are also several other significant figures in the story, such as the Ghost of Christmas Present's two children, Ignorance and Want, and the two gentlemen who visit Scrooge's office. \\n\""
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response_without_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "47f8c7f2-a007-4945-b36f-ebb00f931ae5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Credits: Produced by Suzanne Shell, Janet Blenkinship and the Online\\n        Distributed Proofreading Team at http://www.pgdp.net\\n\\n\\n*** START OF THE PROJECT GUTENBERG EBOOK A CHRISTMAS CAROL ***\\n\\n\\nProduced by Suzanne Shell, Janet Blenkinship and the Online\\nDistributed Proofreading Team at http://www.pgdp.net\\n\\n  A CHRISTMAS CAROL\\n\\n  [Illustration: _\"How now?\" said Scrooge, caustic and cold as ever.\\n  \"What do you want with me?\"_]\\n\\n\\n  A CHRISTMAS CAROL\\n\\n  [Illustration]\\n\\n  BY\\n\\n  CHARLES DICKENS\\n\\n  [Illustration]\\n\\n  ILLUSTRATED BY ARTHUR RACKHAM\\n\\n  [Illustration]\\n\\n  J. B. LIPPINCOTT COMPANY PHILADELPHIA AND NEW YORK\\n\\n  FIRST PUBLISHED 1915\\n\\n  REPRINTED 1923, 1927, 1932, 1933, 1934, 1935, 1947, 1948, 1952, 1958,\\n  1962, 1964, 1966, 1967, 1969, 1971, 1972, 1973\\n\\n  ISBN: 0-397-00033-2\\n\\n  PRINTED IN GREAT BRITAIN\\n\\n\\n  PREFACE'"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_chunk.page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "b657c1e7-4f1c-4285-a108-bee186e8a6fe",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The main characters of \"A Christmas Carol\" are:\\n\\n* **Ebenezer Scrooge:** The miserly protagonist who transforms through the story.\\n* **The Ghost of Christmas Past:** A spirit who shows Scrooge his past life and the choices that led him to his current state.\\n* **The Ghost of Christmas Present:** A spirit who shows Scrooge the present-day happiness and joy of others, contrasting with his own isolation.\\n* **The Ghost of Christmas Yet to Come:** A silent, ominous spirit who shows Scrooge a glimpse of his bleak future if he doesn\\'t change his ways.\\n* **Bob Cratchit:** Scrooge\\'s kind and hardworking clerk, who struggles to provide for his family.\\n* **Tiny Tim:** Bob Cratchit\\'s young, disabled son, who embodies innocence and optimism.\\n* **Fred:** Scrooge\\'s nephew, who represents generosity and goodwill. \\n'"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response_with_context"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "affine-project-kernel",
   "language": "python",
   "name": "affine-project-kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
