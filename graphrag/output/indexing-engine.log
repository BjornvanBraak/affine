00:37:35,760 graphrag.index.cli INFO Logging enabled at /home/jovyan/affine/graphrag/output/indexing-engine.log
00:37:35,765 graphrag.index.cli INFO Starting pipeline run for: 20241007-003735, dryrun=False
00:37:35,766 graphrag.index.cli INFO Using default configuration: {
    "llm": {
        "api_key": "==== REDACTED ====",
        "type": "azure_openai_chat",
        "model": "gpt-4o-mini",
        "max_tokens": 4000,
        "temperature": 0.0,
        "top_p": 1.0,
        "n": 1,
        "request_timeout": 180.0,
        "api_base": "https://affine-project-us-east.openai.azure.com",
        "api_version": "2023-03-15-preview",
        "proxy": null,
        "cognitive_services_endpoint": null,
        "deployment_name": "gpt-4o-mini",
        "model_supports_json": true,
        "tokens_per_minute": 20000,
        "requests_per_minute": 100,
        "max_retries": 10,
        "max_retry_wait": 10.0,
        "sleep_on_rate_limit_recommendation": true,
        "concurrent_requests": 25
    },
    "parallelization": {
        "stagger": 0.3,
        "num_threads": 50
    },
    "async_mode": "threaded",
    "root_dir": "/home/jovyan/affine/graphrag",
    "reporting": {
        "type": "file",
        "base_dir": "/home/jovyan/affine/graphrag/output",
        "storage_account_blob_url": null
    },
    "storage": {
        "type": "file",
        "base_dir": "/home/jovyan/affine/graphrag/output",
        "storage_account_blob_url": null
    },
    "cache": {
        "type": "file",
        "base_dir": "cache",
        "storage_account_blob_url": null
    },
    "input": {
        "type": "file",
        "file_type": "text",
        "base_dir": "input",
        "storage_account_blob_url": null,
        "encoding": "utf-8",
        "file_pattern": ".*\\.txt$",
        "file_filter": null,
        "source_column": null,
        "timestamp_column": null,
        "timestamp_format": null,
        "text_column": "text",
        "title_column": null,
        "document_attribute_columns": []
    },
    "embed_graph": {
        "enabled": false,
        "num_walks": 10,
        "walk_length": 40,
        "window_size": 2,
        "iterations": 3,
        "random_seed": 597832,
        "strategy": null
    },
    "embeddings": {
        "llm": {
            "api_key": "==== REDACTED ====",
            "type": "azure_openai_embedding",
            "model": "text-embedding-3-small",
            "max_tokens": 4000,
            "temperature": 0,
            "top_p": 1,
            "n": 1,
            "request_timeout": 180.0,
            "api_base": "https://affine-project-us-east.openai.azure.com",
            "api_version": "2023-05-15",
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": "text-embedding-3-small",
            "model_supports_json": null,
            "tokens_per_minute": 10000,
            "requests_per_minute": 50,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "batch_size": 16,
        "batch_max_tokens": 8191,
        "target": "required",
        "skip": [],
        "vector_store": null,
        "strategy": null
    },
    "chunks": {
        "size": 1200,
        "overlap": 50,
        "group_by_columns": [
            "id"
        ],
        "strategy": null,
        "encoding_model": null
    },
    "snapshots": {
        "graphml": false,
        "raw_entities": false,
        "top_level_nodes": false
    },
    "entity_extraction": {
        "llm": {
            "api_key": "==== REDACTED ====",
            "type": "azure_openai_chat",
            "model": "gpt-4o-mini",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "n": 1,
            "request_timeout": 180.0,
            "api_base": "https://affine-project-us-east.openai.azure.com",
            "api_version": "2023-03-15-preview",
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": "gpt-4o-mini",
            "model_supports_json": true,
            "tokens_per_minute": 20000,
            "requests_per_minute": 100,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "prompt": "prompts/entity_extraction.txt",
        "entity_types": [
            "organization",
            "person",
            "geo",
            "event"
        ],
        "max_gleanings": 1,
        "strategy": null,
        "encoding_model": null
    },
    "summarize_descriptions": {
        "llm": {
            "api_key": "==== REDACTED ====",
            "type": "azure_openai_chat",
            "model": "gpt-4o-mini",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "n": 1,
            "request_timeout": 180.0,
            "api_base": "https://affine-project-us-east.openai.azure.com",
            "api_version": "2023-03-15-preview",
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": "gpt-4o-mini",
            "model_supports_json": true,
            "tokens_per_minute": 20000,
            "requests_per_minute": 100,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "prompt": "prompts/summarize_descriptions.txt",
        "max_length": 500,
        "strategy": null
    },
    "community_reports": {
        "llm": {
            "api_key": "==== REDACTED ====",
            "type": "azure_openai_chat",
            "model": "gpt-4o-mini",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "n": 1,
            "request_timeout": 180.0,
            "api_base": "https://affine-project-us-east.openai.azure.com",
            "api_version": "2023-03-15-preview",
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": "gpt-4o-mini",
            "model_supports_json": true,
            "tokens_per_minute": 20000,
            "requests_per_minute": 100,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "prompt": "prompts/community_report.txt",
        "max_length": 2000,
        "max_input_length": 8000,
        "strategy": null
    },
    "claim_extraction": {
        "llm": {
            "api_key": "==== REDACTED ====",
            "type": "azure_openai_chat",
            "model": "gpt-4o-mini",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "n": 1,
            "request_timeout": 180.0,
            "api_base": "https://affine-project-us-east.openai.azure.com",
            "api_version": "2023-03-15-preview",
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": "gpt-4o-mini",
            "model_supports_json": true,
            "tokens_per_minute": 20000,
            "requests_per_minute": 100,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "enabled": false,
        "prompt": "prompts/claim_extraction.txt",
        "description": "Any claims or facts that could be relevant to information discovery.",
        "max_gleanings": 1,
        "strategy": null,
        "encoding_model": null
    },
    "cluster_graph": {
        "max_cluster_size": 10,
        "strategy": null
    },
    "umap": {
        "enabled": false
    },
    "local_search": {
        "text_unit_prop": 0.5,
        "community_prop": 0.1,
        "conversation_history_max_turns": 5,
        "top_k_entities": 10,
        "top_k_relationships": 10,
        "temperature": 0.0,
        "top_p": 1.0,
        "n": 1,
        "max_tokens": 12000,
        "llm_max_tokens": 2000
    },
    "global_search": {
        "temperature": 0.0,
        "top_p": 1.0,
        "n": 1,
        "max_tokens": 12000,
        "data_max_tokens": 12000,
        "map_max_tokens": 1000,
        "reduce_max_tokens": 2000,
        "concurrency": 32
    },
    "encoding_model": "cl100k_base",
    "skip_workflows": []
}
00:37:35,770 graphrag.index.create_pipeline_config INFO skipping workflows 
00:37:35,771 graphrag.index.run.run INFO Running pipeline
00:37:35,771 graphrag.index.storage.file_pipeline_storage INFO Creating file storage at /home/jovyan/affine/graphrag/output
00:37:35,777 graphrag.index.input.load_input INFO loading input from root_dir=input
00:37:35,777 graphrag.index.input.load_input INFO using file storage for input
00:37:35,779 graphrag.index.storage.file_pipeline_storage INFO search /home/jovyan/affine/graphrag/input for files matching .*\.txt$
00:37:35,780 graphrag.index.input.text INFO found text files from input, found [('apple-recent-news-Copy1.json.txt', {}), ('apple_10-Q-Q3-2024-As-Filed-Copy1.pdf.json.txt', {}), ('apple-Q3-2024-earnings-call.txt', {}), ('apple_10-Q-Q2-2024-As-Filed-Copy1.pdf.json.txt', {})]
00:37:35,791 graphrag.index.input.text INFO Found 4 files, loading 4
00:37:35,793 graphrag.index.workflows.load INFO Workflow Run Order: ['create_base_text_units', 'create_base_extracted_entities', 'create_summarized_entities', 'create_base_entity_graph', 'create_final_entities', 'create_final_nodes', 'create_final_communities', 'create_final_relationships', 'create_final_text_units', 'create_final_community_reports', 'create_base_documents', 'create_final_documents']
00:37:35,793 graphrag.index.run.run INFO Final # of rows loaded: 4
00:37:35,930 graphrag.index.run.workflow INFO dependencies for create_base_text_units: []
00:37:35,934 datashaper.workflow.workflow INFO executing verb orderby
00:37:35,937 datashaper.workflow.workflow INFO executing verb zip
00:37:35,941 datashaper.workflow.workflow INFO executing verb aggregate_override
00:37:35,946 datashaper.workflow.workflow INFO executing verb chunk
00:37:36,170 datashaper.workflow.workflow INFO executing verb select
00:37:36,174 datashaper.workflow.workflow INFO executing verb unroll
00:37:36,179 datashaper.workflow.workflow INFO executing verb rename
00:37:36,183 datashaper.workflow.workflow INFO executing verb genid
00:37:36,190 datashaper.workflow.workflow INFO executing verb unzip
00:37:36,195 datashaper.workflow.workflow INFO executing verb copy
00:37:36,199 datashaper.workflow.workflow INFO executing verb filter
00:37:36,212 graphrag.index.emit.parquet_table_emitter INFO emitting parquet table create_base_text_units.parquet
00:37:36,373 graphrag.index.run.workflow INFO dependencies for create_base_extracted_entities: ['create_base_text_units']
00:37:36,374 graphrag.utils.storage INFO read table from storage: create_base_text_units.parquet
00:37:36,403 datashaper.workflow.workflow INFO executing verb entity_extract
00:37:36,414 graphrag.llm.openai.create_openai_client INFO Creating Azure OpenAI client api_base=https://affine-project-us-east.openai.azure.com, deployment_name=gpt-4o-mini
00:37:36,422 graphrag.index.llm.load_llm INFO create TPM/RPM limiter for gpt-4o-mini: TPM=20000, RPM=100
00:37:36,422 graphrag.index.llm.load_llm INFO create concurrency limiter for gpt-4o-mini: 25
00:37:38,227 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
00:37:38,236 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 1.705947956070304. input_tokens=2936, output_tokens=107
00:37:39,983 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
00:37:39,988 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 3.4645593978930265. input_tokens=2144, output_tokens=507
00:37:40,895 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
00:37:40,898 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 4.377064519096166. input_tokens=2937, output_tokens=727
00:37:41,191 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
00:37:41,194 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 4.666805720888078. input_tokens=2934, output_tokens=381
00:37:43,93 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
00:37:43,99 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
00:37:43,337 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
00:37:43,341 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 6.827383860014379. input_tokens=2936, output_tokens=739
00:37:49,158 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 6.59718334604986. input_tokens=2933, output_tokens=1009
00:37:49,741 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 6.578792107058689. input_tokens=2936, output_tokens=1107
00:37:58,581 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
00:37:58,583 graphrag.llm.base.rate_limiting_llm WARNING Process failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 39 seconds. Follow recommendation? True
00:38:07,322 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
00:38:07,323 graphrag.llm.base.rate_limiting_llm WARNING Process failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 30 seconds. Follow recommendation? True
00:38:16,138 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
00:38:16,139 graphrag.llm.base.rate_limiting_llm WARNING Process failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 21 seconds. Follow recommendation? True
00:38:25,29 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
00:38:25,31 graphrag.llm.base.rate_limiting_llm WARNING Process failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 13 seconds. Follow recommendation? True
00:38:33,777 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
00:38:33,779 graphrag.llm.base.rate_limiting_llm WARNING Process failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 4 seconds. Follow recommendation? True
00:38:44,298 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
00:38:44,301 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 2.0766565341036767. input_tokens=2936, output_tokens=217
00:38:55,93 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
00:38:55,96 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 1.982266885926947. input_tokens=2936, output_tokens=228
00:39:06,385 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
00:39:06,388 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 4.045063263969496. input_tokens=2934, output_tokens=452
00:39:12,826 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
00:39:12,829 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 1.6352134870830923. input_tokens=2936, output_tokens=222
00:39:21,638 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
00:39:21,639 graphrag.llm.base.rate_limiting_llm WARNING Process failed to invoke LLM 2/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 21 seconds. Follow recommendation? True
00:39:30,364 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
00:39:30,366 graphrag.llm.base.rate_limiting_llm WARNING Process failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 13 seconds. Follow recommendation? True
00:39:39,188 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
00:39:39,190 graphrag.llm.base.rate_limiting_llm WARNING Process failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 4 seconds. Follow recommendation? True
00:39:52,113 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
00:39:52,116 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 4.475364888785407. input_tokens=2936, output_tokens=582
00:40:02,921 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
00:40:02,925 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 5.465889597078785. input_tokens=2935, output_tokens=838
00:40:14,590 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
00:40:14,593 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 4.847508992999792. input_tokens=2937, output_tokens=501
00:40:20,840 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
00:40:20,843 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 2 retries took 2.2716126940213144. input_tokens=2822, output_tokens=367
00:40:28,881 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
00:40:28,883 graphrag.llm.base.rate_limiting_llm WARNING Process failed to invoke LLM 2/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 20 seconds. Follow recommendation? True
00:40:37,692 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
00:40:37,693 graphrag.llm.base.rate_limiting_llm WARNING Process failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 11 seconds. Follow recommendation? True
00:40:46,592 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
00:40:46,594 graphrag.llm.base.rate_limiting_llm WARNING Process failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 2 seconds. Follow recommendation? True
00:40:56,925 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
00:40:56,928 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 1 retries took 2.063905928051099. input_tokens=2937, output_tokens=266
00:41:06,891 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
00:41:06,894 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 2.300879067974165. input_tokens=2936, output_tokens=236
00:41:18,214 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
00:41:18,218 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 3.6691834800876677. input_tokens=2936, output_tokens=490
00:41:28,893 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
00:41:28,897 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 4.3812574099283665. input_tokens=2936, output_tokens=705
00:41:35,699 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
00:41:35,701 graphrag.llm.base.rate_limiting_llm WARNING Process failed to invoke LLM 3/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 20 seconds. Follow recommendation? True
00:41:44,592 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
00:41:44,594 graphrag.llm.base.rate_limiting_llm WARNING Process failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 11 seconds. Follow recommendation? True
00:41:53,337 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
00:41:53,338 graphrag.llm.base.rate_limiting_llm WARNING Process failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 2 seconds. Follow recommendation? True
00:42:04,886 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
00:42:04,890 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 3.103685390902683. input_tokens=2936, output_tokens=414
00:42:17,281 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
00:42:17,285 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 4.328389031114057. input_tokens=2936, output_tokens=648
00:42:26,480 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
00:42:26,484 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 3.9739796922076494. input_tokens=2936, output_tokens=553
00:42:35,560 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
00:42:35,563 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 2.5727028360124677. input_tokens=2936, output_tokens=312
00:42:43,255 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
00:42:43,256 graphrag.llm.base.rate_limiting_llm WARNING Process failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 19 seconds. Follow recommendation? True
00:42:52,69 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
00:42:52,71 graphrag.llm.base.rate_limiting_llm WARNING Process failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 11 seconds. Follow recommendation? True
00:43:00,884 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
00:43:00,885 graphrag.llm.base.rate_limiting_llm WARNING Process failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 2 seconds. Follow recommendation? True
00:43:13,894 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
00:43:13,898 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 4.558407376985997. input_tokens=2936, output_tokens=633
00:43:21,755 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
00:43:21,757 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 1 retries took 1.7192496489733458. input_tokens=2936, output_tokens=196
00:43:32,742 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
00:43:32,745 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 1 retries took 3.280856017023325. input_tokens=2936, output_tokens=442
00:43:32,841 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
00:43:32,843 graphrag.llm.base.rate_limiting_llm WARNING extract-continuation-0 failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 1 seconds. Follow recommendation? True
00:43:39,399 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
00:43:39,402 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 1 retries took 3.952189739793539. input_tokens=34, output_tokens=675
00:43:39,499 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
00:43:39,500 graphrag.llm.base.rate_limiting_llm WARNING extract-continuation-0 failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 31 seconds. Follow recommendation? True
00:43:42,181 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
00:43:42,182 graphrag.llm.base.rate_limiting_llm WARNING Process failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 28 seconds. Follow recommendation? True
00:43:51,353 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
00:43:51,355 graphrag.llm.base.rate_limiting_llm WARNING Process failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 19 seconds. Follow recommendation? True
00:44:00,171 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
00:44:00,172 graphrag.llm.base.rate_limiting_llm WARNING Process failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 10 seconds. Follow recommendation? True
00:44:08,995 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
00:44:08,997 graphrag.llm.base.rate_limiting_llm WARNING Process failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 1 seconds. Follow recommendation? True
00:44:13,166 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
00:44:13,169 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 1 retries took 1.6045933761633933. input_tokens=34, output_tokens=176
00:44:13,350 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
00:44:13,351 graphrag.llm.base.rate_limiting_llm WARNING extract-continuation-0 failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 8 seconds. Follow recommendation? True
00:44:17,962 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
00:44:17,964 graphrag.llm.base.rate_limiting_llm WARNING Process failed to invoke LLM 2/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 3 seconds. Follow recommendation? True
00:44:26,195 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
00:44:26,198 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 1 retries took 3.6776590179651976. input_tokens=34, output_tokens=526
00:44:26,380 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
00:44:26,381 graphrag.llm.base.rate_limiting_llm WARNING extract-continuation-0 failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 4 seconds. Follow recommendation? True
00:44:28,876 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
00:44:28,878 graphrag.llm.base.rate_limiting_llm WARNING Process failed to invoke LLM 2/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 1 seconds. Follow recommendation? True
00:44:34,254 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
00:44:34,257 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 1 retries took 1.9669126991648227. input_tokens=34, output_tokens=238
00:44:34,439 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
00:44:34,440 graphrag.llm.base.rate_limiting_llm WARNING extract-continuation-0 failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 2 seconds. Follow recommendation? True
00:44:38,672 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
00:44:38,674 graphrag.llm.base.rate_limiting_llm WARNING Process failed to invoke LLM 2/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 33 seconds. Follow recommendation? True
00:44:40,802 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
00:44:40,806 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 1 retries took 3.3281995709985495. input_tokens=34, output_tokens=539
00:44:40,986 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
00:44:40,988 graphrag.llm.base.rate_limiting_llm WARNING extract-continuation-0 failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 42 seconds. Follow recommendation? True
00:44:49,593 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
00:44:49,595 graphrag.llm.base.rate_limiting_llm WARNING Process failed to invoke LLM 2/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 23 seconds. Follow recommendation? True
00:44:58,411 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
00:44:58,412 graphrag.llm.base.rate_limiting_llm WARNING Process failed to invoke LLM 2/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 14 seconds. Follow recommendation? True
00:45:07,243 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
00:45:07,245 graphrag.llm.base.rate_limiting_llm WARNING Process failed to invoke LLM 2/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 5 seconds. Follow recommendation? True
00:45:18,786 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
00:45:18,789 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 1 retries took 3.1058790909592062. input_tokens=2936, output_tokens=413
00:45:18,970 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
00:45:18,971 graphrag.llm.base.rate_limiting_llm WARNING extract-continuation-0 failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 4 seconds. Follow recommendation? True
00:45:25,314 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
00:45:25,316 graphrag.llm.base.rate_limiting_llm WARNING extract-continuation-0 failed to invoke LLM 2/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 13 seconds. Follow recommendation? True
00:45:25,570 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
00:45:25,572 graphrag.llm.base.rate_limiting_llm WARNING Process failed to invoke LLM 3/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 7 seconds. Follow recommendation? True
00:45:27,558 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
00:45:27,561 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 1 retries took 3.058242161059752. input_tokens=34, output_tokens=430
00:45:27,657 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
00:45:27,659 graphrag.llm.base.rate_limiting_llm WARNING extract-continuation-0 failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 5 seconds. Follow recommendation? True
00:45:36,743 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
00:45:36,745 graphrag.llm.base.rate_limiting_llm WARNING Process failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 1 seconds. Follow recommendation? True
00:45:38,734 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
00:45:38,737 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 1 retries took 4.162868365179747. input_tokens=34, output_tokens=578
00:45:40,964 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
00:45:40,966 graphrag.llm.base.rate_limiting_llm WARNING extract-continuation-0 failed to invoke LLM 3/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 36 seconds. Follow recommendation? True
00:45:41,635 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
00:45:41,638 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 2.8990970319136977. input_tokens=34, output_tokens=414
00:45:41,819 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
00:45:41,820 graphrag.llm.base.rate_limiting_llm WARNING extract-continuation-0 failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 35 seconds. Follow recommendation? True
00:45:48,650 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
00:45:48,651 graphrag.llm.base.rate_limiting_llm WARNING Process failed to invoke LLM 2/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 28 seconds. Follow recommendation? True
00:45:57,466 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
00:45:57,467 graphrag.llm.base.rate_limiting_llm WARNING Process failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 19 seconds. Follow recommendation? True
00:46:06,204 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
00:46:06,206 graphrag.llm.base.rate_limiting_llm WARNING Process failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 10 seconds. Follow recommendation? True
00:46:15,25 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
00:46:15,26 graphrag.llm.base.rate_limiting_llm WARNING Process failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 2 seconds. Follow recommendation? True
00:46:21,670 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
00:46:21,671 graphrag.llm.base.rate_limiting_llm WARNING extract-continuation-0 failed to invoke LLM 4/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 4 seconds. Follow recommendation? True
00:46:23,604 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
00:46:23,606 graphrag.llm.base.rate_limiting_llm WARNING Process failed to invoke LLM 2/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 2 seconds. Follow recommendation? True
00:46:24,175 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
00:46:24,274 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
00:46:24,275 graphrag.llm.base.rate_limiting_llm WARNING extract-continuation-0 failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 1 seconds. Follow recommendation? True
00:46:27,90 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 1 retries took 5.874434897210449. input_tokens=34, output_tokens=970
00:46:30,317 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
00:46:30,320 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 1 retries took 3.2047867469955236. input_tokens=34, output_tokens=429
00:46:30,416 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
00:46:30,418 graphrag.llm.base.rate_limiting_llm WARNING extract-continuation-0 failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 5 seconds. Follow recommendation? True
00:46:34,804 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
00:46:34,806 graphrag.llm.base.rate_limiting_llm WARNING extract-continuation-0 failed to invoke LLM 5/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 1 seconds. Follow recommendation? True
00:46:37,349 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
00:46:37,351 graphrag.llm.base.rate_limiting_llm WARNING extract-continuation-0 failed to invoke LLM 2/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 2 seconds. Follow recommendation? True
00:46:38,400 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
00:46:38,402 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 2 retries took 1.6058841778431088. input_tokens=2936, output_tokens=224
00:46:38,580 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
00:46:38,582 graphrag.llm.base.rate_limiting_llm WARNING extract-continuation-0 failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 1 seconds. Follow recommendation? True
00:46:41,697 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
00:46:41,699 graphrag.llm.base.rate_limiting_llm WARNING extract-continuation-0 failed to invoke LLM 3/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 37 seconds. Follow recommendation? True
00:46:43,929 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
00:46:43,932 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 1 retries took 2.5140930868219584. input_tokens=34, output_tokens=370
00:46:44,110 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
00:46:44,112 graphrag.llm.base.rate_limiting_llm WARNING extract-continuation-0 failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 35 seconds. Follow recommendation? True
00:46:45,989 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
00:46:45,991 graphrag.llm.base.rate_limiting_llm WARNING extract-continuation-0 failed to invoke LLM 6/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 33 seconds. Follow recommendation? True
00:46:48,54 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
00:46:48,55 graphrag.llm.base.rate_limiting_llm WARNING Process failed to invoke LLM 2/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 31 seconds. Follow recommendation? True
00:46:57,151 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
00:46:57,153 graphrag.llm.base.rate_limiting_llm WARNING Process failed to invoke LLM 2/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 22 seconds. Follow recommendation? True
00:47:05,960 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
00:47:05,961 graphrag.llm.base.rate_limiting_llm WARNING Process failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 13 seconds. Follow recommendation? True
00:47:14,793 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
00:47:14,793 graphrag.llm.base.rate_limiting_llm WARNING Process failed to invoke LLM 4/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 4 seconds. Follow recommendation? True
00:47:23,845 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
00:47:23,847 graphrag.llm.base.rate_limiting_llm WARNING Process failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 4 seconds. Follow recommendation? True
00:47:23,924 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
00:47:23,926 graphrag.llm.base.rate_limiting_llm WARNING extract-continuation-0 failed to invoke LLM 4/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 4 seconds. Follow recommendation? True
00:47:24,895 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
00:47:24,898 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 1 retries took 4.049067829037085. input_tokens=34, output_tokens=399
00:47:25,75 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
00:47:25,77 graphrag.llm.base.rate_limiting_llm WARNING extract-continuation-0 failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 3 seconds. Follow recommendation? True
00:47:29,743 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
00:47:29,745 graphrag.llm.base.rate_limiting_llm WARNING extract-continuation-0 failed to invoke LLM 2/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 12 seconds. Follow recommendation? True
00:47:31,715 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
00:47:31,718 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 6 retries took 2.7235531168989837. input_tokens=34, output_tokens=398
00:47:31,813 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
00:47:31,814 graphrag.llm.base.rate_limiting_llm WARNING extract-continuation-0 failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 6 seconds. Follow recommendation? True
00:47:35,323 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
00:47:35,324 graphrag.llm.base.rate_limiting_llm WARNING Process failed to invoke LLM 3/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 2 seconds. Follow recommendation? True
00:47:36,582 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
00:47:36,583 graphrag.llm.base.rate_limiting_llm WARNING extract-continuation-0 failed to invoke LLM 5/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 6 seconds. Follow recommendation? True
00:47:44,347 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
00:47:44,349 graphrag.llm.base.rate_limiting_llm WARNING extract-continuation-0 failed to invoke LLM 3/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 38 seconds. Follow recommendation? True
00:47:46,994 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
00:47:46,998 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 3.09780216217041. input_tokens=2934, output_tokens=417
00:47:47,95 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
00:47:47,97 graphrag.llm.base.rate_limiting_llm WARNING extract-continuation-0 failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 35 seconds. Follow recommendation? True
00:47:47,496 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
00:47:47,680 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
00:47:47,681 graphrag.llm.base.rate_limiting_llm WARNING extract-continuation-0 failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 34 seconds. Follow recommendation? True
00:47:51,228 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 1 retries took 7.905609175097197. input_tokens=34, output_tokens=1242
00:47:52,684 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
00:47:52,686 graphrag.llm.base.rate_limiting_llm WARNING extract-continuation-0 failed to invoke LLM 6/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 29 seconds. Follow recommendation? True
00:47:58,605 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
00:47:58,607 graphrag.llm.base.rate_limiting_llm WARNING Process failed to invoke LLM 4/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 23 seconds. Follow recommendation? True
00:48:07,351 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
00:48:07,353 graphrag.llm.base.rate_limiting_llm WARNING Process failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 15 seconds. Follow recommendation? True
00:48:16,170 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
00:48:16,171 graphrag.llm.base.rate_limiting_llm WARNING Process failed to invoke LLM 2/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 6 seconds. Follow recommendation? True
00:48:23,765 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
00:48:23,767 graphrag.llm.base.rate_limiting_llm WARNING extract-continuation-0 failed to invoke LLM 2/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 6 seconds. Follow recommendation? True
00:48:25,259 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
00:48:25,260 graphrag.llm.base.rate_limiting_llm WARNING Process failed to invoke LLM 3/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 4 seconds. Follow recommendation? True
00:48:26,178 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
00:48:26,181 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 1 retries took 3.046572651946917. input_tokens=34, output_tokens=429
00:48:26,359 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
00:48:26,361 graphrag.llm.base.rate_limiting_llm WARNING extract-continuation-0 failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 3 seconds. Follow recommendation? True
00:48:26,697 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
00:48:26,698 graphrag.llm.base.rate_limiting_llm WARNING extract-continuation-0 failed to invoke LLM 4/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 3 seconds. Follow recommendation? True
00:48:32,144 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
00:48:32,145 graphrag.llm.base.rate_limiting_llm WARNING extract-continuation-0 failed to invoke LLM 7/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 8 seconds. Follow recommendation? True
00:48:32,332 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
00:48:32,333 graphrag.llm.base.rate_limiting_llm WARNING extract-continuation-0 failed to invoke LLM 3/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 8 seconds. Follow recommendation? True
00:48:32,512 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
00:48:32,515 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 1 retries took 1.767293777083978. input_tokens=34, output_tokens=260
00:48:32,612 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
00:48:32,614 graphrag.llm.base.rate_limiting_llm WARNING extract-continuation-0 failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 8 seconds. Follow recommendation? True
00:48:37,335 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
00:48:37,336 graphrag.llm.base.rate_limiting_llm WARNING Process failed to invoke LLM 3/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 3 seconds. Follow recommendation? True
00:48:38,247 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
00:48:38,248 graphrag.llm.base.rate_limiting_llm WARNING extract-continuation-0 failed to invoke LLM 5/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 2 seconds. Follow recommendation? True
00:48:44,83 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
00:48:44,86 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 1 retries took 2.1830394780263305. input_tokens=34, output_tokens=240
00:48:44,266 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
00:48:44,267 graphrag.llm.base.rate_limiting_llm WARNING extract-continuation-0 failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 1 seconds. Follow recommendation? True
00:48:46,658 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
00:48:46,660 graphrag.llm.base.rate_limiting_llm WARNING Process failed to invoke LLM 3/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 37 seconds. Follow recommendation? True
00:48:47,443 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
00:48:47,445 graphrag.llm.base.rate_limiting_llm WARNING extract-continuation-0 failed to invoke LLM 2/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 37 seconds. Follow recommendation? True
00:48:49,711 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
00:48:49,717 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 3 retries took 4.86415117001161. input_tokens=34, output_tokens=871
00:48:49,895 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
00:48:49,897 graphrag.llm.base.rate_limiting_llm WARNING extract-continuation-0 failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 34 seconds. Follow recommendation? True
00:48:50,246 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
00:48:50,247 graphrag.llm.base.rate_limiting_llm WARNING extract-continuation-0 failed to invoke LLM 8/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 34 seconds. Follow recommendation? True
00:48:50,346 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
00:48:50,348 graphrag.llm.base.rate_limiting_llm WARNING extract-continuation-0 failed to invoke LLM 6/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 34 seconds. Follow recommendation? True
00:48:58,426 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
00:48:58,427 graphrag.llm.base.rate_limiting_llm WARNING Process failed to invoke LLM 3/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 26 seconds. Follow recommendation? True
00:49:07,232 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
00:49:07,233 graphrag.llm.base.rate_limiting_llm WARNING Process failed to invoke LLM 2/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 17 seconds. Follow recommendation? True
00:49:16,125 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
00:49:16,127 graphrag.llm.base.rate_limiting_llm WARNING Process failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 8 seconds. Follow recommendation? True
00:49:25,371 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
00:49:25,372 graphrag.llm.base.rate_limiting_llm WARNING extract-continuation-0 failed to invoke LLM 2/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 6 seconds. Follow recommendation? True
00:49:26,669 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
00:49:26,670 graphrag.llm.base.rate_limiting_llm WARNING extract-continuation-0 failed to invoke LLM 3/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 5 seconds. Follow recommendation? True
00:49:28,423 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
00:49:28,427 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 3.930550022982061. input_tokens=2936, output_tokens=591
00:49:28,524 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
00:49:28,525 graphrag.llm.base.rate_limiting_llm WARNING extract-continuation-0 failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 3 seconds. Follow recommendation? True
00:49:34,154 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
00:49:34,155 graphrag.llm.base.rate_limiting_llm WARNING extract-continuation-0 failed to invoke LLM 3/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 8 seconds. Follow recommendation? True
00:49:34,348 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
00:49:34,350 graphrag.llm.base.rate_limiting_llm WARNING extract-continuation-0 failed to invoke LLM 9/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 8 seconds. Follow recommendation? True
00:49:34,446 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
00:49:34,448 graphrag.llm.base.rate_limiting_llm WARNING extract-continuation-0 failed to invoke LLM 7/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 8 seconds. Follow recommendation? True
00:49:36,163 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
00:49:36,164 graphrag.llm.base.rate_limiting_llm WARNING extract-continuation-0 failed to invoke LLM 4/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 6 seconds. Follow recommendation? True
00:49:36,428 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
00:49:36,429 graphrag.llm.base.rate_limiting_llm WARNING Process failed to invoke LLM 2/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 6 seconds. Follow recommendation? True
00:49:38,105 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
00:49:38,109 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 1 retries took 4.836185363121331. input_tokens=34, output_tokens=759
00:49:38,288 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
00:49:38,290 graphrag.llm.base.rate_limiting_llm WARNING extract-continuation-0 failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 4 seconds. Follow recommendation? True
00:49:47,506 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
00:49:47,509 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 1 retries took 3.5280341680627316. input_tokens=34, output_tokens=489
00:49:47,687 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
00:49:47,688 graphrag.llm.base.rate_limiting_llm WARNING extract-continuation-0 failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 38 seconds. Follow recommendation? True
00:49:49,83 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
00:49:49,84 graphrag.llm.base.rate_limiting_llm WARNING Process failed to invoke LLM 2/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 36 seconds. Follow recommendation? True
00:49:49,907 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
00:49:49,910 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 3 retries took 2.9010327260475606. input_tokens=34, output_tokens=383
00:49:50,6 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
00:49:50,7 graphrag.llm.base.rate_limiting_llm WARNING extract-continuation-0 failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 35 seconds. Follow recommendation? True
00:49:50,564 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
00:49:50,566 graphrag.llm.base.rate_limiting_llm WARNING extract-continuation-0 failed to invoke LLM 5/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 35 seconds. Follow recommendation? True
00:49:52,452 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
00:49:52,464 graphrag.llm.base.rate_limiting_llm WARNING extract-continuation-0 failed to invoke LLM 10/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 33 seconds. Follow recommendation? True
00:49:52,632 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
00:49:52,634 graphrag.llm.base.rate_limiting_llm WARNING extract-continuation-0 failed to invoke LLM 8/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 33 seconds. Follow recommendation? True
00:49:59,518 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
00:49:59,519 graphrag.llm.base.rate_limiting_llm WARNING Process failed to invoke LLM 3/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 26 seconds. Follow recommendation? True
00:50:08,327 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
00:50:08,329 graphrag.llm.base.rate_limiting_llm WARNING Process failed to invoke LLM 3/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 17 seconds. Follow recommendation? True
00:50:17,67 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
00:50:17,68 graphrag.llm.base.rate_limiting_llm WARNING Process failed to invoke LLM 3/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 8 seconds. Follow recommendation? True
00:50:25,470 root ERROR error extracting graph
Traceback (most recent call last):
  File "/opt/miniconda3/envs/affine-project-env/lib/python3.12/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py", line 122, in __call__
    result = await self._process_document(text, prompt_variables)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/miniconda3/envs/affine-project-env/lib/python3.12/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py", line 161, in _process_document
    response = await self._llm(
               ^^^^^^^^^^^^^^^^
  File "/opt/miniconda3/envs/affine-project-env/lib/python3.12/site-packages/graphrag/llm/openai/json_parsing_llm.py", line 34, in __call__
    result = await self._delegate(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/miniconda3/envs/affine-project-env/lib/python3.12/site-packages/graphrag/llm/openai/openai_token_replacing_llm.py", line 37, in __call__
    return await self._delegate(input, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/miniconda3/envs/affine-project-env/lib/python3.12/site-packages/graphrag/llm/openai/openai_history_tracking_llm.py", line 33, in __call__
    output = await self._delegate(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/miniconda3/envs/affine-project-env/lib/python3.12/site-packages/graphrag/llm/base/caching_llm.py", line 96, in __call__
    result = await self._delegate(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/miniconda3/envs/affine-project-env/lib/python3.12/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 177, in __call__
    result, start = await execute_with_retry()
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/miniconda3/envs/affine-project-env/lib/python3.12/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 159, in execute_with_retry
    async for attempt in retryer:
  File "/opt/miniconda3/envs/affine-project-env/lib/python3.12/site-packages/tenacity/asyncio/__init__.py", line 166, in __anext__
    do = await self.iter(retry_state=self._retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/miniconda3/envs/affine-project-env/lib/python3.12/site-packages/tenacity/asyncio/__init__.py", line 153, in iter
    result = await action(retry_state)
             ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/miniconda3/envs/affine-project-env/lib/python3.12/site-packages/tenacity/_utils.py", line 99, in inner
    return call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/opt/miniconda3/envs/affine-project-env/lib/python3.12/site-packages/tenacity/__init__.py", line 418, in exc_check
    raise retry_exc.reraise()
          ^^^^^^^^^^^^^^^^^^^
  File "/opt/miniconda3/envs/affine-project-env/lib/python3.12/site-packages/tenacity/__init__.py", line 185, in reraise
    raise self.last_attempt.result()
          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/miniconda3/envs/affine-project-env/lib/python3.12/concurrent/futures/_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "/opt/miniconda3/envs/affine-project-env/lib/python3.12/concurrent/futures/_base.py", line 401, in __get_result
    raise self._exception
  File "/opt/miniconda3/envs/affine-project-env/lib/python3.12/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 165, in execute_with_retry
    return await do_attempt(), start
           ^^^^^^^^^^^^^^^^^^
  File "/opt/miniconda3/envs/affine-project-env/lib/python3.12/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 151, in do_attempt
    await sleep_for(sleep_time)
  File "/opt/miniconda3/envs/affine-project-env/lib/python3.12/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 147, in do_attempt
    return await self._delegate(input, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/miniconda3/envs/affine-project-env/lib/python3.12/site-packages/graphrag/llm/base/base_llm.py", line 50, in __call__
    return await self._invoke(input, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/miniconda3/envs/affine-project-env/lib/python3.12/site-packages/graphrag/llm/base/base_llm.py", line 54, in _invoke
    output = await self._execute_llm(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/miniconda3/envs/affine-project-env/lib/python3.12/site-packages/graphrag/llm/openai/openai_chat_llm.py", line 53, in _execute_llm
    completion = await self.client.chat.completions.create(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/miniconda3/envs/affine-project-env/lib/python3.12/site-packages/openai/resources/chat/completions.py", line 1490, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/opt/miniconda3/envs/affine-project-env/lib/python3.12/site-packages/openai/_base_client.py", line 1831, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/miniconda3/envs/affine-project-env/lib/python3.12/site-packages/openai/_base_client.py", line 1525, in request
    return await self._request(
           ^^^^^^^^^^^^^^^^^^^^
  File "/opt/miniconda3/envs/affine-project-env/lib/python3.12/site-packages/openai/_base_client.py", line 1626, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the Chatcompletions_Create Operation under Azure OpenAI API version 2023-03-15-preview have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 33 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}
00:50:25,480 graphrag.index.reporting.file_workflow_callbacks INFO Entity Extraction Error details={'doc_index': 0, 'text': '2,141</td><td>- 76</td><td>@)</td><td>2,210</td><td>1,648</td><td>562</td><td></td></tr><tr><td colspan="8">Level 2 </td></tr><tr><td>U.S. Treasury securities</td><td>16,298</td><td>3</td><td>(855)</td><td>15,446</td><td>138</td><td>4,649</td><td>10,659</td></tr><tr><td>U.S. agency securities</td><td>5,500</td><td></td><td>(418)</td><td>5,082</td><td>73</td><td>518</td><td>4,491</td></tr><tr><td>Non-U.S. government securities</td><td>17,560</td><td>31</td><td>(680)</td><td>16,911</td><td></td><td>11,592</td><td>5,319</td></tr><tr><td>Certificates of deposit and time deposits</td><td>1,337</td><td></td><td></td><td>1,337</td><td>838</td><td>492</td><td>7</td></tr><tr><td>Commercial paper</td><td>1,346</td><td></td><td></td><td>1,346</td><td>2</td><td>1,344</td><td></td></tr><tr><td>Corporate debt securities</td><td>68,194</td><td>83</td><td>(3,350)</td><td>64,927</td><td></td><td>15,489</td><td>49,438</td></tr><tr><td>Municipal securities</td><td>480</td><td></td><td>(13 3</td><td>467</td><td></td><td>197</td><td>270</td></tr><tr><td>Mortgage- and asset-backed securities</td><td>24,508</td><td>27</td><td>(2,086)</td><td>22,449</td><td></td><td>1,393</td><td>21,056</td></tr><tr><td>Subtotal</td><td>- _ 135,223</td><td>144</td><td>U, (7,402)</td><td>127,965</td><td>e 1,051</td><td>35,674</td><td>91,240</td></tr><tr><td>Total @</td><td>Ly JedeEsy $ 160,230</td><td>t =ee $ 220</td><td>W WLERR) @, 7,409</td><td>) JeRlea $ 153,041</td><td>B SIeey 25,565</td><td>8 Shieey 36,236 </td><td>91,240</td></tr></tbody></table>This table presents a breakdown of Apple Inc.\'s cash, cash equivalents, and marketable securities as of June 29, 2024, and September 30, 2023, in millions of dollars. \n\nIt categorizes these assets into two levels: Level 1 and Level 2. Level 1 includes highly liquid investments like money market funds and mutual funds, while Level 2 encompasses less liquid investments like U.S. Treasury securities, U.S. agency securities, and corporate debt securities. \n\nThe table provides information on the adjusted cost, unrealized gains and losses, fair value, and allocation between cash and cash equivalents, current marketable securities, and non-current marketable securities. \n\nThe table allows users to analyze the composition of Apple Inc.\'s investment portfolio and track changes in the fair value of these assets over time. \n\n<table><thead><tr><th></th><th colspan="7">September 30, 2023</th></tr><tr><th></th><th>Adjusted\n Cost\n _</th><th>Unrealized Gains</th><th>Unrealized Losses</th><th>Fair Value</th><th>Cash and Cash Equivalents</th><th>Current Marketable Securities</th><th>Non-Current Marketable Securities</th></tr></thead><tbody><tr><td>Cash</td><td>$ 28359</td><td></td><td>  $</td><td>$ 28,359</td><td>28,359</td><td>  $</td><td></td></tr><tr><td colspan="8">Level 1:</td></tr><tr><td>Money market funds</td><td>481</td><td></td><td></td><td>481</td><td>481</td><td></td><td></td></tr><tr><td>Mutual funds and equity securities</td><td>442 -</td><td>12</td><td>(26)</td><td>428</td><td></td><td>428</td><td>'}
00:50:26,611 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
00:50:26,613 graphrag.llm.base.rate_limiting_llm WARNING extract-continuation-0 failed to invoke LLM 2/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 7 seconds. Follow recommendation? True
00:50:27,86 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
00:50:27,87 graphrag.llm.base.rate_limiting_llm WARNING extract-continuation-0 failed to invoke LLM 2/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 7 seconds. Follow recommendation? True
00:50:29,444 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
00:50:29,448 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 3.959280549082905. input_tokens=2935, output_tokens=592
00:50:36,84 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
00:50:36,86 graphrag.llm.base.rate_limiting_llm WARNING extract-continuation-0 failed to invoke LLM 9/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 9 seconds. Follow recommendation? True
00:50:36,227 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
00:50:36,229 graphrag.llm.base.rate_limiting_llm WARNING extract-continuation-0 failed to invoke LLM 3/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 9 seconds. Follow recommendation? True
00:50:36,673 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
00:50:36,675 graphrag.llm.base.rate_limiting_llm WARNING Process failed to invoke LLM 2/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 8 seconds. Follow recommendation? True
00:50:36,821 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
00:50:36,822 graphrag.llm.base.rate_limiting_llm WARNING extract-continuation-0 failed to invoke LLM 3/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 8 seconds. Follow recommendation? True
00:50:38,531 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
00:50:38,534 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 5 retries took 2.962892387062311. input_tokens=34, output_tokens=360
00:50:49,600 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
00:50:49,603 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 2 retries took 2.802961562993005. input_tokens=2936, output_tokens=413
00:50:49,867 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
00:50:49,869 graphrag.llm.base.rate_limiting_llm WARNING extract-continuation-0 failed to invoke LLM 4/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 37 seconds. Follow recommendation? True
00:50:53,311 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
00:50:53,315 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 3 retries took 4.049021192127839. input_tokens=34, output_tokens=580
00:50:55,270 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
00:50:55,271 graphrag.llm.base.rate_limiting_llm WARNING extract-continuation-0 failed to invoke LLM 10/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 31 seconds. Follow recommendation? True
00:50:59,658 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
00:50:59,659 graphrag.llm.base.rate_limiting_llm WARNING Process failed to invoke LLM 5/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 27 seconds. Follow recommendation? True
00:51:08,839 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
00:51:08,840 graphrag.llm.base.rate_limiting_llm WARNING Process failed to invoke LLM 2/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 18 seconds. Follow recommendation? True
00:51:17,566 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
00:51:17,568 graphrag.llm.base.rate_limiting_llm WARNING Process failed to invoke LLM 2/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 9 seconds. Follow recommendation? True
00:51:26,273 root ERROR error extracting graph
Traceback (most recent call last):
  File "/opt/miniconda3/envs/affine-project-env/lib/python3.12/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py", line 122, in __call__
    result = await self._process_document(text, prompt_variables)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/miniconda3/envs/affine-project-env/lib/python3.12/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py", line 161, in _process_document
    response = await self._llm(
               ^^^^^^^^^^^^^^^^
  File "/opt/miniconda3/envs/affine-project-env/lib/python3.12/site-packages/graphrag/llm/openai/json_parsing_llm.py", line 34, in __call__
    result = await self._delegate(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/miniconda3/envs/affine-project-env/lib/python3.12/site-packages/graphrag/llm/openai/openai_token_replacing_llm.py", line 37, in __call__
    return await self._delegate(input, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/miniconda3/envs/affine-project-env/lib/python3.12/site-packages/graphrag/llm/openai/openai_history_tracking_llm.py", line 33, in __call__
    output = await self._delegate(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/miniconda3/envs/affine-project-env/lib/python3.12/site-packages/graphrag/llm/base/caching_llm.py", line 96, in __call__
    result = await self._delegate(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/miniconda3/envs/affine-project-env/lib/python3.12/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 177, in __call__
    result, start = await execute_with_retry()
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/miniconda3/envs/affine-project-env/lib/python3.12/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 159, in execute_with_retry
    async for attempt in retryer:
  File "/opt/miniconda3/envs/affine-project-env/lib/python3.12/site-packages/tenacity/asyncio/__init__.py", line 166, in __anext__
    do = await self.iter(retry_state=self._retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/miniconda3/envs/affine-project-env/lib/python3.12/site-packages/tenacity/asyncio/__init__.py", line 153, in iter
    result = await action(retry_state)
             ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/miniconda3/envs/affine-project-env/lib/python3.12/site-packages/tenacity/_utils.py", line 99, in inner
    return call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/opt/miniconda3/envs/affine-project-env/lib/python3.12/site-packages/tenacity/__init__.py", line 418, in exc_check
    raise retry_exc.reraise()
          ^^^^^^^^^^^^^^^^^^^
  File "/opt/miniconda3/envs/affine-project-env/lib/python3.12/site-packages/tenacity/__init__.py", line 185, in reraise
    raise self.last_attempt.result()
          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/miniconda3/envs/affine-project-env/lib/python3.12/concurrent/futures/_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "/opt/miniconda3/envs/affine-project-env/lib/python3.12/concurrent/futures/_base.py", line 401, in __get_result
    raise self._exception
  File "/opt/miniconda3/envs/affine-project-env/lib/python3.12/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 165, in execute_with_retry
    return await do_attempt(), start
           ^^^^^^^^^^^^^^^^^^
  File "/opt/miniconda3/envs/affine-project-env/lib/python3.12/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 151, in do_attempt
    await sleep_for(sleep_time)
  File "/opt/miniconda3/envs/affine-project-env/lib/python3.12/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 147, in do_attempt
    return await self._delegate(input, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/miniconda3/envs/affine-project-env/lib/python3.12/site-packages/graphrag/llm/base/base_llm.py", line 50, in __call__
    return await self._invoke(input, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/miniconda3/envs/affine-project-env/lib/python3.12/site-packages/graphrag/llm/base/base_llm.py", line 54, in _invoke
    output = await self._execute_llm(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/miniconda3/envs/affine-project-env/lib/python3.12/site-packages/graphrag/llm/openai/openai_chat_llm.py", line 53, in _execute_llm
    completion = await self.client.chat.completions.create(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/miniconda3/envs/affine-project-env/lib/python3.12/site-packages/openai/resources/chat/completions.py", line 1490, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/opt/miniconda3/envs/affine-project-env/lib/python3.12/site-packages/openai/_base_client.py", line 1831, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/miniconda3/envs/affine-project-env/lib/python3.12/site-packages/openai/_base_client.py", line 1525, in request
    return await self._request(
           ^^^^^^^^^^^^^^^^^^^^
  File "/opt/miniconda3/envs/affine-project-env/lib/python3.12/site-packages/openai/_base_client.py", line 1626, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the Chatcompletions_Create Operation under Azure OpenAI API version 2023-03-15-preview have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 31 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}
00:51:26,281 graphrag.index.reporting.file_workflow_callbacks INFO Entity Extraction Error details={'doc_index': 0, 'text': 'August 1, 2024\n\nBy:\n\n/s/ Timothy D. Cook\n\nTimothy D. Cook\n\nChief Executive Officer\n\nCERTIFICATION\n\nI, Luca Maestri, certify that:\n\nI have reviewed this quarterly report on Form 10-Q of Apple Inc.;\n\n2. Based on my knowledge, this report does not contain any untrue statement of a material fact or omit to state a material fact necessary to make the statements made, in light of the circumstances under which such statements were made, not misleading with respect to the period covered by this report;\n\n3. Based on my knowledge, the financial statements, and other financial information included in this report, fairly present in all material respects the financial condition, results of operations and cash flows of the Registrant as of, and for, the periods presented in this report;\n\n4. The Registrants other certifying officer(s) and I are responsible for establishing and maintaining disclosure controls and procedures (as defined in Exchange Act Rules 13a-15(e) and 15d-15(e)) and internal control over financial reporting (as defined in Exchange Act Rules 13a-15(f) and 15d-15(f)) for the Registrant and have:\n\n(a) Designed such disclosure controls and procedures, or caused such disclosure controls and procedures to be designed under our supervision, to ensure that material information relating to the Registrant, including its consolidated subsidiaries, is made known to us by others within those entities, particularly during the period in which this report is being prepared;\n\n(b) Designed such internal control over financial reporting, or caused such internal control over financial reporting to be designed under our supervision, to provide reasonable assurance regarding the reliability of financial reporting and the preparation of financial statements for external purposes in accordance with generally accepted accounting principles;\n\n(c) Evaluated the effectiveness of the Registrants disclosure controls and procedures and presented in this report our conclusions about the effectiveness of the disclosure controls and procedures, as of the end of the period covered by this report based on such evaluation; and\n\n(d) Disclosed in this report any change in the Registrants internal control over financial reporting that occurred during the Registrants most recent fiscal quarter (the Registrants fourth fiscal quarter in the case of an annual report) that has materially affected, or is reasonably likely to materially affect, the Registrants internal control over financial reporting; and\n\n5. The Registrants other certifying officer(s) and I have disclosed, based on our most recent evaluation of internal control over financial reporting, to the Registrants auditors and the audit committee of the Registrants board of directors (or persons performing the equivalent functions):\n\n(a) All significant deficiencies and material weaknesses in the design or operation of internal control over financial reporting which are reasonably likely to adversely affect the Registrants ability to record, process, summarize and report financial information; and\n\n(b) Any fraud, whether or not material, that involves management or other employees who have a significant role in the Registrants internal control over financial reporting.\n\nDate: August 1, 2024\n\nBy:\n\n/s/ Luca Maestri\n\nLuca Maestri\n\nSenior Vice President, Chief Financial Officer\n\nCERTIFICATIONS OF CHIEF EXECUTIVE OFFICER AND CHIEF FINANCIAL OFFICER PURSUANT TO 18 U.S.C. SECTION 1350, AS ADOPTED PURSUANT TO SECTION 906 OF THE SARBANES-OXLEY ACT OF 2002\n\nI, Timothy D. Cook, certify, as of the date hereof, pursuant to 18 U.S.C. Section 1350, as adopted pursuant to Section 906 of the Sarbanes-Oxley Act of 2002, that the Quarterly Report of Apple Inc. on Form 10-Q for the period ended June 29, 2024 fully complies with the requirements of Section 13(a) or 15(d) of the Securities Exchange Act of 1934 and that information contained in such Form 10-Q fairly presents in all material respects the financial condition and results of operations of Apple Inc. at the dates and for the periods indicated.\n\nDate: August 1, 2024\n\nBy:\n\n/s/ Timothy D. Cook\n\nTimothy D. Cook\n\nChief Executive Officer\n\nI, Luca Maestri, certify, as of the date hereof, pursuant to 18 U.S.C. Section 1350, as adopted pursuant to Section 906 of the Sarbanes-Oxley Act of 2002, that the Quarterly Report of Apple Inc. on Form 10-Q for the period ended June 29, 2024 fully complies with the requirements of Section 13(a) or 15(d) of the Securities Exchange Act of 1934 and that information contained in such Form 10-Q fairly presents in all material respects the financial condition and results of operations of Apple Inc. at the dates and for the periods indicated.\n\nDate: August 1, 2024\n\nBy:\n\n/s/ Luca Maestri\n\nLuca Maestri\n\nSenior Vice President, Chief Financial Officer\n\nA signed original of this written statement required by Section 906 has been provided to Apple Inc. and will be retained by Apple Inc. and furnished to the Securities and Exchange Commission or its staff upon request.'}
00:51:26,728 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
00:51:26,730 graphrag.llm.base.rate_limiting_llm WARNING extract-continuation-0 failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 10 seconds. Follow recommendation? True
00:51:30,287 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
00:51:30,291 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 1 retries took 4.271017187042162. input_tokens=2936, output_tokens=685
00:51:35,916 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
00:51:35,918 graphrag.llm.base.rate_limiting_llm WARNING extract-continuation-0 failed to invoke LLM 5/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 1 seconds. Follow recommendation? True
00:51:38,847 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
00:51:38,849 graphrag.llm.base.rate_limiting_llm WARNING extract-continuation-0 failed to invoke LLM 2/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 9 seconds. Follow recommendation? True
00:51:45,923 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
00:51:45,925 graphrag.llm.base.rate_limiting_llm WARNING Process failed to invoke LLM 6/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 2 seconds. Follow recommendation? True
00:51:47,102 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
00:51:47,103 graphrag.llm.base.rate_limiting_llm WARNING extract-continuation-0 failed to invoke LLM 6/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 1 seconds. Follow recommendation? True
00:51:47,318 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
00:51:52,418 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
00:51:52,422 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 2 retries took 2.2144503528252244. input_tokens=34, output_tokens=336
00:51:52,527 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 1 retries took 11.037917795125395. input_tokens=2936, output_tokens=1734
00:52:01,118 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
00:52:01,121 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 6 retries took 3.014578722883016. input_tokens=34, output_tokens=404
00:52:03,810 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
00:52:03,812 graphrag.llm.base.rate_limiting_llm WARNING Process failed to invoke LLM 2/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 23 seconds. Follow recommendation? True
00:52:12,959 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
00:52:12,961 graphrag.llm.base.rate_limiting_llm WARNING Process failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 14 seconds. Follow recommendation? True
00:52:21,698 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
00:52:21,699 graphrag.llm.base.rate_limiting_llm WARNING Process failed to invoke LLM 3/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 5 seconds. Follow recommendation? True
00:52:30,938 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
00:52:30,941 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 1 retries took 2.71536863502115. input_tokens=2847, output_tokens=420
00:52:41,350 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
00:52:41,354 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 2 retries took 3.1618499788455665. input_tokens=2937, output_tokens=513
00:52:41,460 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
00:52:41,462 graphrag.llm.base.rate_limiting_llm WARNING extract-continuation-0 failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 9 seconds. Follow recommendation? True
00:52:49,20 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
00:52:49,22 graphrag.llm.base.rate_limiting_llm WARNING Process failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 2 seconds. Follow recommendation? True
00:52:54,214 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
00:52:54,218 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 1 retries took 2.2122745509259403. input_tokens=34, output_tokens=373
00:52:58,218 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
00:52:58,220 graphrag.llm.base.rate_limiting_llm WARNING Process failed to invoke LLM 4/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 1 seconds. Follow recommendation? True
00:53:10,65 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
00:53:10,68 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 4 retries took 3.126740766922012. input_tokens=2936, output_tokens=471
00:53:17,654 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
00:53:17,656 graphrag.llm.base.rate_limiting_llm WARNING Process failed to invoke LLM 7/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 12 seconds. Follow recommendation? True
00:53:25,94 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
00:53:25,95 graphrag.llm.base.rate_limiting_llm WARNING Process failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 4 seconds. Follow recommendation? True
00:53:36,347 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
00:53:36,350 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 3 retries took 3.1737204319797456. input_tokens=2936, output_tokens=474
00:53:36,529 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
00:53:36,532 graphrag.llm.base.rate_limiting_llm WARNING extract-continuation-0 failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 3 seconds. Follow recommendation? True
00:53:42,903 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
00:53:42,907 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 1 retries took 2.2905476870946586. input_tokens=34, output_tokens=348
00:53:43,85 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
00:53:43,87 graphrag.llm.base.rate_limiting_llm WARNING extract-continuation-0 failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 10 seconds. Follow recommendation? True
00:53:45,117 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
00:53:45,118 graphrag.llm.base.rate_limiting_llm WARNING Process failed to invoke LLM 2/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 8 seconds. Follow recommendation? True
00:53:55,189 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
00:53:55,191 graphrag.llm.base.rate_limiting_llm WARNING extract-continuation-0 failed to invoke LLM 2/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 13 seconds. Follow recommendation? True
00:53:57,851 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
00:53:57,856 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 1 retries took 5.320270548108965. input_tokens=2442, output_tokens=847
00:53:58,33 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
00:53:58,35 graphrag.llm.base.rate_limiting_llm WARNING extract-continuation-0 failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 10 seconds. Follow recommendation? True
00:54:04,911 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
00:54:04,912 graphrag.llm.base.rate_limiting_llm WARNING Process failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 3 seconds. Follow recommendation? True
00:54:10,992 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
00:54:10,994 graphrag.llm.base.rate_limiting_llm WARNING extract-continuation-0 failed to invoke LLM 3/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 23 seconds. Follow recommendation? True
00:54:11,423 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
00:54:11,426 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 1 retries took 1.7259471439756453. input_tokens=34, output_tokens=228
00:54:11,605 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
00:54:11,606 graphrag.llm.base.rate_limiting_llm WARNING extract-continuation-0 failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 22 seconds. Follow recommendation? True
00:54:13,593 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
00:54:13,595 graphrag.llm.base.rate_limiting_llm WARNING Process failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 21 seconds. Follow recommendation? True
00:54:22,763 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
00:54:22,764 graphrag.llm.base.rate_limiting_llm WARNING Process failed to invoke LLM 4/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 11 seconds. Follow recommendation? True
00:54:31,498 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
00:54:31,499 graphrag.llm.base.rate_limiting_llm WARNING Process failed to invoke LLM 4/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 3 seconds. Follow recommendation? True
00:54:38,664 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
00:54:38,668 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 1 retries took 3.8682109229266644. input_tokens=34, output_tokens=671
00:54:38,846 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
00:54:38,847 graphrag.llm.base.rate_limiting_llm WARNING extract-continuation-0 failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 2 seconds. Follow recommendation? True
00:54:38,983 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
00:54:38,984 graphrag.llm.base.rate_limiting_llm WARNING extract-continuation-0 failed to invoke LLM 4/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 2 seconds. Follow recommendation? True
00:54:42,442 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
00:54:42,443 graphrag.llm.base.rate_limiting_llm WARNING Process failed to invoke LLM 5/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 11 seconds. Follow recommendation? True
00:54:44,79 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
00:54:44,82 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 1 retries took 2.2255400829017162. input_tokens=34, output_tokens=332
00:54:44,261 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
00:54:44,262 graphrag.llm.base.rate_limiting_llm WARNING extract-continuation-0 failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 26 seconds. Follow recommendation? True
00:54:49,930 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
00:54:49,931 graphrag.llm.base.rate_limiting_llm WARNING extract-continuation-0 failed to invoke LLM 5/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 20 seconds. Follow recommendation? True
00:54:52,385 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
00:54:52,387 graphrag.llm.base.rate_limiting_llm WARNING Process failed to invoke LLM 3/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 1 seconds. Follow recommendation? True
00:55:04,975 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
00:55:04,979 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 2 retries took 3.8696413771249354. input_tokens=2936, output_tokens=581
00:55:05,159 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
00:55:05,160 graphrag.llm.base.rate_limiting_llm WARNING extract-continuation-0 failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 5 seconds. Follow recommendation? True
00:55:12,236 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
00:55:12,237 graphrag.llm.base.rate_limiting_llm WARNING extract-continuation-0 failed to invoke LLM 2/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 23 seconds. Follow recommendation? True
00:55:12,352 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
00:55:12,354 graphrag.llm.base.rate_limiting_llm WARNING Process failed to invoke LLM 6/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 23 seconds. Follow recommendation? True
00:55:13,557 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
00:55:13,560 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 1 retries took 2.2043912350200117. input_tokens=34, output_tokens=210
00:55:13,738 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
00:55:13,740 graphrag.llm.base.rate_limiting_llm WARNING extract-continuation-0 failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 22 seconds. Follow recommendation? True
00:55:20,383 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
00:55:20,384 graphrag.llm.base.rate_limiting_llm WARNING extract-continuation-0 failed to invoke LLM 6/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 15 seconds. Follow recommendation? True
00:55:22,477 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
00:55:22,479 graphrag.llm.base.rate_limiting_llm WARNING Process failed to invoke LLM 4/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 13 seconds. Follow recommendation? True
00:55:31,572 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
00:55:31,574 graphrag.llm.base.rate_limiting_llm WARNING Process failed to invoke LLM 4/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 4 seconds. Follow recommendation? True
00:55:38,571 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
00:55:38,572 graphrag.llm.base.rate_limiting_llm WARNING extract-continuation-0 failed to invoke LLM 3/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 4 seconds. Follow recommendation? True
00:55:39,537 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
00:55:39,540 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 1 retries took 2.4770475500263274. input_tokens=34, output_tokens=331
00:55:39,718 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
00:55:39,720 graphrag.llm.base.rate_limiting_llm WARNING extract-continuation-0 failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 3 seconds. Follow recommendation? True
00:55:41,566 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
00:55:41,568 graphrag.llm.base.rate_limiting_llm WARNING Process failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 1 seconds. Follow recommendation? True
00:55:45,838 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
00:55:45,839 graphrag.llm.base.rate_limiting_llm WARNING extract-continuation-0 failed to invoke LLM 7/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 26 seconds. Follow recommendation? True
00:55:46,971 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
00:55:46,974 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 1 retries took 2.8415898280218244. input_tokens=34, output_tokens=390
00:55:47,174 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
00:55:47,175 graphrag.llm.base.rate_limiting_llm WARNING extract-continuation-0 failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 15 seconds. Follow recommendation? True
00:55:47,177 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
00:55:47,178 graphrag.llm.base.rate_limiting_llm WARNING extract-continuation-0 failed to invoke LLM 4/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 15 seconds. Follow recommendation? True
00:55:51,908 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
00:55:51,910 graphrag.llm.base.rate_limiting_llm WARNING Process failed to invoke LLM 8/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 10 seconds. Follow recommendation? True
00:56:01,86 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
00:56:01,88 graphrag.llm.base.rate_limiting_llm WARNING Process failed to invoke LLM 3/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 1 seconds. Follow recommendation? True
00:56:05,993 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
00:56:05,996 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 1 retries took 2.792918256018311. input_tokens=34, output_tokens=416
00:56:06,177 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
00:56:06,179 graphrag.llm.base.rate_limiting_llm WARNING extract-continuation-0 failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 6 seconds. Follow recommendation? True
00:56:10,431 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
00:56:10,433 graphrag.llm.base.rate_limiting_llm WARNING Process failed to invoke LLM 5/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 2 seconds. Follow recommendation? True
00:56:11,95 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
00:56:11,96 graphrag.llm.base.rate_limiting_llm WARNING extract-continuation-0 failed to invoke LLM 5/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 1 seconds. Follow recommendation? True
00:56:15,614 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
00:56:15,617 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 1 retries took 1.491887649986893. input_tokens=34, output_tokens=230
00:56:15,797 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
00:56:15,799 graphrag.llm.base.rate_limiting_llm WARNING extract-continuation-0 failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 22 seconds. Follow recommendation? True
00:56:20,94 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
00:56:20,96 graphrag.llm.base.rate_limiting_llm WARNING Process failed to invoke LLM 3/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 18 seconds. Follow recommendation? True
00:56:22,24 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
00:56:22,25 graphrag.llm.base.rate_limiting_llm WARNING extract-continuation-0 failed to invoke LLM 8/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 16 seconds. Follow recommendation? True
00:56:22,197 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
00:56:22,199 graphrag.llm.base.rate_limiting_llm WARNING extract-continuation-0 failed to invoke LLM 6/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 16 seconds. Follow recommendation? True
00:56:29,469 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
00:56:29,471 graphrag.llm.base.rate_limiting_llm WARNING Process failed to invoke LLM 3/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 9 seconds. Follow recommendation? True
00:56:39,713 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
00:56:39,715 graphrag.llm.base.rate_limiting_llm WARNING extract-continuation-0 failed to invoke LLM 2/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 5 seconds. Follow recommendation? True
00:56:41,522 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
00:56:41,525 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 3.688619571039453. input_tokens=2936, output_tokens=438
00:56:41,738 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
00:56:41,740 graphrag.llm.base.rate_limiting_llm WARNING extract-continuation-0 failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 3 seconds. Follow recommendation? True
00:56:47,537 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
00:56:47,541 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 1 retries took 1.3950350179802626. input_tokens=34, output_tokens=179
00:56:47,812 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
00:56:47,814 graphrag.llm.base.rate_limiting_llm WARNING extract-continuation-0 failed to invoke LLM 3/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 16 seconds. Follow recommendation? True
00:56:48,214 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
00:56:48,215 graphrag.llm.base.rate_limiting_llm WARNING extract-continuation-0 failed to invoke LLM 9/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 16 seconds. Follow recommendation? True
00:56:48,654 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
00:56:48,655 graphrag.llm.base.rate_limiting_llm WARNING extract-continuation-0 failed to invoke LLM 7/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 15 seconds. Follow recommendation? True
00:56:48,969 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
00:56:48,971 graphrag.llm.base.rate_limiting_llm WARNING Process failed to invoke LLM 6/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 15 seconds. Follow recommendation? True
00:56:58,141 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
00:56:58,142 graphrag.llm.base.rate_limiting_llm WARNING Process failed to invoke LLM 4/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 6 seconds. Follow recommendation? True
00:57:08,441 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
00:57:08,443 graphrag.llm.base.rate_limiting_llm WARNING extract-continuation-0 failed to invoke LLM 4/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 6 seconds. Follow recommendation? True
00:57:09,605 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
00:57:09,609 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 3 retries took 3.100046169012785. input_tokens=2936, output_tokens=464
00:57:09,797 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
00:57:09,798 graphrag.llm.base.rate_limiting_llm WARNING extract-continuation-0 failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 5 seconds. Follow recommendation? True
00:57:13,838 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
00:57:13,839 graphrag.llm.base.rate_limiting_llm WARNING extract-continuation-0 failed to invoke LLM 8/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 1 seconds. Follow recommendation? True
00:57:16,886 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
00:57:16,888 graphrag.llm.base.rate_limiting_llm WARNING extract-continuation-0 failed to invoke LLM 2/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 22 seconds. Follow recommendation? True
00:57:17,844 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
00:57:17,846 graphrag.llm.base.rate_limiting_llm WARNING Process failed to invoke LLM 4/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 21 seconds. Follow recommendation? True
00:57:18,331 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
00:57:18,335 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 9 retries took 4.114695670083165. input_tokens=34, output_tokens=337
00:57:23,429 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
00:57:23,431 graphrag.llm.base.rate_limiting_llm WARNING extract-continuation-0 failed to invoke LLM 5/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 15 seconds. Follow recommendation? True
00:57:25,24 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
00:57:25,25 graphrag.llm.base.rate_limiting_llm WARNING extract-continuation-0 failed to invoke LLM 9/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 14 seconds. Follow recommendation? True
00:57:27,532 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
00:57:27,533 graphrag.llm.base.rate_limiting_llm WARNING Process failed to invoke LLM 3/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 11 seconds. Follow recommendation? True
00:57:36,629 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
00:57:36,631 graphrag.llm.base.rate_limiting_llm WARNING Process failed to invoke LLM 4/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 2 seconds. Follow recommendation? True
00:57:43,914 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
00:57:43,917 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 2 retries took 2.192525800084695. input_tokens=34, output_tokens=245
00:57:48,887 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
00:57:48,889 graphrag.llm.base.rate_limiting_llm WARNING extract-continuation-0 failed to invoke LLM 6/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 19 seconds. Follow recommendation? True
00:57:49,124 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
00:57:49,126 graphrag.llm.base.rate_limiting_llm WARNING extract-continuation-0 failed to invoke LLM 10/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 18 seconds. Follow recommendation? True
00:57:49,332 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
00:57:49,335 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 4 retries took 2.455614347010851. input_tokens=2936, output_tokens=183
00:57:49,442 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
00:57:49,444 graphrag.llm.base.rate_limiting_llm WARNING extract-continuation-0 failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 18 seconds. Follow recommendation? True
00:57:56,402 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
00:57:56,403 graphrag.llm.base.rate_limiting_llm WARNING Process failed to invoke LLM 5/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 11 seconds. Follow recommendation? True
00:58:05,227 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
00:58:05,229 graphrag.llm.base.rate_limiting_llm WARNING Process failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 2 seconds. Follow recommendation? True
00:58:07,128 root ERROR error extracting graph
Traceback (most recent call last):
  File "/opt/miniconda3/envs/affine-project-env/lib/python3.12/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py", line 122, in __call__
    result = await self._process_document(text, prompt_variables)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/miniconda3/envs/affine-project-env/lib/python3.12/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py", line 161, in _process_document
    response = await self._llm(
               ^^^^^^^^^^^^^^^^
  File "/opt/miniconda3/envs/affine-project-env/lib/python3.12/site-packages/graphrag/llm/openai/json_parsing_llm.py", line 34, in __call__
    result = await self._delegate(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/miniconda3/envs/affine-project-env/lib/python3.12/site-packages/graphrag/llm/openai/openai_token_replacing_llm.py", line 37, in __call__
    return await self._delegate(input, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/miniconda3/envs/affine-project-env/lib/python3.12/site-packages/graphrag/llm/openai/openai_history_tracking_llm.py", line 33, in __call__
    output = await self._delegate(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/miniconda3/envs/affine-project-env/lib/python3.12/site-packages/graphrag/llm/base/caching_llm.py", line 96, in __call__
    result = await self._delegate(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/miniconda3/envs/affine-project-env/lib/python3.12/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 177, in __call__
    result, start = await execute_with_retry()
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/miniconda3/envs/affine-project-env/lib/python3.12/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 159, in execute_with_retry
    async for attempt in retryer:
  File "/opt/miniconda3/envs/affine-project-env/lib/python3.12/site-packages/tenacity/asyncio/__init__.py", line 166, in __anext__
    do = await self.iter(retry_state=self._retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/miniconda3/envs/affine-project-env/lib/python3.12/site-packages/tenacity/asyncio/__init__.py", line 153, in iter
    result = await action(retry_state)
             ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/miniconda3/envs/affine-project-env/lib/python3.12/site-packages/tenacity/_utils.py", line 99, in inner
    return call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/opt/miniconda3/envs/affine-project-env/lib/python3.12/site-packages/tenacity/__init__.py", line 418, in exc_check
    raise retry_exc.reraise()
          ^^^^^^^^^^^^^^^^^^^
  File "/opt/miniconda3/envs/affine-project-env/lib/python3.12/site-packages/tenacity/__init__.py", line 185, in reraise
    raise self.last_attempt.result()
          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/miniconda3/envs/affine-project-env/lib/python3.12/concurrent/futures/_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "/opt/miniconda3/envs/affine-project-env/lib/python3.12/concurrent/futures/_base.py", line 401, in __get_result
    raise self._exception
  File "/opt/miniconda3/envs/affine-project-env/lib/python3.12/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 165, in execute_with_retry
    return await do_attempt(), start
           ^^^^^^^^^^^^^^^^^^
  File "/opt/miniconda3/envs/affine-project-env/lib/python3.12/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 151, in do_attempt
    await sleep_for(sleep_time)
  File "/opt/miniconda3/envs/affine-project-env/lib/python3.12/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 147, in do_attempt
    return await self._delegate(input, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/miniconda3/envs/affine-project-env/lib/python3.12/site-packages/graphrag/llm/base/base_llm.py", line 50, in __call__
    return await self._invoke(input, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/miniconda3/envs/affine-project-env/lib/python3.12/site-packages/graphrag/llm/base/base_llm.py", line 54, in _invoke
    output = await self._execute_llm(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/miniconda3/envs/affine-project-env/lib/python3.12/site-packages/graphrag/llm/openai/openai_chat_llm.py", line 53, in _execute_llm
    completion = await self.client.chat.completions.create(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/miniconda3/envs/affine-project-env/lib/python3.12/site-packages/openai/resources/chat/completions.py", line 1490, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/opt/miniconda3/envs/affine-project-env/lib/python3.12/site-packages/openai/_base_client.py", line 1831, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/miniconda3/envs/affine-project-env/lib/python3.12/site-packages/openai/_base_client.py", line 1525, in request
    return await self._request(
           ^^^^^^^^^^^^^^^^^^^^
  File "/opt/miniconda3/envs/affine-project-env/lib/python3.12/site-packages/openai/_base_client.py", line 1626, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the Chatcompletions_Create Operation under Azure OpenAI API version 2023-03-15-preview have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 18 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}
00:58:07,135 graphrag.index.reporting.file_workflow_callbacks INFO Entity Extraction Error details={'doc_index': 0, 'text': ', that involves management or other employees who have a significant role in the Registrants internal control over financial reporting.\n\nDate: May 2, 2024\n\nBy:\n\n/s/ Timothy D. Cook\n\nTimothy D. Cook\n\nChief Executive Officer\n\nCERTIFICATION\n\nI, Luca Maestri, certify that:\n\nI have reviewed this quarterly report on Form 10-Q of Apple Inc.;\n\n2. Based on my knowledge, this report does not contain any untrue statement of a material fact or omit to state a material fact necessary to make the statements made, in light of the circumstances under which such statements were made, not misleading with respect to the period covered by this report;\n\n3. Based on my knowledge, the financial statements, and other financial information included in this report, fairly present in all material respects the financial condition, results of operations and cash flows of the Registrant as of, and for, the periods presented in this report;\n\n4. The Registrants other certifying officer(s) and I are responsible for establishing and maintaining disclosure controls and procedures (as defined in Exchange Act Rules 13a-15(e) and 15d-15(e)) and internal control over financial reporting (as defined in Exchange Act Rules 13a-15(f) and 15d-15(f)) for the Registrant and have:\n\n(a) Designed such disclosure controls and procedures, or caused such disclosure controls and procedures to be designed under our supervision, to ensure that material information relating to the Registrant, including its consolidated subsidiaries, is made known to us by others within those entities, particularly during the period in which this report is being prepared;\n\n(b) Designed such internal control over financial reporting, or caused such internal control over financial reporting to be designed under our supervision, to provide reasonable assurance regarding the reliability of financial reporting and the preparation of financial statements for external purposes in accordance with generally accepted accounting principles;\n\n(c) Evaluated the effectiveness of the Registrants disclosure controls and procedures and presented in this report our conclusions about the effectiveness of the disclosure controls and procedures, as of the end of the period covered by this report based on such evaluation; and\n\n(d) Disclosed in this report any change in the Registrants internal control over financial reporting that occurred during the Registrants most recent fiscal quarter (the Registrants fourth fiscal quarter in the case of an annual report) that has materially affected, or is reasonably likely to materially affect, the Registrants internal control over financial reporting; and\n\n5. The Registrants other certifying officer(s) and I have disclosed, based on our most recent evaluation of internal control over financial reporting, to the Registrants auditors and the audit committee of the Registrants board of directors (or persons performing the equivalent functions):\n\n(a) All significant deficiencies and material weaknesses in the design or operation of internal control over financial reporting which are reasonably likely to adversely affect the Registrants ability to record, process, summarize and report financial information; and\n\n(b) Any fraud, whether or not material, that involves management or other employees who have a significant role in the Registrants internal control over financial reporting.\n\nDate: May 2, 2024\n\nBy:\n\n/s/ Luca Maestri\n\nLuca Maestri\n\nSenior Vice President, Chief Financial Officer\n\nCERTIFICATIONS OF CHIEF EXECUTIVE OFFICER AND CHIEF FINANCIAL OFFICER PURSUANT TO 18 U.S.C. SECTION 1350, AS ADOPTED PURSUANT TO SECTION 906 OF THE SARBANES-OXLEY ACT OF 2002\n\nI, Timothy D. Cook, certify, as of the date hereof, pursuant to 18 U.S.C. Section 1350, as adopted pursuant to Section 906 of the Sarbanes-Oxley Act of 2002, that the Quarterly Report of Apple Inc. on Form 10-Q for the period ended March 30, 2024 fully complies with the requirements of Section 13(a) or 15(d) of the Securities Exchange Act of 1934 and that information contained in such Form 10-Q fairly presents in all material respects the financial condition and results of operations of Apple Inc. at the dates and for the periods indicated.\n\nDate: May 2, 2024\n\nBy:\n\n/s/ Timothy D. Cook\n\nTimothy D. Cook\n\nChief Executive Officer\n\nI, Luca Maestri, certify, as of the date hereof, pursuant to 18 U.S.C. Section 1350, as adopted pursuant to Section 906 of the Sarbanes-Oxley Act of 2002, that the Quarterly Report of Apple Inc. on Form 10-Q for the period ended March 30, 2024 fully complies with the requirements of Section 13(a) or 15(d) of the Securities Exchange Act of 1934 and that information contained in such Form 10-Q fairly presents in all material respects the financial condition and results of operations of Apple Inc. at the dates and for the periods indicated.\n\nDate: May 2, 2024\n\nBy:\n\n/s/ Luca Maestri\n\nLuca Maestri\n\nSenior Vice President, Chief Financial Officer\n\nA signed original of this written statement required by Section 906 has been provided to Apple Inc. and will be retained by Apple Inc. and furnished to the Securities and Exchange Commission or its staff upon request.'}
00:58:12,657 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
00:58:12,661 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 1 retries took 3.444375446997583. input_tokens=34, output_tokens=484
00:58:18,357 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
00:58:18,358 graphrag.llm.base.rate_limiting_llm WARNING extract-continuation-0 failed to invoke LLM 7/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 24 seconds. Follow recommendation? True
00:58:18,897 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
00:58:18,901 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 3.9785022898577154. input_tokens=2936, output_tokens=593
00:58:19,87 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
00:58:19,89 graphrag.llm.base.rate_limiting_llm WARNING extract-continuation-0 failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 24 seconds. Follow recommendation? True
00:58:25,745 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
00:58:25,746 graphrag.llm.base.rate_limiting_llm WARNING Process failed to invoke LLM 2/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 17 seconds. Follow recommendation? True
00:58:34,484 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
00:58:34,486 graphrag.llm.base.rate_limiting_llm WARNING Process failed to invoke LLM 5/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 8 seconds. Follow recommendation? True
00:58:44,747 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
00:58:44,748 graphrag.llm.base.rate_limiting_llm WARNING extract-continuation-0 failed to invoke LLM 2/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 3 seconds. Follow recommendation? True
00:58:49,894 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
00:58:49,898 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 6.9596033280249685. input_tokens=2936, output_tokens=819
00:58:50,998 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
00:58:50,999 graphrag.llm.base.rate_limiting_llm WARNING extract-continuation-0 failed to invoke LLM 3/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 19 seconds. Follow recommendation? True
00:58:52,542 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
00:58:52,543 graphrag.llm.base.rate_limiting_llm WARNING extract-continuation-0 failed to invoke LLM 8/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 17 seconds. Follow recommendation? True
00:58:53,407 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
00:58:53,410 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 3.477601748891175. input_tokens=34, output_tokens=476
00:58:57,895 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
00:58:57,897 graphrag.llm.base.rate_limiting_llm WARNING Process failed to invoke LLM 5/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 12 seconds. Follow recommendation? True
00:59:07,69 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
00:59:07,71 graphrag.llm.base.rate_limiting_llm WARNING Process failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 3 seconds. Follow recommendation? True
00:59:17,236 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
00:59:17,239 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 3 retries took 2.467531877104193. input_tokens=34, output_tokens=303
00:59:18,242 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
00:59:18,246 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 1 retries took 3.461021365132183. input_tokens=2936, output_tokens=518
00:59:18,439 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
00:59:18,441 graphrag.llm.base.rate_limiting_llm WARNING extract-continuation-0 failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 32 seconds. Follow recommendation? True
00:59:19,728 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
00:59:19,730 graphrag.llm.base.rate_limiting_llm WARNING extract-continuation-0 failed to invoke LLM 9/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 24 seconds. Follow recommendation? True
00:59:26,43 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
00:59:26,44 graphrag.llm.base.rate_limiting_llm WARNING Process failed to invoke LLM 7/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 18 seconds. Follow recommendation? True
00:59:34,767 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
00:59:34,768 graphrag.llm.base.rate_limiting_llm WARNING Process failed to invoke LLM 5/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 9 seconds. Follow recommendation? True
00:59:45,640 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
00:59:45,643 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 3 retries took 2.418329797917977. input_tokens=2936, output_tokens=339
00:59:45,771 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
00:59:45,772 graphrag.llm.base.rate_limiting_llm WARNING extract-continuation-0 failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 5 seconds. Follow recommendation? True
00:59:53,31 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
00:59:53,32 graphrag.llm.base.rate_limiting_llm WARNING extract-continuation-0 failed to invoke LLM 2/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 23 seconds. Follow recommendation? True
00:59:53,851 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
00:59:53,853 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 1 retries took 1.7027890009339899. input_tokens=34, output_tokens=206
00:59:53,918 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
00:59:53,919 graphrag.llm.base.rate_limiting_llm WARNING extract-continuation-0 failed to invoke LLM 10/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 22 seconds. Follow recommendation? True
00:59:54,190 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
00:59:54,192 graphrag.llm.base.rate_limiting_llm WARNING Process failed to invoke LLM 2/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 22 seconds. Follow recommendation? True
01:00:02,947 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
01:00:02,948 graphrag.llm.base.rate_limiting_llm WARNING Process failed to invoke LLM 6/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 13 seconds. Follow recommendation? True
01:00:11,851 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
01:00:11,852 graphrag.llm.base.rate_limiting_llm WARNING Process failed to invoke LLM 4/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 4 seconds. Follow recommendation? True
01:00:15,921 root ERROR error extracting graph
Traceback (most recent call last):
  File "/opt/miniconda3/envs/affine-project-env/lib/python3.12/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py", line 122, in __call__
    result = await self._process_document(text, prompt_variables)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/miniconda3/envs/affine-project-env/lib/python3.12/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py", line 161, in _process_document
    response = await self._llm(
               ^^^^^^^^^^^^^^^^
  File "/opt/miniconda3/envs/affine-project-env/lib/python3.12/site-packages/graphrag/llm/openai/json_parsing_llm.py", line 34, in __call__
    result = await self._delegate(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/miniconda3/envs/affine-project-env/lib/python3.12/site-packages/graphrag/llm/openai/openai_token_replacing_llm.py", line 37, in __call__
    return await self._delegate(input, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/miniconda3/envs/affine-project-env/lib/python3.12/site-packages/graphrag/llm/openai/openai_history_tracking_llm.py", line 33, in __call__
    output = await self._delegate(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/miniconda3/envs/affine-project-env/lib/python3.12/site-packages/graphrag/llm/base/caching_llm.py", line 96, in __call__
    result = await self._delegate(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/miniconda3/envs/affine-project-env/lib/python3.12/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 177, in __call__
    result, start = await execute_with_retry()
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/miniconda3/envs/affine-project-env/lib/python3.12/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 159, in execute_with_retry
    async for attempt in retryer:
  File "/opt/miniconda3/envs/affine-project-env/lib/python3.12/site-packages/tenacity/asyncio/__init__.py", line 166, in __anext__
    do = await self.iter(retry_state=self._retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/miniconda3/envs/affine-project-env/lib/python3.12/site-packages/tenacity/asyncio/__init__.py", line 153, in iter
    result = await action(retry_state)
             ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/miniconda3/envs/affine-project-env/lib/python3.12/site-packages/tenacity/_utils.py", line 99, in inner
    return call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/opt/miniconda3/envs/affine-project-env/lib/python3.12/site-packages/tenacity/__init__.py", line 418, in exc_check
    raise retry_exc.reraise()
          ^^^^^^^^^^^^^^^^^^^
  File "/opt/miniconda3/envs/affine-project-env/lib/python3.12/site-packages/tenacity/__init__.py", line 185, in reraise
    raise self.last_attempt.result()
          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/miniconda3/envs/affine-project-env/lib/python3.12/concurrent/futures/_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "/opt/miniconda3/envs/affine-project-env/lib/python3.12/concurrent/futures/_base.py", line 401, in __get_result
    raise self._exception
  File "/opt/miniconda3/envs/affine-project-env/lib/python3.12/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 165, in execute_with_retry
    return await do_attempt(), start
           ^^^^^^^^^^^^^^^^^^
  File "/opt/miniconda3/envs/affine-project-env/lib/python3.12/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 151, in do_attempt
    await sleep_for(sleep_time)
  File "/opt/miniconda3/envs/affine-project-env/lib/python3.12/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 147, in do_attempt
    return await self._delegate(input, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/miniconda3/envs/affine-project-env/lib/python3.12/site-packages/graphrag/llm/base/base_llm.py", line 50, in __call__
    return await self._invoke(input, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/miniconda3/envs/affine-project-env/lib/python3.12/site-packages/graphrag/llm/base/base_llm.py", line 54, in _invoke
    output = await self._execute_llm(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/miniconda3/envs/affine-project-env/lib/python3.12/site-packages/graphrag/llm/openai/openai_chat_llm.py", line 53, in _execute_llm
    completion = await self.client.chat.completions.create(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/miniconda3/envs/affine-project-env/lib/python3.12/site-packages/openai/resources/chat/completions.py", line 1490, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/opt/miniconda3/envs/affine-project-env/lib/python3.12/site-packages/openai/_base_client.py", line 1831, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/miniconda3/envs/affine-project-env/lib/python3.12/site-packages/openai/_base_client.py", line 1525, in request
    return await self._request(
           ^^^^^^^^^^^^^^^^^^^^
  File "/opt/miniconda3/envs/affine-project-env/lib/python3.12/site-packages/openai/_base_client.py", line 1626, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the Chatcompletions_Create Operation under Azure OpenAI API version 2023-03-15-preview have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 22 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}
01:00:15,928 graphrag.index.reporting.file_workflow_callbacks INFO Entity Extraction Error details={'doc_index': 0, 'text': 'th><th colspan="3">Three Months Ended</th><th colspan="3">Nine Months Ended</th></tr><tr><th></th><th>June 29, _ 2024</th><th>July 1, 2023</th><th>Change</th><th>June 29, 2024</th><th>July 1, 2023</th><th>Change</th></tr></thead><tbody><tr><td colspan="7">- Net sales by category:</td></tr><tr><td>iPhone</td><td>$ 39,296</td><td>39,669</td><td>(1%</td><td>$ 154,961</td><td>$ 156,778</td><td>(1) %</td></tr><tr><td>Mac</td><td>7,009</td><td>6,840</td><td>2%</td><td>22,240</td><td>21,743</td><td>2%</td></tr><tr><td>iPad</td><td>7,162</td><td>5,791</td><td>24 %</td><td>19,744</td><td>21,857</td><td>(10) %</td></tr><tr><td>Wearables, Home and Accessories</td><td>8,097</td><td>8,284</td><td>()%</td><td>27,963</td><td>30,523</td><td>(8) %</td></tr><tr><td>Services</td><td>24,213</td><td>21,213</td><td>14 %</td><td>71,197</td><td>62,886</td><td>13 %</td></tr><tr><td>Total net sales</td><td>$ 85,777</td><td>81,797</td><td>5%</td><td>$ 296,105</td><td>$ 293,787</td><td>1%</td></tr></tbody></table>\niPhone\n\niPhone net sales were relatively flat during the third quarter and first nine months of 2024 compared to the same periods in 2023.\n\nMac\n\nMac net sales increased during the third quarter and first nine months of 2024 compared to the same periods in 2023 due to higher net sales of laptops.\n\niPad\n\niPad net sales increased during the third quarter of 2024 compared to the third quarter of 2023 due primarily to higher net sales of iPad Pro and iPad Air. Year-over-year iPad net sales decreased during the first nine months of 2024 due primarily to lower net sales of iPad 9th generation and iPad Pro, partially offset by higher net sales of iPad 10th generation.\n\nWearables, Home and Accessories\n\nWearables, Home and Accessories net sales decreased during the third quarter of 2024 compared to the third quarter of 2023 due primarily to lower net sales of Wearables. Year-over-year Wearables, Home and Accessories net sales decreased during the first nine months of 2024 due primarily to lower net sales of Wearables and Accessories.\n\nServices\n\nServices net sales increased during the third quarter and first nine months of 2024 compared to the same periods in 2023 due primarily to higher net sales from advertising, the App Store and cloud services.\n\nGross Margin\n\nProducts and Services gross margin and gross margin percentage for the three- and nine-month periods ended June 29, 2024 and July 1, 2023 were as follows (dollars in millions):\nThis table presents the gross margin and gross margin percentage for both products and services of a company for the three-month and nine-month periods ending June 29, 2024 and July 1, 2023. It compares the gross margin figures for both periods, displaying the total gross margin for products, services, and overall. All figures are in millions of dollars.  \n\n<table><thead><tr><th></th><th colspan="2">Three Months Ended</th><th colspan="2">Nine Months Ended</th></tr><tr><th></th><th>June 29, 2024</th><th>July 1, 2023</th><th>June 29, 2024</th><th>July 1, 2023</th></tr></thead><tbody><tr><td colspan="5">Gross margin:</td></tr><tr><td>Products</td><td>$ 21,761</td><td>$ 21,448</td><td>$ 84,241</td><td>$ 84,205</td></tr><tr><td>Services</td><td>17,917</td><td>14,965</td><td>52,563</td><td>44,516</td></tr><tr><td>Total gross margin</td><td>$ 39,678</td><td>$ 36,413</td><td> 136,804</td><td>$ 128,721</td></tr></tbody></table>\nGross margin percentage:\nThis table presents the gross margin percentage for products, services, and total gross margin for the three- and nine-month periods ended June 29, 2024, and July 1, 2023. The table shows that the gross margin percentage for products has remained relatively stable, while the gross margin percentage for services has increased slightly. The overall gross margin percentage has also increased slightly.  The table provides a breakdown of the gross margin percentage by product'}
01:00:21,529 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
01:00:21,532 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 2 retries took 2.925387973198667. input_tokens=34, output_tokens=345
01:00:24,600 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
01:00:24,604 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 7 retries took 4.120947699993849. input_tokens=2936, output_tokens=543
01:00:24,791 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
01:00:24,792 graphrag.llm.base.rate_limiting_llm WARNING extract-continuation-0 failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 19 seconds. Follow recommendation? True
01:00:32,335 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
01:00:32,336 graphrag.llm.base.rate_limiting_llm WARNING Process failed to invoke LLM 4/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 12 seconds. Follow recommendation? True
01:00:41,226 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
01:00:41,228 graphrag.llm.base.rate_limiting_llm WARNING Process failed to invoke LLM 9/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 3 seconds. Follow recommendation? True
01:00:50,102 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
01:00:50,106 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 1 retries took 5.132304447004572. input_tokens=34, output_tokens=588
01:00:52,481 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
01:00:52,483 graphrag.llm.base.rate_limiting_llm WARNING Process failed to invoke LLM 7/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 1 seconds. Follow recommendation? True
01:01:05,738 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
01:01:05,742 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 4 retries took 4.534902245970443. input_tokens=2936, output_tokens=577
01:01:05,935 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
01:01:05,936 graphrag.llm.base.rate_limiting_llm WARNING extract-continuation-0 failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 14 seconds. Follow recommendation? True
01:01:12,63 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
01:01:12,64 graphrag.llm.base.rate_limiting_llm WARNING Process failed to invoke LLM 3/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 8 seconds. Follow recommendation? True
01:01:23,858 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
01:01:23,861 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 6 retries took 3.4438007050193846. input_tokens=2936, output_tokens=281
01:01:23,969 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
01:01:23,971 graphrag.llm.base.rate_limiting_llm WARNING extract-continuation-0 failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 22 seconds. Follow recommendation? True
01:01:24,667 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
01:01:24,671 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 1 retries took 3.6695818279404193. input_tokens=34, output_tokens=513
01:01:31,449 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
01:01:31,450 graphrag.llm.base.rate_limiting_llm WARNING Process failed to invoke LLM 6/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 14 seconds. Follow recommendation? True
01:01:40,339 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
01:01:40,340 graphrag.llm.base.rate_limiting_llm WARNING Process failed to invoke LLM 4/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 5 seconds. Follow recommendation? True
01:01:49,279 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
01:01:49,281 graphrag.llm.base.rate_limiting_llm WARNING Process failed to invoke LLM 6/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 13 seconds. Follow recommendation? True
01:01:50,222 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
01:01:50,225 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 1 retries took 3.042473889887333. input_tokens=34, output_tokens=309
01:01:58,852 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
01:01:58,854 graphrag.llm.base.rate_limiting_llm WARNING Process failed to invoke LLM 6/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 3 seconds. Follow recommendation? True
01:02:12,496 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
01:02:12,500 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 1 retries took 5.203104828950018. input_tokens=2935, output_tokens=828
01:02:12,689 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
01:02:12,691 graphrag.llm.base.rate_limiting_llm WARNING extract-continuation-0 failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 9 seconds. Follow recommendation? True
01:02:24,827 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
01:02:24,830 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 4 retries took 4.175174827920273. input_tokens=2936, output_tokens=560
01:02:25,20 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
01:02:25,22 graphrag.llm.base.rate_limiting_llm WARNING extract-continuation-0 failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 23 seconds. Follow recommendation? True
01:02:29,574 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
01:02:29,575 graphrag.llm.base.rate_limiting_llm WARNING Process failed to invoke LLM 7/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 19 seconds. Follow recommendation? True
01:02:29,686 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
01:02:32,615 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 1 retries took 6.304609715938568. input_tokens=34, output_tokens=974
01:02:41,884 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
01:02:41,885 graphrag.llm.base.rate_limiting_llm WARNING Process failed to invoke LLM 3/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 6 seconds. Follow recommendation? True
01:02:51,8 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
01:02:51,11 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 1 retries took 1.7170318278949708. input_tokens=34, output_tokens=208
01:02:51,104 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
01:02:51,106 graphrag.llm.base.rate_limiting_llm WARNING Process failed to invoke LLM 2/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 17 seconds. Follow recommendation? True
01:03:00,294 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
01:03:00,296 graphrag.llm.base.rate_limiting_llm WARNING Process failed to invoke LLM 5/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 8 seconds. Follow recommendation? True
01:03:11,551 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
01:03:11,555 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 4 retries took 2.904399403836578. input_tokens=2936, output_tokens=457
01:03:11,660 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
01:03:11,662 graphrag.llm.base.rate_limiting_llm WARNING extract-continuation-0 failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 10 seconds. Follow recommendation? True
01:03:19,309 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
01:03:19,311 graphrag.llm.base.rate_limiting_llm WARNING Process failed to invoke LLM 4/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 2 seconds. Follow recommendation? True
01:03:25,566 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
01:03:25,570 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 1 retries took 2.6955208550207317. input_tokens=34, output_tokens=420
01:03:34,732 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
01:03:34,736 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 4 retries took 5.217501338105649. input_tokens=2936, output_tokens=586
01:03:34,928 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
01:03:34,930 graphrag.llm.base.rate_limiting_llm WARNING extract-continuation-0 failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 15 seconds. Follow recommendation? True
01:03:40,842 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
01:03:40,844 graphrag.llm.base.rate_limiting_llm WARNING Process failed to invoke LLM 7/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 9 seconds. Follow recommendation? True
01:03:49,660 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
01:03:49,662 graphrag.llm.base.rate_limiting_llm WARNING Process failed to invoke LLM 10/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 1 seconds. Follow recommendation? True
01:03:50,664 root ERROR error extracting graph
Traceback (most recent call last):
  File "/opt/miniconda3/envs/affine-project-env/lib/python3.12/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py", line 122, in __call__
    result = await self._process_document(text, prompt_variables)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/miniconda3/envs/affine-project-env/lib/python3.12/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py", line 150, in _process_document
    response = await self._llm(
               ^^^^^^^^^^^^^^^^
  File "/opt/miniconda3/envs/affine-project-env/lib/python3.12/site-packages/graphrag/llm/openai/json_parsing_llm.py", line 34, in __call__
    result = await self._delegate(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/miniconda3/envs/affine-project-env/lib/python3.12/site-packages/graphrag/llm/openai/openai_token_replacing_llm.py", line 37, in __call__
    return await self._delegate(input, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/miniconda3/envs/affine-project-env/lib/python3.12/site-packages/graphrag/llm/openai/openai_history_tracking_llm.py", line 33, in __call__
    output = await self._delegate(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/miniconda3/envs/affine-project-env/lib/python3.12/site-packages/graphrag/llm/base/caching_llm.py", line 96, in __call__
    result = await self._delegate(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/miniconda3/envs/affine-project-env/lib/python3.12/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 177, in __call__
    result, start = await execute_with_retry()
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/miniconda3/envs/affine-project-env/lib/python3.12/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 159, in execute_with_retry
    async for attempt in retryer:
  File "/opt/miniconda3/envs/affine-project-env/lib/python3.12/site-packages/tenacity/asyncio/__init__.py", line 166, in __anext__
    do = await self.iter(retry_state=self._retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/miniconda3/envs/affine-project-env/lib/python3.12/site-packages/tenacity/asyncio/__init__.py", line 153, in iter
    result = await action(retry_state)
             ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/miniconda3/envs/affine-project-env/lib/python3.12/site-packages/tenacity/_utils.py", line 99, in inner
    return call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/opt/miniconda3/envs/affine-project-env/lib/python3.12/site-packages/tenacity/__init__.py", line 418, in exc_check
    raise retry_exc.reraise()
          ^^^^^^^^^^^^^^^^^^^
  File "/opt/miniconda3/envs/affine-project-env/lib/python3.12/site-packages/tenacity/__init__.py", line 185, in reraise
    raise self.last_attempt.result()
          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/miniconda3/envs/affine-project-env/lib/python3.12/concurrent/futures/_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "/opt/miniconda3/envs/affine-project-env/lib/python3.12/concurrent/futures/_base.py", line 401, in __get_result
    raise self._exception
  File "/opt/miniconda3/envs/affine-project-env/lib/python3.12/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 165, in execute_with_retry
    return await do_attempt(), start
           ^^^^^^^^^^^^^^^^^^
  File "/opt/miniconda3/envs/affine-project-env/lib/python3.12/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 151, in do_attempt
    await sleep_for(sleep_time)
  File "/opt/miniconda3/envs/affine-project-env/lib/python3.12/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 147, in do_attempt
    return await self._delegate(input, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/miniconda3/envs/affine-project-env/lib/python3.12/site-packages/graphrag/llm/base/base_llm.py", line 50, in __call__
    return await self._invoke(input, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/miniconda3/envs/affine-project-env/lib/python3.12/site-packages/graphrag/llm/base/base_llm.py", line 54, in _invoke
    output = await self._execute_llm(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/miniconda3/envs/affine-project-env/lib/python3.12/site-packages/graphrag/llm/openai/openai_chat_llm.py", line 53, in _execute_llm
    completion = await self.client.chat.completions.create(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/miniconda3/envs/affine-project-env/lib/python3.12/site-packages/openai/resources/chat/completions.py", line 1490, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/opt/miniconda3/envs/affine-project-env/lib/python3.12/site-packages/openai/_base_client.py", line 1831, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/miniconda3/envs/affine-project-env/lib/python3.12/site-packages/openai/_base_client.py", line 1525, in request
    return await self._request(
           ^^^^^^^^^^^^^^^^^^^^
  File "/opt/miniconda3/envs/affine-project-env/lib/python3.12/site-packages/openai/_base_client.py", line 1626, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the Chatcompletions_Create Operation under Azure OpenAI API version 2023-03-15-preview have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}
01:03:50,673 graphrag.index.reporting.file_workflow_callbacks INFO Entity Extraction Error details={'doc_index': 0, 'text': 'vendors that individually represented 10% or more of total vendor non-trade receivables, which accounted for 46% and 18%. As of September 30, 2023, the Company had two vendors that individually represented 10% or more of total vendor non-trade receivables, which accounted for 48% and 23%.\n\nNote 5  Condensed Consolidated Financial Statement Details\n\nThe following table shows the Companys condensed consolidated financial statement details as of June 29, 2024 and September 30, 2023 (in millions):\n\nProperty, Plant and Equipment, Net\nThis table presents the balance sheet line item "Property, Plant and Equipment, Net" for two different dates: June 29, 2024 and September 30, 202*. The table shows the gross value of property, plant and equipment, the accumulated depreciation, and the resulting net value.  The net value is calculated by subtracting the accumulated depreciation from the gross value. The table shows a slight decrease in the net value of property, plant and equipment from June 29, 2024 to September 30, 202*. \n\n<table><thead><tr><th></th><th>June 29, 2024</th><th>September 30, 202</th></tr></thead><tbody><tr><td>Gross property, plant and equipment</td><td>$ 117,129</td><td>$ 114,599</td></tr><tr><td>Accumulated depreciation</td><td>(72,627)</td><td>(70,884)</td></tr><tr><td>Total property, plant and equipment, net</td><td>$ 44,502</td><td>$ 43,715</td></tr></tbody></table>\nNote 6  Income Taxes\n\nEuropean Commission State Aid Decision\n\nOn August 30, 2016, the European Commission (the Commission) announced its decision that Ireland granted state aid to the Company by providing tax opinions in 1991 and 2007 concerning the tax allocation of profits of the Irish branches of two subsidiaries of the Company (the State Aid Decision). The State Aid Decision ordered Ireland to calculate and recover additional taxes from the Company for the period June 2003 through December 2014. Irish legislative changes, effective as of January 2015, eliminated the application of the tax opinions from that date forward. The Company and Ireland appealed the State Aid Decision to the General Court of the Court of Justice of the European Union (the General Court). On July 15, 2020, the General Court annulled the State Aid Decision. On September 25, 2020, the Commission appealed the General Courts decision to the European Court of Justice (the ECJ) and a hearing was held on May 23, 2023. A decision from the ECJ is expected in the fourth quarter of 2024. The Company believes it would be eligible to claim a U.S. foreign tax credit for a portion of any incremental Irish corporate income taxes potentially due related to the State Aid Decision.\n\nNote 7  Debt\n\nCommercial Paper\n\nThe Company issues unsecured short-term promissory notes pursuant to a commercial paper program. The Company uses net proceeds from the commercial paper program for general corporate purposes, including dividends and share repurchases. As of June 29, 2024 and September 30, 2023, the Company had $3.0 billion and $6.0 billion of commercial paper outstanding, respectively. The following table provides a summary of cash flows associated with the issuance and maturities of commercial paper for the nine months ended June 29, 2024 and July 1, 2023 (in millions):\nThis table summarizes the cash flows associated with the issuance and maturities of commercial paper for the nine months ended June 29, 2024 and July 1, 2023. It breaks down the repayments of commercial paper by maturity period (90 days or less and greater than 90 days) and shows the total repayments for each period.  The table shows that the company repaid $2.985 billion in commercial paper during the nine months ended June 29, 2024, while it repaid $5.971 billion during the nine months ended July 1, 2023. The table also shows that the company had no repayments of commercial paper with a maturity greater than 90 days during the nine months ended June 29, 2024. \n\n<table><thead><tr><th></th><th colspan="2">Nine Months Ended</th></tr><tr><th></th><th>June 29, 2024</th><th>July 1, 2023</th></tr></thead><tbody><tr><td colspan="3">Maturities 90 days or less:</td></tr><tr><td>Repayments of commercial paper, net</td><td>$ (2,985)</td><td>$ (3,326)</td></tr><tr><td colspan="3">Maturities greater than 90 days:</td></tr><tr><td>Repayments of commercial paper</td><td></td><td>(2,645)</td></tr><tr><td>Total repayments of commercial paper, net</td><td>$ (2,985)</td><td>$ (5,971)</td></tr></tbody></table>\nTerm Debt\n\nAs of June 29, 2024 and September 30, 2023, the Company had outstanding fixed-rate notes with varying maturities for an aggregate carrying amount of $98.3 billion and $105.1 billion, respectively (collectively the Notes). As of June 29, 202'}
01:03:52,566 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
01:03:52,569 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 1 retries took 1.1735277238767594. input_tokens=34, output_tokens=160
01:03:59,157 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
01:03:59,159 graphrag.llm.base.rate_limiting_llm WARNING Process failed to invoke LLM 7/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 10 seconds. Follow recommendation? True
01:04:07,974 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
01:04:07,976 graphrag.llm.base.rate_limiting_llm WARNING Process failed to invoke LLM 8/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 2 seconds. Follow recommendation? True
01:04:21,450 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
01:04:21,453 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 3 retries took 5.017717850161716. input_tokens=2936, output_tokens=549
01:04:21,646 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
01:04:21,647 graphrag.llm.base.rate_limiting_llm WARNING extract-continuation-0 failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 2 seconds. Follow recommendation? True
01:04:26,723 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
01:04:26,724 graphrag.llm.base.rate_limiting_llm WARNING Process failed to invoke LLM 8/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 3 seconds. Follow recommendation? True
01:04:27,384 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
01:04:27,387 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 1 retries took 1.798434094991535. input_tokens=34, output_tokens=251
01:04:39,819 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
01:04:39,823 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 7 retries took 3.6174054259900004. input_tokens=2936, output_tokens=469
01:04:39,931 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
01:04:39,933 graphrag.llm.base.rate_limiting_llm WARNING extract-continuation-0 failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 12 seconds. Follow recommendation? True
01:04:45,973 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
01:04:45,975 graphrag.llm.base.rate_limiting_llm WARNING Process failed to invoke LLM 8/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 6 seconds. Follow recommendation? True
01:04:55,656 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
01:04:55,657 graphrag.llm.base.rate_limiting_llm WARNING Process failed to invoke LLM 6/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 22 seconds. Follow recommendation? True
01:04:56,782 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
01:04:56,785 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 1 retries took 2.9109949979465455. input_tokens=34, output_tokens=299
01:05:06,45 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
01:05:06,47 graphrag.llm.base.rate_limiting_llm WARNING Process failed to invoke LLM 3/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 11 seconds. Follow recommendation? True
01:05:14,782 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
01:05:14,783 graphrag.llm.base.rate_limiting_llm WARNING Process failed to invoke LLM 9/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 3 seconds. Follow recommendation? True
01:05:27,220 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
01:05:27,224 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 8 retries took 3.9839020899962634. input_tokens=2936, output_tokens=539
01:05:30,376 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
01:05:30,379 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 3.128689190838486. input_tokens=34, output_tokens=440
01:05:39,647 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
01:05:39,651 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 6 retries took 3.1742719057947397. input_tokens=2936, output_tokens=426
01:05:39,838 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
01:05:39,840 graphrag.llm.base.rate_limiting_llm WARNING extract-continuation-0 failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 15 seconds. Follow recommendation? True
01:05:45,775 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
01:05:45,777 graphrag.llm.base.rate_limiting_llm WARNING Process failed to invoke LLM 10/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 9 seconds. Follow recommendation? True
01:05:54,779 root ERROR error extracting graph
Traceback (most recent call last):
  File "/opt/miniconda3/envs/affine-project-env/lib/python3.12/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py", line 122, in __call__
    result = await self._process_document(text, prompt_variables)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/miniconda3/envs/affine-project-env/lib/python3.12/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py", line 150, in _process_document
    response = await self._llm(
               ^^^^^^^^^^^^^^^^
  File "/opt/miniconda3/envs/affine-project-env/lib/python3.12/site-packages/graphrag/llm/openai/json_parsing_llm.py", line 34, in __call__
    result = await self._delegate(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/miniconda3/envs/affine-project-env/lib/python3.12/site-packages/graphrag/llm/openai/openai_token_replacing_llm.py", line 37, in __call__
    return await self._delegate(input, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/miniconda3/envs/affine-project-env/lib/python3.12/site-packages/graphrag/llm/openai/openai_history_tracking_llm.py", line 33, in __call__
    output = await self._delegate(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/miniconda3/envs/affine-project-env/lib/python3.12/site-packages/graphrag/llm/base/caching_llm.py", line 96, in __call__
    result = await self._delegate(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/miniconda3/envs/affine-project-env/lib/python3.12/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 177, in __call__
    result, start = await execute_with_retry()
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/miniconda3/envs/affine-project-env/lib/python3.12/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 159, in execute_with_retry
    async for attempt in retryer:
  File "/opt/miniconda3/envs/affine-project-env/lib/python3.12/site-packages/tenacity/asyncio/__init__.py", line 166, in __anext__
    do = await self.iter(retry_state=self._retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/miniconda3/envs/affine-project-env/lib/python3.12/site-packages/tenacity/asyncio/__init__.py", line 153, in iter
    result = await action(retry_state)
             ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/miniconda3/envs/affine-project-env/lib/python3.12/site-packages/tenacity/_utils.py", line 99, in inner
    return call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/opt/miniconda3/envs/affine-project-env/lib/python3.12/site-packages/tenacity/__init__.py", line 418, in exc_check
    raise retry_exc.reraise()
          ^^^^^^^^^^^^^^^^^^^
  File "/opt/miniconda3/envs/affine-project-env/lib/python3.12/site-packages/tenacity/__init__.py", line 185, in reraise
    raise self.last_attempt.result()
          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/miniconda3/envs/affine-project-env/lib/python3.12/concurrent/futures/_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "/opt/miniconda3/envs/affine-project-env/lib/python3.12/concurrent/futures/_base.py", line 401, in __get_result
    raise self._exception
  File "/opt/miniconda3/envs/affine-project-env/lib/python3.12/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 165, in execute_with_retry
    return await do_attempt(), start
           ^^^^^^^^^^^^^^^^^^
  File "/opt/miniconda3/envs/affine-project-env/lib/python3.12/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 151, in do_attempt
    await sleep_for(sleep_time)
  File "/opt/miniconda3/envs/affine-project-env/lib/python3.12/site-packages/graphrag/llm/base/rate_limiting_llm.py", line 147, in do_attempt
    return await self._delegate(input, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/miniconda3/envs/affine-project-env/lib/python3.12/site-packages/graphrag/llm/base/base_llm.py", line 50, in __call__
    return await self._invoke(input, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/miniconda3/envs/affine-project-env/lib/python3.12/site-packages/graphrag/llm/base/base_llm.py", line 54, in _invoke
    output = await self._execute_llm(input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/miniconda3/envs/affine-project-env/lib/python3.12/site-packages/graphrag/llm/openai/openai_chat_llm.py", line 53, in _execute_llm
    completion = await self.client.chat.completions.create(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/miniconda3/envs/affine-project-env/lib/python3.12/site-packages/openai/resources/chat/completions.py", line 1490, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/opt/miniconda3/envs/affine-project-env/lib/python3.12/site-packages/openai/_base_client.py", line 1831, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/miniconda3/envs/affine-project-env/lib/python3.12/site-packages/openai/_base_client.py", line 1525, in request
    return await self._request(
           ^^^^^^^^^^^^^^^^^^^^
  File "/opt/miniconda3/envs/affine-project-env/lib/python3.12/site-packages/openai/_base_client.py", line 1626, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the Chatcompletions_Create Operation under Azure OpenAI API version 2023-03-15-preview have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.'}}
01:05:54,787 graphrag.index.reporting.file_workflow_callbacks INFO Entity Extraction Error details={'doc_index': 0, 'text': '62,158</th><th>June 29, 2024\n $ 62,146</th><th>July 1, 2023\n $ 50,672</th></tr></thead><tbody><tr><td colspan="5">Common stock and additional paid-in capital:</td></tr><tr><td>Beginning balances</td><td>78,815</td><td>69,568</td><td>73,812</td><td>64,849</td></tr><tr><td>Common stock issued</td><td></td><td></td><td>752</td><td>690</td></tr><tr><td>Common stock withheld related to net share settlement of awards</td><td></td><td></td><td></td><td></td></tr><tr><td>equity Share-based compensation</td><td>(1,920) 2,955</td><td>(1,595) 2,694</td><td>(3,802) 9,088</td><td>(3,310) \n 8,438</td></tr><tr><td>Ending balances</td><td>79,850</td><td>70,667</td><td>79,850</td><td>70,667</td></tr><tr><td colspan="5">Retained earnings/(Accumulated deficit):</td></tr><tr><td>Beginning balances</td><td>4,339</td><td>4,336</td><td>(214)</td><td>(3,068)</td></tr><tr><td>Net income</td><td>21,448</td><td>19,881</td><td>79,000</td><td>74,039</td></tr><tr><td>Dividends and dividend equivalents declared</td><td>(3,864)</td><td>(3,811)</td><td>(11,384)</td><td>(11,207)</td></tr><tr><td>Common stock withheld related to net share settlement of equity awards</td><td>(428)</td><td>(858)</td><td>(1,517)</td><td>(1,988)</td></tr><tr><td>Common stock repurchased</td><td>(26,221)</td><td>(18,140)</td><td>(70,611)</td><td>(56,368)</td></tr><tr><td>Ending balances</td><td>(4,726)</td><td>1,408</td><td>(4,726)</td><td>1,408</td></tr><tr><td colspan="5">Accumulated other comprehensive income/(loss):</td></tr><tr><td>Beginning balances</td><td>(8,960)</td><td>(11,746)</td><td>(11,452)</td><td>(11,109)</td></tr><tr><td>Other comprehensive income/(loss)</td><td>544</td><td>(55)</td><td>3,036</td><td>(692)</td></tr><tr><td>Ending balances</td><td>(8,416)</td><td>(11,801)</td><td>(8,416)</td><td>(11,801)</td></tr><tr><td>Total shareholders equity, ending balances</td><td>66,708 $</td><td>$ 60,274</td><td>$ 66,708</td><td>$ 60,274</td></tr><tr><td>Nividende and dividend eaiiivalante declared nar ehare ar RS</td><td>0N 25</td><td>no4</td><td> N7</td><td> 0 70</td></tr></tbody></table>\nDividends and dividend equivalents declared per share or RSU $\n\nSee accompanying Notes to Condensed Consolidated Financial Statements.\n\nApple Inc. CONDENSED CONSOLIDATED STATEMENTS OF CASH FLOWS (Unaudited)\n\n(In millions)\nThis table presents Apple Inc.\'s Condensed Consolidated Statements of Cash Flows for the nine-month periods ending June 29, 2024 and July 1, 2023 (in millions of dollars). It details the company\'s cash flow activities categorized into three sections: operating, investing, and financing. \n\nFor each category, the table shows the individual components that contribute to the net cash flow generated or used. For example, under operating activities, it includes net income, adjustments to reconcile net income to cash flow, and changes in operating assets and liabilities. Similarly, investing activities include details like purchases and sales of marketable securities, payments for property, plant, and equipment, and other investing activities. Financing activities encompass payments for taxes, dividends, stock repurchases, debt issuance and repayments, and other financing activities. \n\nThe table concludes with the net increase or decrease in cash, cash equivalents, and restricted cash for each period, as well as the ending balances for both periods. It also includes a supplemental cash flow disclosure, though the content of that section is not clear from the provided information. \n\n<table><thead><tr><th></th><th colspan="2">Nine Months Ended</th></tr><tr><th></th><th>June 29, 2024</th><th>July 1, 2023</th></tr></thead><tbody><tr><td>Cash, cash equivalents and restricted cash, beginning balances</td><td>30,737 $</td><'}
01:05:56,579 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
01:05:56,581 graphrag.llm.base.rate_limiting_llm WARNING extract-continuation-0 failed to invoke LLM 2/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 28 seconds. Follow recommendation? True
01:05:56,887 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
01:05:56,890 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 8 retries took 2.6567653859965503. input_tokens=2936, output_tokens=380
01:05:56,998 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
01:05:56,999 graphrag.llm.base.rate_limiting_llm WARNING extract-continuation-0 failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 27 seconds. Follow recommendation? True
01:06:06,185 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
01:06:06,186 graphrag.llm.base.rate_limiting_llm WARNING Process failed to invoke LLM 4/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 18 seconds. Follow recommendation? True
01:06:29,887 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
01:06:29,891 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 1 retries took 4.450502797961235. input_tokens=34, output_tokens=677
01:06:30,300 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
01:06:30,303 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 2 retries took 2.9589256439357996. input_tokens=34, output_tokens=387
01:06:32,661 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
01:06:32,663 graphrag.llm.base.rate_limiting_llm WARNING Process failed to invoke LLM 5/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 5 seconds. Follow recommendation? True
01:06:54,396 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
01:06:54,400 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 5 retries took 6.719298150157556. input_tokens=2936, output_tokens=849
01:06:54,590 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
01:06:54,591 graphrag.llm.base.rate_limiting_llm WARNING extract-continuation-0 failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 1 seconds. Follow recommendation? True
01:07:01,190 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
01:07:01,193 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 1 retries took 4.305315159959719. input_tokens=34, output_tokens=720
01:07:01,227 datashaper.workflow.workflow INFO executing verb merge_graphs
01:07:01,289 graphrag.index.emit.parquet_table_emitter INFO emitting parquet table create_base_extracted_entities.parquet
01:07:01,595 graphrag.index.run.workflow INFO dependencies for create_summarized_entities: ['create_base_extracted_entities']
01:07:01,601 graphrag.utils.storage INFO read table from storage: create_base_extracted_entities.parquet
01:07:01,635 datashaper.workflow.workflow INFO executing verb summarize_descriptions
01:07:02,231 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
01:07:02,233 graphrag.llm.base.rate_limiting_llm WARNING summarize failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 24 seconds. Follow recommendation? True
01:07:02,523 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
01:07:02,525 graphrag.llm.base.rate_limiting_llm WARNING summarize failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 24 seconds. Follow recommendation? True
01:07:02,527 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
01:07:02,528 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
01:07:02,529 graphrag.llm.base.rate_limiting_llm WARNING summarize failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 24 seconds. Follow recommendation? True
01:07:02,529 graphrag.llm.base.rate_limiting_llm WARNING summarize failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 24 seconds. Follow recommendation? True
01:07:02,537 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
01:07:02,538 graphrag.llm.base.rate_limiting_llm WARNING summarize failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 24 seconds. Follow recommendation? True
01:07:02,563 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
01:07:02,565 graphrag.llm.base.rate_limiting_llm WARNING summarize failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 24 seconds. Follow recommendation? True
01:07:02,567 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
01:07:02,569 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
01:07:02,570 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
01:07:02,571 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
01:07:02,572 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
01:07:02,573 graphrag.llm.base.rate_limiting_llm WARNING summarize failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 24 seconds. Follow recommendation? True
01:07:02,573 graphrag.llm.base.rate_limiting_llm WARNING summarize failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 24 seconds. Follow recommendation? True
01:07:02,574 graphrag.llm.base.rate_limiting_llm WARNING summarize failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 24 seconds. Follow recommendation? True
01:07:02,575 graphrag.llm.base.rate_limiting_llm WARNING summarize failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 24 seconds. Follow recommendation? True
01:07:02,575 graphrag.llm.base.rate_limiting_llm WARNING summarize failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 24 seconds. Follow recommendation? True
01:07:02,576 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
01:07:02,577 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
01:07:02,577 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
01:07:02,578 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
01:07:02,578 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
01:07:02,578 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
01:07:02,579 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
01:07:02,579 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
01:07:02,579 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
01:07:02,580 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
01:07:02,580 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
01:07:02,581 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
01:07:02,581 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
01:07:02,581 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
01:07:02,582 graphrag.llm.base.rate_limiting_llm WARNING summarize failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 24 seconds. Follow recommendation? True
01:07:02,582 graphrag.llm.base.rate_limiting_llm WARNING summarize failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 24 seconds. Follow recommendation? True
01:07:02,583 graphrag.llm.base.rate_limiting_llm WARNING summarize failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 24 seconds. Follow recommendation? True
01:07:02,583 graphrag.llm.base.rate_limiting_llm WARNING summarize failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 24 seconds. Follow recommendation? True
01:07:02,584 graphrag.llm.base.rate_limiting_llm WARNING summarize failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 24 seconds. Follow recommendation? True
01:07:02,584 graphrag.llm.base.rate_limiting_llm WARNING summarize failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 24 seconds. Follow recommendation? True
01:07:02,585 graphrag.llm.base.rate_limiting_llm WARNING summarize failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 24 seconds. Follow recommendation? True
01:07:02,585 graphrag.llm.base.rate_limiting_llm WARNING summarize failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 24 seconds. Follow recommendation? True
01:07:02,586 graphrag.llm.base.rate_limiting_llm WARNING summarize failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 24 seconds. Follow recommendation? True
01:07:02,586 graphrag.llm.base.rate_limiting_llm WARNING summarize failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 24 seconds. Follow recommendation? True
01:07:02,587 graphrag.llm.base.rate_limiting_llm WARNING summarize failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 24 seconds. Follow recommendation? True
01:07:02,587 graphrag.llm.base.rate_limiting_llm WARNING summarize failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 24 seconds. Follow recommendation? True
01:07:02,588 graphrag.llm.base.rate_limiting_llm WARNING summarize failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 24 seconds. Follow recommendation? True
01:07:02,588 graphrag.llm.base.rate_limiting_llm WARNING summarize failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 24 seconds. Follow recommendation? True
01:07:28,505 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
01:07:28,507 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 1 retries took 0.772454421967268. input_tokens=161, output_tokens=50
01:07:28,569 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
01:07:28,570 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 1 retries took 0.9095088629983366. input_tokens=176, output_tokens=67
01:07:28,660 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
01:07:28,662 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 1 retries took 0.7988343990873545. input_tokens=165, output_tokens=47
01:07:28,685 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
01:07:28,688 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 1 retries took 0.832634663907811. input_tokens=279, output_tokens=73
01:07:28,695 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
01:07:28,696 graphrag.llm.base.rate_limiting_llm WARNING summarize failed to invoke LLM 2/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 20 seconds. Follow recommendation? True
01:07:28,755 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
01:07:28,757 graphrag.llm.base.rate_limiting_llm WARNING summarize failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 20 seconds. Follow recommendation? True
01:07:28,761 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
01:07:28,763 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 1 retries took 0.8756173730362207. input_tokens=164, output_tokens=65
01:07:28,777 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
01:07:28,785 graphrag.llm.base.rate_limiting_llm WARNING summarize failed to invoke LLM 2/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 20 seconds. Follow recommendation? True
01:07:28,786 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
01:07:28,794 graphrag.llm.base.rate_limiting_llm WARNING summarize failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 20 seconds. Follow recommendation? True
01:07:28,794 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
01:07:28,795 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
01:07:28,796 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 1 retries took 1.0081521000247449. input_tokens=165, output_tokens=70
01:07:28,798 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 1 retries took 1.1236883089877665. input_tokens=195, output_tokens=105
01:07:28,817 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
01:07:28,819 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 1 retries took 0.7503383341245353. input_tokens=154, output_tokens=28
01:07:28,857 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
01:07:28,858 graphrag.llm.base.rate_limiting_llm WARNING summarize failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 20 seconds. Follow recommendation? True
01:07:28,860 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
01:07:28,861 graphrag.llm.base.rate_limiting_llm WARNING summarize failed to invoke LLM 2/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 20 seconds. Follow recommendation? True
01:07:28,885 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
01:07:28,887 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 1 retries took 0.9733529018703848. input_tokens=176, output_tokens=64
01:07:28,897 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
01:07:28,898 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
01:07:28,899 graphrag.llm.base.rate_limiting_llm WARNING summarize failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 20 seconds. Follow recommendation? True
01:07:28,899 graphrag.llm.base.rate_limiting_llm WARNING summarize failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 20 seconds. Follow recommendation? True
01:07:28,919 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
01:07:28,919 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
01:07:28,920 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
01:07:28,921 graphrag.llm.base.rate_limiting_llm WARNING summarize failed to invoke LLM 2/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 20 seconds. Follow recommendation? True
01:07:28,921 graphrag.llm.base.rate_limiting_llm WARNING summarize failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 20 seconds. Follow recommendation? True
01:07:28,922 graphrag.llm.base.rate_limiting_llm WARNING summarize failed to invoke LLM 2/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 20 seconds. Follow recommendation? True
01:07:28,950 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
01:07:28,952 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 1 retries took 1.027017927961424. input_tokens=202, output_tokens=93
01:07:28,958 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
01:07:28,959 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 1 retries took 1.0875967079773545. input_tokens=180, output_tokens=60
01:07:28,965 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
01:07:28,967 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 1 retries took 1.0737247348297387. input_tokens=204, output_tokens=103
01:07:28,991 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
01:07:28,992 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
01:07:28,996 graphrag.llm.base.rate_limiting_llm WARNING summarize failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 20 seconds. Follow recommendation? True
01:07:28,997 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 1 retries took 1.1955726169981062. input_tokens=212, output_tokens=91
01:07:29,2 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
01:07:29,3 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 1 retries took 0.7763984960038215. input_tokens=157, output_tokens=46
01:07:29,54 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
01:07:29,58 graphrag.llm.base.rate_limiting_llm WARNING summarize failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 20 seconds. Follow recommendation? True
01:07:29,60 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
01:07:29,61 graphrag.llm.base.rate_limiting_llm WARNING summarize failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 20 seconds. Follow recommendation? True
01:07:29,62 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
01:07:29,63 graphrag.llm.base.rate_limiting_llm WARNING summarize failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 20 seconds. Follow recommendation? True
01:07:29,70 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
01:07:29,72 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 0.5647357818670571. input_tokens=156, output_tokens=63
01:07:29,76 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
01:07:29,78 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 1 retries took 0.8208318429533392. input_tokens=162, output_tokens=56
01:07:29,78 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
01:07:29,83 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 1 retries took 0.9625823888927698. input_tokens=192, output_tokens=77
01:07:29,91 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
01:07:29,92 graphrag.llm.base.rate_limiting_llm WARNING summarize failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 20 seconds. Follow recommendation? True
01:07:29,93 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
01:07:29,95 graphrag.llm.base.rate_limiting_llm WARNING summarize failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 20 seconds. Follow recommendation? True
01:07:29,136 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
01:07:29,140 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 1 retries took 0.9191521268803626. input_tokens=167, output_tokens=56
01:07:29,177 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
01:07:29,178 graphrag.llm.base.rate_limiting_llm WARNING summarize failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 19 seconds. Follow recommendation? True
01:07:29,178 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
01:07:29,179 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
01:07:29,180 graphrag.llm.base.rate_limiting_llm WARNING summarize failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 19 seconds. Follow recommendation? True
01:07:29,180 graphrag.llm.base.rate_limiting_llm WARNING summarize failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 19 seconds. Follow recommendation? True
01:07:29,234 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
01:07:29,236 graphrag.llm.base.rate_limiting_llm WARNING summarize failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 19 seconds. Follow recommendation? True
01:07:29,265 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
01:07:29,269 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 1 retries took 1.3509142219554633. input_tokens=304, output_tokens=140
01:07:29,365 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
01:07:29,368 graphrag.llm.base.rate_limiting_llm WARNING summarize failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 19 seconds. Follow recommendation? True
01:07:29,515 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
01:07:29,518 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 0.9480168060399592. input_tokens=236, output_tokens=75
01:07:29,612 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
01:07:29,615 graphrag.llm.base.rate_limiting_llm WARNING summarize failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 19 seconds. Follow recommendation? True
01:07:29,701 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
01:07:29,705 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 1 retries took 1.550019372953102. input_tokens=536, output_tokens=196
01:07:29,799 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
01:07:29,802 graphrag.llm.base.rate_limiting_llm WARNING summarize failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 19 seconds. Follow recommendation? True
01:07:30,595 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
01:07:30,599 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 1 retries took 2.5180744668468833. input_tokens=175, output_tokens=66
01:07:30,692 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
01:07:30,695 graphrag.llm.base.rate_limiting_llm WARNING summarize failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 18 seconds. Follow recommendation? True
01:07:50,471 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
01:07:50,472 graphrag.llm.base.rate_limiting_llm WARNING summarize failed to invoke LLM 2/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 7 seconds. Follow recommendation? True
01:07:50,518 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
01:07:50,520 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 1 retries took 0.7864252149593085. input_tokens=172, output_tokens=43
01:07:50,537 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
01:07:50,538 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 1 retries took 0.776790063129738. input_tokens=177, output_tokens=48
01:07:50,573 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
01:07:50,574 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 1 retries took 0.9791226158849895. input_tokens=165, output_tokens=42
01:07:50,615 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
01:07:50,616 graphrag.llm.base.rate_limiting_llm WARNING summarize failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 7 seconds. Follow recommendation? True
01:07:50,627 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
01:07:50,628 graphrag.llm.base.rate_limiting_llm WARNING summarize failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 7 seconds. Follow recommendation? True
01:07:50,656 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
01:07:50,657 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 1 retries took 0.7643412509933114. input_tokens=168, output_tokens=46
01:07:50,665 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
01:07:50,665 graphrag.llm.base.rate_limiting_llm WARNING summarize failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 7 seconds. Follow recommendation? True
01:07:50,672 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
01:07:50,672 graphrag.llm.base.rate_limiting_llm WARNING summarize failed to invoke LLM 2/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 7 seconds. Follow recommendation? True
01:07:50,742 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
01:07:50,742 graphrag.llm.base.rate_limiting_llm WARNING summarize failed to invoke LLM 2/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 7 seconds. Follow recommendation? True
01:07:50,749 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
01:07:50,749 graphrag.llm.base.rate_limiting_llm WARNING summarize failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 7 seconds. Follow recommendation? True
01:07:50,782 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
01:07:50,783 graphrag.llm.base.rate_limiting_llm WARNING summarize failed to invoke LLM 2/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 7 seconds. Follow recommendation? True
01:07:50,784 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
01:07:50,785 graphrag.llm.base.rate_limiting_llm WARNING summarize failed to invoke LLM 2/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 7 seconds. Follow recommendation? True
01:07:50,798 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
01:07:50,799 graphrag.llm.base.rate_limiting_llm WARNING summarize failed to invoke LLM 2/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 7 seconds. Follow recommendation? True
01:07:50,832 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
01:07:50,833 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
01:07:50,834 graphrag.llm.base.rate_limiting_llm WARNING summarize failed to invoke LLM 2/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 7 seconds. Follow recommendation? True
01:07:50,835 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 1 retries took 0.7845951109193265. input_tokens=155, output_tokens=41
01:07:50,839 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
01:07:50,840 graphrag.llm.base.rate_limiting_llm WARNING summarize failed to invoke LLM 2/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 7 seconds. Follow recommendation? True
01:07:50,841 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
01:07:50,842 graphrag.llm.base.rate_limiting_llm WARNING summarize failed to invoke LLM 2/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 7 seconds. Follow recommendation? True
01:07:50,863 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
01:07:50,864 graphrag.llm.base.rate_limiting_llm WARNING summarize failed to invoke LLM 2/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 7 seconds. Follow recommendation? True
01:07:50,897 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
01:07:50,899 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 1 retries took 0.928012718912214. input_tokens=194, output_tokens=84
01:07:50,920 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
01:07:50,921 graphrag.llm.base.rate_limiting_llm WARNING summarize failed to invoke LLM 2/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 7 seconds. Follow recommendation? True
01:07:50,925 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
01:07:50,926 graphrag.llm.base.rate_limiting_llm WARNING summarize failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 7 seconds. Follow recommendation? True
01:07:50,993 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
01:07:50,994 graphrag.llm.base.rate_limiting_llm WARNING summarize failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 7 seconds. Follow recommendation? True
01:07:51,48 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
01:07:51,49 graphrag.llm.base.rate_limiting_llm WARNING summarize failed to invoke LLM 3/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 7 seconds. Follow recommendation? True
01:07:51,57 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
01:07:51,58 graphrag.llm.base.rate_limiting_llm WARNING summarize failed to invoke LLM 2/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 7 seconds. Follow recommendation? True
01:07:51,126 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
01:07:51,128 graphrag.llm.base.rate_limiting_llm WARNING summarize failed to invoke LLM 3/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 6 seconds. Follow recommendation? True
01:07:51,133 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
01:07:51,135 graphrag.llm.base.rate_limiting_llm WARNING summarize failed to invoke LLM 2/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 6 seconds. Follow recommendation? True
01:07:51,162 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
01:07:51,164 graphrag.llm.base.rate_limiting_llm WARNING summarize failed to invoke LLM 2/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 6 seconds. Follow recommendation? True
01:07:51,712 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
01:07:51,714 graphrag.llm.base.rate_limiting_llm WARNING summarize failed to invoke LLM 3/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 6 seconds. Follow recommendation? True
01:07:51,715 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
01:07:51,717 graphrag.llm.base.rate_limiting_llm WARNING summarize failed to invoke LLM 3/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 6 seconds. Follow recommendation? True
01:07:51,973 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
01:07:51,975 graphrag.llm.base.rate_limiting_llm WARNING summarize failed to invoke LLM 3/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 6 seconds. Follow recommendation? True
01:08:00,88 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
01:08:00,90 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 1 retries took 1.0916639550123364. input_tokens=279, output_tokens=116
01:08:00,318 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
01:08:00,319 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 1 retries took 1.3105757988523692. input_tokens=224, output_tokens=115
01:08:00,433 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
01:08:00,434 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 1 retries took 0.9454289639834315. input_tokens=198, output_tokens=88
01:08:00,509 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
01:08:00,511 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 1 retries took 1.121262254891917. input_tokens=199, output_tokens=68
01:08:00,519 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
01:08:00,520 graphrag.llm.base.rate_limiting_llm WARNING summarize failed to invoke LLM 3/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 28 seconds. Follow recommendation? True
01:08:00,527 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
01:08:00,530 graphrag.llm.base.rate_limiting_llm WARNING summarize failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 28 seconds. Follow recommendation? True
01:08:00,606 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
01:08:00,608 graphrag.llm.base.rate_limiting_llm WARNING summarize failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 28 seconds. Follow recommendation? True
01:08:00,621 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
01:08:00,622 graphrag.llm.base.rate_limiting_llm WARNING summarize failed to invoke LLM 3/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 28 seconds. Follow recommendation? True
01:08:00,623 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
01:08:00,624 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
01:08:00,625 graphrag.llm.base.rate_limiting_llm WARNING summarize failed to invoke LLM 3/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 28 seconds. Follow recommendation? True
01:08:00,625 graphrag.llm.base.rate_limiting_llm WARNING summarize failed to invoke LLM 3/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 28 seconds. Follow recommendation? True
01:08:00,640 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
01:08:00,641 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 2 retries took 0.7341319001279771. input_tokens=183, output_tokens=54
01:08:00,649 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
01:08:00,649 graphrag.llm.base.rate_limiting_llm WARNING summarize failed to invoke LLM 3/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 28 seconds. Follow recommendation? True
01:08:00,681 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
01:08:00,682 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 1 retries took 0.9598885818850249. input_tokens=190, output_tokens=49
01:08:00,710 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
01:08:00,711 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
01:08:00,717 graphrag.llm.base.rate_limiting_llm WARNING summarize failed to invoke LLM 3/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 28 seconds. Follow recommendation? True
01:08:00,718 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 0.6270277739968151. input_tokens=173, output_tokens=68
01:08:00,732 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
01:08:00,733 graphrag.llm.base.rate_limiting_llm WARNING summarize failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 28 seconds. Follow recommendation? True
01:08:00,765 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
01:08:00,766 graphrag.llm.base.rate_limiting_llm WARNING summarize failed to invoke LLM 3/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 28 seconds. Follow recommendation? True
01:08:00,774 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
01:08:00,775 graphrag.llm.base.rate_limiting_llm WARNING summarize failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 28 seconds. Follow recommendation? True
01:08:00,804 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
01:08:00,808 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 1 retries took 1.8484706580638885. input_tokens=502, output_tokens=237
01:08:00,815 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
01:08:00,816 graphrag.llm.base.rate_limiting_llm WARNING summarize failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 28 seconds. Follow recommendation? True
01:08:00,832 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
01:08:00,833 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
01:08:00,834 graphrag.llm.base.rate_limiting_llm WARNING summarize failed to invoke LLM 3/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 28 seconds. Follow recommendation? True
01:08:00,834 graphrag.llm.base.rate_limiting_llm WARNING summarize failed to invoke LLM 3/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 28 seconds. Follow recommendation? True
01:08:00,858 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
01:08:00,860 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 2 retries took 0.8701967350207269. input_tokens=203, output_tokens=67
01:08:00,880 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
01:08:00,881 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 0.5614278591237962. input_tokens=178, output_tokens=43
01:08:00,902 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
01:08:00,903 graphrag.llm.base.rate_limiting_llm WARNING summarize failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 28 seconds. Follow recommendation? True
01:08:00,949 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
01:08:00,952 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 2 retries took 0.9376642580609769. input_tokens=188, output_tokens=70
01:08:00,954 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
01:08:00,956 graphrag.llm.base.rate_limiting_llm WARNING summarize failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 28 seconds. Follow recommendation? True
01:08:00,994 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
01:08:00,995 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 2 retries took 0.9519531289115548. input_tokens=178, output_tokens=65
01:08:01,6 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
01:08:01,212 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 2 retries took 0.9903903489466757. input_tokens=187, output_tokens=68
01:08:02,38 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
01:08:02,40 graphrag.llm.base.rate_limiting_llm WARNING summarize failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 27 seconds. Follow recommendation? True
01:08:02,536 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
01:08:02,538 graphrag.llm.base.rate_limiting_llm WARNING summarize failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 26 seconds. Follow recommendation? True
01:08:03,79 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
01:08:03,81 graphrag.llm.base.rate_limiting_llm WARNING summarize failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 26 seconds. Follow recommendation? True
01:08:03,766 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
01:08:03,768 graphrag.llm.base.rate_limiting_llm WARNING summarize failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 25 seconds. Follow recommendation? True
01:08:04,276 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
01:08:04,278 graphrag.llm.base.rate_limiting_llm WARNING summarize failed to invoke LLM 4/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 24 seconds. Follow recommendation? True
01:08:04,898 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
01:08:04,901 graphrag.llm.base.rate_limiting_llm WARNING summarize failed to invoke LLM 4/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 24 seconds. Follow recommendation? True
01:08:05,490 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
01:08:05,492 graphrag.llm.base.rate_limiting_llm WARNING summarize failed to invoke LLM 4/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 23 seconds. Follow recommendation? True
01:08:06,475 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
01:08:06,476 graphrag.llm.base.rate_limiting_llm WARNING summarize failed to invoke LLM 4/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 22 seconds. Follow recommendation? True
01:08:08,225 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
01:08:08,227 graphrag.llm.base.rate_limiting_llm WARNING summarize failed to invoke LLM 4/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 20 seconds. Follow recommendation? True
01:08:30,316 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
01:08:30,318 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 1 retries took 0.7752034889999777. input_tokens=212, output_tokens=41
01:08:30,701 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
01:08:30,702 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 1 retries took 0.8302663459908217. input_tokens=166, output_tokens=41
01:08:30,740 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
01:08:30,741 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 1 retries took 0.7517462249379605. input_tokens=198, output_tokens=38
01:08:30,761 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
01:08:30,762 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 1 retries took 0.8380156711209565. input_tokens=159, output_tokens=51
01:08:30,864 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
01:08:30,867 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 1 retries took 1.0350671601481736. input_tokens=203, output_tokens=68
01:08:30,876 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
01:08:30,878 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 1 retries took 0.939597203861922. input_tokens=225, output_tokens=84
01:08:30,982 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
01:08:30,983 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 1 retries took 0.8520187549293041. input_tokens=177, output_tokens=57
01:08:30,992 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
01:08:30,994 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 0.6750262870918959. input_tokens=162, output_tokens=51
01:08:31,55 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
01:08:31,57 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 1 retries took 0.8267152609769255. input_tokens=185, output_tokens=39
01:08:31,153 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
01:08:31,155 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 0.4525537509471178. input_tokens=166, output_tokens=48
01:08:31,249 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
01:08:31,250 graphrag.llm.base.rate_limiting_llm WARNING summarize failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 19 seconds. Follow recommendation? True
01:08:31,604 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
01:08:31,607 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 0.5470262710005045. input_tokens=168, output_tokens=65
01:08:31,615 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
01:08:31,616 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 0.8751547529827803. input_tokens=225, output_tokens=105
01:08:31,671 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
01:08:31,672 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 1 retries took 1.0372305330820382. input_tokens=243, output_tokens=80
01:08:31,701 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
01:08:31,702 graphrag.llm.base.rate_limiting_llm WARNING summarize failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 19 seconds. Follow recommendation? True
01:08:31,708 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
01:08:31,708 graphrag.llm.base.rate_limiting_llm WARNING summarize failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 19 seconds. Follow recommendation? True
01:08:31,711 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
01:08:31,713 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 1 retries took 1.0220558710861951. input_tokens=246, output_tokens=78
01:08:31,763 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
01:08:31,764 graphrag.llm.base.rate_limiting_llm WARNING summarize failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 19 seconds. Follow recommendation? True
01:08:31,805 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
01:08:31,807 graphrag.llm.base.rate_limiting_llm WARNING summarize failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 19 seconds. Follow recommendation? True
01:08:31,824 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
01:08:31,827 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 0.8313488520216197. input_tokens=158, output_tokens=64
01:08:31,836 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
01:08:31,837 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 0.9584111119620502. input_tokens=254, output_tokens=122
01:08:31,845 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
01:08:31,852 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.088038262212649. input_tokens=253, output_tokens=144
01:08:31,923 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
01:08:31,925 graphrag.llm.base.rate_limiting_llm WARNING summarize failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 19 seconds. Follow recommendation? True
01:08:31,927 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
01:08:31,929 graphrag.llm.base.rate_limiting_llm WARNING summarize failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 19 seconds. Follow recommendation? True
01:08:31,945 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
01:08:31,946 graphrag.llm.base.rate_limiting_llm WARNING summarize failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 19 seconds. Follow recommendation? True
01:08:32,151 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
01:08:32,154 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.2857418269850314. input_tokens=327, output_tokens=163
01:08:32,175 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
01:08:32,177 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 1 retries took 1.4200963410548866. input_tokens=242, output_tokens=167
01:08:32,239 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
01:08:32,242 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.2574166269041598. input_tokens=284, output_tokens=146
01:08:32,247 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
01:08:32,249 graphrag.llm.base.rate_limiting_llm WARNING summarize failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 18 seconds. Follow recommendation? True
01:08:32,266 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
01:08:32,268 graphrag.llm.base.rate_limiting_llm WARNING summarize failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 18 seconds. Follow recommendation? True
01:08:32,756 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
01:08:32,758 graphrag.llm.base.rate_limiting_llm WARNING summarize failed to invoke LLM 4/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 18 seconds. Follow recommendation? True
01:08:33,366 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
01:08:33,368 graphrag.llm.base.rate_limiting_llm WARNING summarize failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 17 seconds. Follow recommendation? True
01:08:33,974 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
01:08:33,976 graphrag.llm.base.rate_limiting_llm WARNING summarize failed to invoke LLM 4/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 17 seconds. Follow recommendation? True
01:08:34,489 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
01:08:34,491 graphrag.llm.base.rate_limiting_llm WARNING summarize failed to invoke LLM 4/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 16 seconds. Follow recommendation? True
01:08:35,33 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
01:08:35,34 graphrag.llm.base.rate_limiting_llm WARNING summarize failed to invoke LLM 4/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 16 seconds. Follow recommendation? True
01:08:35,633 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
01:08:35,635 graphrag.llm.base.rate_limiting_llm WARNING summarize failed to invoke LLM 4/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 15 seconds. Follow recommendation? True
01:08:36,243 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
01:08:36,245 graphrag.llm.base.rate_limiting_llm WARNING summarize failed to invoke LLM 4/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 14 seconds. Follow recommendation? True
01:08:36,823 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
01:08:36,825 graphrag.llm.base.rate_limiting_llm WARNING summarize failed to invoke LLM 4/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 14 seconds. Follow recommendation? True
01:08:37,433 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
01:08:37,435 graphrag.llm.base.rate_limiting_llm WARNING summarize failed to invoke LLM 4/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 13 seconds. Follow recommendation? True
01:08:38,43 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
01:08:38,45 graphrag.llm.base.rate_limiting_llm WARNING summarize failed to invoke LLM 4/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 13 seconds. Follow recommendation? True
01:08:38,637 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
01:08:38,638 graphrag.llm.base.rate_limiting_llm WARNING summarize failed to invoke LLM 5/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 12 seconds. Follow recommendation? True
01:08:39,246 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
01:08:39,248 graphrag.llm.base.rate_limiting_llm WARNING summarize failed to invoke LLM 5/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 11 seconds. Follow recommendation? True
01:08:39,856 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
01:08:39,858 graphrag.llm.base.rate_limiting_llm WARNING summarize failed to invoke LLM 5/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 11 seconds. Follow recommendation? True
01:08:40,466 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
01:08:40,467 graphrag.llm.base.rate_limiting_llm WARNING summarize failed to invoke LLM 5/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 10 seconds. Follow recommendation? True
01:08:41,225 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
01:08:41,226 graphrag.llm.base.rate_limiting_llm WARNING summarize failed to invoke LLM 5/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 9 seconds. Follow recommendation? True
01:08:52,154 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
01:08:52,157 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 1 retries took 0.8517746040597558. input_tokens=189, output_tokens=72
01:08:52,432 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
01:08:52,433 graphrag.llm.base.rate_limiting_llm WARNING summarize failed to invoke LLM 2/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 7 seconds. Follow recommendation? True
01:08:52,438 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
01:08:52,440 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 1 retries took 0.8036021010484546. input_tokens=177, output_tokens=49
01:08:52,532 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
01:08:52,534 graphrag.llm.base.rate_limiting_llm WARNING summarize failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 7 seconds. Follow recommendation? True
01:08:52,561 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
01:08:52,561 graphrag.llm.base.rate_limiting_llm WARNING summarize failed to invoke LLM 2/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 7 seconds. Follow recommendation? True
01:08:52,566 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
01:08:52,567 graphrag.llm.base.rate_limiting_llm WARNING summarize failed to invoke LLM 2/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 7 seconds. Follow recommendation? True
01:08:52,601 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
01:08:52,603 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 1 retries took 1.084691833006218. input_tokens=256, output_tokens=92
01:08:52,642 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
01:08:52,645 graphrag.llm.base.rate_limiting_llm WARNING summarize failed to invoke LLM 2/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 7 seconds. Follow recommendation? True
01:08:52,699 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
01:08:52,701 graphrag.llm.base.rate_limiting_llm WARNING summarize failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 7 seconds. Follow recommendation? True
01:08:52,822 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
01:08:52,824 graphrag.llm.base.rate_limiting_llm WARNING summarize failed to invoke LLM 2/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 7 seconds. Follow recommendation? True
01:08:52,839 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
01:08:52,840 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 1 retries took 0.7441459489054978. input_tokens=173, output_tokens=43
01:08:52,846 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
01:08:52,846 graphrag.llm.base.rate_limiting_llm WARNING summarize failed to invoke LLM 2/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 7 seconds. Follow recommendation? True
01:08:52,918 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
01:08:52,920 graphrag.llm.base.rate_limiting_llm WARNING summarize failed to invoke LLM 2/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 7 seconds. Follow recommendation? True
01:08:52,933 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
01:08:52,935 graphrag.llm.base.rate_limiting_llm WARNING summarize failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 7 seconds. Follow recommendation? True
01:08:52,958 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
01:08:52,961 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 0.8031763930339366. input_tokens=166, output_tokens=84
01:08:53,659 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
01:08:53,661 graphrag.llm.base.rate_limiting_llm WARNING summarize failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 6 seconds. Follow recommendation? True
01:08:59,142 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
01:08:59,146 graphrag.llm.base.rate_limiting_llm WARNING summarize failed to invoke LLM 5/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 1 seconds. Follow recommendation? True
01:08:59,227 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
01:08:59,228 graphrag.llm.base.rate_limiting_llm WARNING summarize failed to invoke LLM 5/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 1 seconds. Follow recommendation? True
01:08:59,237 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
01:08:59,237 graphrag.llm.base.rate_limiting_llm WARNING summarize failed to invoke LLM 5/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 1 seconds. Follow recommendation? True
01:08:59,323 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
01:08:59,324 graphrag.llm.base.rate_limiting_llm WARNING summarize failed to invoke LLM 5/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 1 seconds. Follow recommendation? True
01:08:59,350 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
01:08:59,352 graphrag.llm.base.rate_limiting_llm WARNING summarize failed to invoke LLM 5/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 1 seconds. Follow recommendation? True
01:08:59,922 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
01:08:59,924 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 4 retries took 0.6346640940755606. input_tokens=219, output_tokens=58
01:09:00,370 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
01:09:00,377 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
01:09:00,461 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
01:09:01,313 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
01:09:01,714 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
01:09:02,87 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
01:09:02,386 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
01:09:02,523 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 4 retries took 0.4724280219525099. input_tokens=189, output_tokens=54
01:09:03,711 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
01:09:03,713 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 0.5888757230713964. input_tokens=177, output_tokens=49
01:09:04,315 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 0.4546566070057452. input_tokens=159, output_tokens=48
01:09:04,917 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 4 retries took 0.4963619711343199. input_tokens=173, output_tokens=54
01:09:06,97 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
01:09:06,99 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 5 retries took 0.5813298199791461. input_tokens=167, output_tokens=48
01:09:07,311 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 4 retries took 0.8679064877796918. input_tokens=217, output_tokens=106
01:09:07,441 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
01:09:07,912 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 1 retries took 0.7871995440218598. input_tokens=194, output_tokens=81
01:09:08,513 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 5 retries took 0.4745077691040933. input_tokens=182, output_tokens=59
01:09:09,521 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
01:09:10,369 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
01:09:10,663 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
01:09:10,665 graphrag.llm.base.rate_limiting_llm WARNING summarize failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 20 seconds. Follow recommendation? True
01:09:10,998 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
01:09:11,0 graphrag.llm.base.rate_limiting_llm WARNING summarize failed to invoke LLM 3/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 19 seconds. Follow recommendation? True
01:09:11,608 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
01:09:11,610 graphrag.llm.base.rate_limiting_llm WARNING summarize failed to invoke LLM 3/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 19 seconds. Follow recommendation? True
01:09:12,123 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 5 retries took 1.0766081721521914. input_tokens=580, output_tokens=157
01:09:12,823 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
01:09:12,824 graphrag.llm.base.rate_limiting_llm WARNING summarize failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 18 seconds. Follow recommendation? True
01:09:13,430 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
01:09:13,432 graphrag.llm.base.rate_limiting_llm WARNING summarize failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 17 seconds. Follow recommendation? True
01:09:14,41 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
01:09:14,42 graphrag.llm.base.rate_limiting_llm WARNING summarize failed to invoke LLM 6/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 16 seconds. Follow recommendation? True
01:09:14,651 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
01:09:14,652 graphrag.llm.base.rate_limiting_llm WARNING summarize failed to invoke LLM 2/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 16 seconds. Follow recommendation? True
01:09:15,186 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
01:09:15,188 graphrag.llm.base.rate_limiting_llm WARNING summarize failed to invoke LLM 6/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 15 seconds. Follow recommendation? True
01:09:15,702 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 1 retries took 0.7417564040515572. input_tokens=172, output_tokens=28
01:09:16,399 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
01:09:16,401 graphrag.llm.base.rate_limiting_llm WARNING summarize failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 14 seconds. Follow recommendation? True
01:09:17,9 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
01:09:17,10 graphrag.llm.base.rate_limiting_llm WARNING summarize failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 13 seconds. Follow recommendation? True
01:09:17,524 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 2 retries took 0.4494070888031274. input_tokens=164, output_tokens=42
01:09:18,221 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
01:09:18,222 graphrag.llm.base.rate_limiting_llm WARNING summarize failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 12 seconds. Follow recommendation? True
01:09:18,830 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
01:09:18,832 graphrag.llm.base.rate_limiting_llm WARNING summarize failed to invoke LLM 6/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 12 seconds. Follow recommendation? True
01:09:19,345 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 2 retries took 0.6875255540944636. input_tokens=177, output_tokens=68
01:09:20,41 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
01:09:20,42 graphrag.llm.base.rate_limiting_llm WARNING summarize failed to invoke LLM 6/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 10 seconds. Follow recommendation? True
01:09:20,651 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
01:09:20,652 graphrag.llm.base.rate_limiting_llm WARNING summarize failed to invoke LLM 6/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 10 seconds. Follow recommendation? True
01:09:21,263 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
01:09:21,265 graphrag.llm.base.rate_limiting_llm WARNING summarize failed to invoke LLM 3/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 9 seconds. Follow recommendation? True
01:09:21,870 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
01:09:21,872 graphrag.llm.base.rate_limiting_llm WARNING summarize failed to invoke LLM 6/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 9 seconds. Follow recommendation? True
01:09:22,478 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
01:09:22,479 graphrag.llm.base.rate_limiting_llm WARNING summarize failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 8 seconds. Follow recommendation? True
01:09:23,88 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
01:09:23,90 graphrag.llm.base.rate_limiting_llm WARNING summarize failed to invoke LLM 3/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 7 seconds. Follow recommendation? True
01:09:23,698 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
01:09:23,699 graphrag.llm.base.rate_limiting_llm WARNING summarize failed to invoke LLM 3/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 7 seconds. Follow recommendation? True
01:09:24,309 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
01:09:24,310 graphrag.llm.base.rate_limiting_llm WARNING summarize failed to invoke LLM 2/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 6 seconds. Follow recommendation? True
01:09:24,918 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
01:09:24,919 graphrag.llm.base.rate_limiting_llm WARNING summarize failed to invoke LLM 6/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 5 seconds. Follow recommendation? True
01:09:25,526 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
01:09:25,528 graphrag.llm.base.rate_limiting_llm WARNING summarize failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 5 seconds. Follow recommendation? True
01:09:26,136 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
01:09:26,137 graphrag.llm.base.rate_limiting_llm WARNING summarize failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 4 seconds. Follow recommendation? True
01:09:26,746 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
01:09:26,748 graphrag.llm.base.rate_limiting_llm WARNING summarize failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 4 seconds. Follow recommendation? True
01:09:27,357 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
01:09:27,358 graphrag.llm.base.rate_limiting_llm WARNING summarize failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 3 seconds. Follow recommendation? True
01:09:32,598 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
01:09:32,601 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 1 retries took 0.8322327539790422. input_tokens=169, output_tokens=60
01:09:32,657 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
01:09:32,799 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
01:09:32,850 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
01:09:33,129 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
01:09:33,131 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 1 retries took 0.9778716799337417. input_tokens=172, output_tokens=74
01:09:33,180 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
01:09:33,476 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
01:09:33,594 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
01:09:34,329 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
01:09:34,927 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
01:09:34,929 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 1 retries took 0.5846837980207056. input_tokens=178, output_tokens=48
01:09:36,9 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
01:09:37,13 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
01:09:37,531 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
01:09:37,894 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
01:09:37,974 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 1 retries took 0.8997742480132729. input_tokens=269, output_tokens=127
01:09:38,463 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 1 retries took 1.3482089738827199. input_tokens=378, output_tokens=150
01:09:39,663 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
01:09:39,665 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 0.6000754041597247. input_tokens=168, output_tokens=58
01:09:40,267 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 1 retries took 1.0254354290664196. input_tokens=178, output_tokens=87
01:09:41,479 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 1 retries took 0.9183572591282427. input_tokens=163, output_tokens=62
01:09:41,566 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
01:09:42,666 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
01:09:42,669 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 0.5876097059808671. input_tokens=179, output_tokens=50
01:09:43,271 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 1 retries took 1.2969580749049783. input_tokens=142, output_tokens=45
01:09:44,482 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 0.596973764942959. input_tokens=178, output_tokens=62
01:09:45,865 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
01:09:45,905 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
01:09:46,302 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 1 retries took 0.48114728601649404. input_tokens=174, output_tokens=54
01:09:46,631 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
01:09:46,904 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 1 retries took 1.8177860178984702. input_tokens=457, output_tokens=186
01:09:47,599 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
01:09:47,601 graphrag.llm.base.rate_limiting_llm WARNING summarize failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 5 seconds. Follow recommendation? True
01:09:48,114 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 2 retries took 0.87340157199651. input_tokens=288, output_tokens=124
01:09:48,811 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
01:09:48,813 graphrag.llm.base.rate_limiting_llm WARNING summarize failed to invoke LLM 4/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 3 seconds. Follow recommendation? True
01:09:49,327 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 0.5365003999322653. input_tokens=172, output_tokens=58
01:09:50,23 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
01:09:50,24 graphrag.llm.base.rate_limiting_llm WARNING summarize failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 2 seconds. Follow recommendation? True
01:09:50,537 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 1 retries took 0.7815757489297539. input_tokens=329, output_tokens=111
01:09:51,235 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
01:09:51,237 graphrag.llm.base.rate_limiting_llm WARNING summarize failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 1 seconds. Follow recommendation? True
01:09:52,581 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
01:09:53,228 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
01:09:53,493 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
01:09:53,496 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 6 retries took 0.5630462181288749. input_tokens=164, output_tokens=50
01:09:54,567 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
01:09:54,707 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 0.6987351789139211. input_tokens=175, output_tokens=59
01:09:56,13 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
01:09:56,14 graphrag.llm.base.rate_limiting_llm WARNING summarize failed to invoke LLM 7/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 4 seconds. Follow recommendation? True
01:09:56,54 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
01:09:56,623 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
01:09:56,625 graphrag.llm.base.rate_limiting_llm WARNING summarize failed to invoke LLM 4/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 3 seconds. Follow recommendation? True
01:09:57,232 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
01:09:57,233 graphrag.llm.base.rate_limiting_llm WARNING summarize failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 3 seconds. Follow recommendation? True
01:09:57,843 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
01:09:57,844 graphrag.llm.base.rate_limiting_llm WARNING summarize failed to invoke LLM 4/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 2 seconds. Follow recommendation? True
01:09:58,453 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
01:09:58,454 graphrag.llm.base.rate_limiting_llm WARNING summarize failed to invoke LLM 7/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 1 seconds. Follow recommendation? True
01:09:59,63 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
01:09:59,65 graphrag.llm.base.rate_limiting_llm WARNING summarize failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 1 seconds. Follow recommendation? True
01:10:00,12 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
01:10:00,189 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 0.7830081570427865. input_tokens=183, output_tokens=54
01:10:01,401 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 2 retries took 2.035330133046955. input_tokens=175, output_tokens=62
01:10:01,516 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
01:10:02,348 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
01:10:02,548 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 3 retries took 0.9412563308142126. input_tokens=181, output_tokens=75
01:10:03,691 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
01:10:03,693 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 0.5430274039972574. input_tokens=173, output_tokens=50
01:10:05,187 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
01:10:05,873 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
01:10:05,977 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
01:10:06,681 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
01:10:06,684 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 3 retries took 0.5597305598203093. input_tokens=182, output_tokens=48
01:10:07,887 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
01:10:07,890 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 0.6025958149693906. input_tokens=167, output_tokens=52
01:10:09,204 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
01:10:09,889 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
01:10:10,442 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
01:10:10,965 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
01:10:11,633 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
01:10:11,635 graphrag.llm.base.rate_limiting_llm WARNING summarize failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 21 seconds. Follow recommendation? True
01:10:11,799 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
01:10:12,147 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 6 retries took 0.8699145899154246. input_tokens=279, output_tokens=124
01:10:12,848 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
01:10:12,849 graphrag.llm.base.rate_limiting_llm WARNING summarize failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 20 seconds. Follow recommendation? True
01:10:13,359 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 6 retries took 0.907806945964694. input_tokens=176, output_tokens=71
01:10:14,56 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
01:10:14,58 graphrag.llm.base.rate_limiting_llm WARNING summarize failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 18 seconds. Follow recommendation? True
01:10:14,571 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 0.47154678916558623. input_tokens=168, output_tokens=52
01:10:15,268 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
01:10:15,269 graphrag.llm.base.rate_limiting_llm WARNING summarize failed to invoke LLM 2/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 17 seconds. Follow recommendation? True
01:10:15,880 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
01:10:15,881 graphrag.llm.base.rate_limiting_llm WARNING summarize failed to invoke LLM 2/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 16 seconds. Follow recommendation? True
01:10:16,488 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
01:10:16,489 graphrag.llm.base.rate_limiting_llm WARNING summarize failed to invoke LLM 2/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 16 seconds. Follow recommendation? True
01:10:17,3 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 0.747466053115204. input_tokens=172, output_tokens=70
01:10:17,698 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
01:10:17,700 graphrag.llm.base.rate_limiting_llm WARNING summarize failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 15 seconds. Follow recommendation? True
01:10:18,309 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
01:10:18,310 graphrag.llm.base.rate_limiting_llm WARNING summarize failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 14 seconds. Follow recommendation? True
01:10:18,824 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 0.647706720046699. input_tokens=176, output_tokens=57
01:10:19,520 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
01:10:19,521 graphrag.llm.base.rate_limiting_llm WARNING summarize failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 13 seconds. Follow recommendation? True
01:10:20,129 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
01:10:20,130 graphrag.llm.base.rate_limiting_llm WARNING summarize failed to invoke LLM 5/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 12 seconds. Follow recommendation? True
01:10:20,738 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
01:10:20,739 graphrag.llm.base.rate_limiting_llm WARNING summarize failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 12 seconds. Follow recommendation? True
01:10:21,252 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 0.4363215819466859. input_tokens=169, output_tokens=38
01:10:21,949 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
01:10:21,950 graphrag.llm.base.rate_limiting_llm WARNING summarize failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 10 seconds. Follow recommendation? True
01:10:22,559 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
01:10:22,561 graphrag.llm.base.rate_limiting_llm WARNING summarize failed to invoke LLM 5/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 10 seconds. Follow recommendation? True
01:10:23,169 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
01:10:23,171 graphrag.llm.base.rate_limiting_llm WARNING summarize failed to invoke LLM 2/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 9 seconds. Follow recommendation? True
01:10:23,684 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 0.7270654579624534. input_tokens=212, output_tokens=89
01:10:24,287 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 4 retries took 0.7160184741951525. input_tokens=179, output_tokens=69
01:10:24,987 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
01:10:24,988 graphrag.llm.base.rate_limiting_llm WARNING summarize failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 7 seconds. Follow recommendation? True
01:10:25,499 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 0.734066260047257. input_tokens=176, output_tokens=64
01:10:26,196 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
01:10:26,197 graphrag.llm.base.rate_limiting_llm WARNING summarize failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 6 seconds. Follow recommendation? True
01:10:26,804 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
01:10:26,806 graphrag.llm.base.rate_limiting_llm WARNING summarize failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 6 seconds. Follow recommendation? True
01:10:27,317 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 1 retries took 0.4093033990357071. input_tokens=155, output_tokens=18
01:10:28,13 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
01:10:28,15 graphrag.llm.base.rate_limiting_llm WARNING summarize failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 4 seconds. Follow recommendation? True
01:10:28,529 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 0.8927564769983292. input_tokens=211, output_tokens=90
01:10:29,224 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
01:10:29,226 graphrag.llm.base.rate_limiting_llm WARNING summarize failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 3 seconds. Follow recommendation? True
01:10:29,739 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 6 retries took 0.9695328909438103. input_tokens=197, output_tokens=89
01:10:30,437 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
01:10:30,438 graphrag.llm.base.rate_limiting_llm WARNING summarize failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 2 seconds. Follow recommendation? True
01:10:30,951 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 6 retries took 0.46459290804341435. input_tokens=166, output_tokens=25
01:10:31,649 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
01:10:31,651 graphrag.llm.base.rate_limiting_llm WARNING summarize failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 1 seconds. Follow recommendation? True
01:10:32,773 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 0.7907768099103123. input_tokens=171, output_tokens=68
01:10:32,964 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
01:10:33,668 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
01:10:34,347 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
01:10:35,92 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
01:10:35,473 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 1 retries took 0.5506599289365113. input_tokens=169, output_tokens=55
01:10:35,541 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
01:10:36,531 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
01:10:37,293 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 0.8736212768126279. input_tokens=220, output_tokens=105
01:10:37,474 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
01:10:38,505 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 7 retries took 0.8027447210624814. input_tokens=177, output_tokens=77
01:10:38,530 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
01:10:39,548 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
01:10:40,351 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
01:10:41,164 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
01:10:41,522 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
01:10:41,524 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 1 retries took 0.5833887869957834. input_tokens=169, output_tokens=60
01:10:42,772 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
01:10:43,377 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
01:10:43,949 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
01:10:43,952 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 1 retries took 0.6084151191171259. input_tokens=191, output_tokens=66
01:10:45,94 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
01:10:45,97 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 0.5424327910877764. input_tokens=170, output_tokens=60
01:10:46,345 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
01:10:47,361 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
01:10:48,74 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
01:10:48,76 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 1 retries took 1.768836960894987. input_tokens=174, output_tokens=54
01:10:48,402 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
01:10:49,248 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
01:10:49,381 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
01:10:49,383 graphrag.llm.base.rate_limiting_llm WARNING summarize failed to invoke LLM 2/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 3 seconds. Follow recommendation? True
01:10:49,990 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
01:10:49,992 graphrag.llm.base.rate_limiting_llm WARNING summarize failed to invoke LLM 2/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 2 seconds. Follow recommendation? True
01:10:50,506 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 1 retries took 0.6576507019344717. input_tokens=164, output_tokens=46
01:10:51,203 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
01:10:51,205 graphrag.llm.base.rate_limiting_llm WARNING summarize failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 1 seconds. Follow recommendation? True
01:10:52,423 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
01:10:52,425 graphrag.llm.base.rate_limiting_llm WARNING summarize failed to invoke LLM 2/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 1 seconds. Follow recommendation? True
01:10:52,513 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
01:10:53,630 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
01:10:54,245 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
01:10:54,699 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
01:10:54,701 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 2 retries took 0.544597270200029. input_tokens=167, output_tokens=39
01:10:55,864 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
01:10:55,912 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 0.7915619760751724. input_tokens=178, output_tokens=50
01:10:56,608 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
01:10:56,610 graphrag.llm.base.rate_limiting_llm WARNING summarize failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 4 seconds. Follow recommendation? True
01:10:57,218 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
01:10:57,219 graphrag.llm.base.rate_limiting_llm WARNING summarize failed to invoke LLM 3/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 3 seconds. Follow recommendation? True
01:10:57,733 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 2 retries took 0.6596139550674707. input_tokens=197, output_tokens=54
01:10:58,428 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
01:10:58,430 graphrag.llm.base.rate_limiting_llm WARNING summarize failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 2 seconds. Follow recommendation? True
01:10:58,945 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 0.45914839510805905. input_tokens=167, output_tokens=46
01:10:59,644 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
01:10:59,645 graphrag.llm.base.rate_limiting_llm WARNING summarize failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 1 seconds. Follow recommendation? True
01:11:00,157 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 7 retries took 0.7935462479945272. input_tokens=183, output_tokens=64
01:11:01,370 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 0.6348957009613514. input_tokens=166, output_tokens=41
01:11:01,420 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
01:11:02,582 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 0.44414086313918233. input_tokens=161, output_tokens=28
01:11:02,998 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
01:11:03,666 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
01:11:03,678 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 0.5636759859044105. input_tokens=165, output_tokens=49
01:11:04,890 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 1 retries took 0.6348861120641232. input_tokens=178, output_tokens=69
01:11:05,123 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
01:11:06,42 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
01:11:06,102 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 1 retries took 0.8397100809961557. input_tokens=169, output_tokens=46
01:11:07,120 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
01:11:07,755 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
01:11:08,534 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 0.6485102528240532. input_tokens=163, output_tokens=51
01:11:08,775 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
01:11:09,680 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 0.572769682155922. input_tokens=165, output_tokens=52
01:11:09,684 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
01:11:10,879 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 0.5907644471153617. input_tokens=192, output_tokens=49
01:11:11,83 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
01:11:12,73 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
01:11:12,91 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 1 retries took 0.6445815810002387. input_tokens=158, output_tokens=48
01:11:13,179 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
01:11:13,301 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 0.6498106690123677. input_tokens=176, output_tokens=62
01:11:14,512 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 0.5507849238347262. input_tokens=158, output_tokens=47
01:11:14,539 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
01:11:15,681 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 0.5937252228613943. input_tokens=162, output_tokens=49
01:11:15,754 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
01:11:16,378 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
01:11:16,380 graphrag.llm.base.rate_limiting_llm WARNING summarize failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 16 seconds. Follow recommendation? True
01:11:16,893 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 1 retries took 0.4461401680018753. input_tokens=164, output_tokens=35
01:11:17,598 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
01:11:17,599 graphrag.llm.base.rate_limiting_llm WARNING summarize failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 15 seconds. Follow recommendation? True
01:11:18,105 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 1 retries took 0.8771241239737719. input_tokens=214, output_tokens=104
01:11:18,802 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
01:11:18,803 graphrag.llm.base.rate_limiting_llm WARNING summarize failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 14 seconds. Follow recommendation? True
01:11:19,317 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 2 retries took 0.7965948698110878. input_tokens=167, output_tokens=80
01:11:20,13 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
01:11:20,15 graphrag.llm.base.rate_limiting_llm WARNING summarize failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 13 seconds. Follow recommendation? True
01:11:20,622 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
01:11:20,624 graphrag.llm.base.rate_limiting_llm WARNING summarize failed to invoke LLM 2/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 12 seconds. Follow recommendation? True
01:11:21,137 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 1 retries took 0.6942092350218445. input_tokens=155, output_tokens=53
01:11:21,836 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
01:11:21,838 graphrag.llm.base.rate_limiting_llm WARNING summarize failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 11 seconds. Follow recommendation? True
01:11:22,445 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
01:11:22,447 graphrag.llm.base.rate_limiting_llm WARNING summarize failed to invoke LLM 3/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 10 seconds. Follow recommendation? True
01:11:22,959 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 1 retries took 0.699783073971048. input_tokens=254, output_tokens=96
01:11:23,657 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
01:11:23,659 graphrag.llm.base.rate_limiting_llm WARNING summarize failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 9 seconds. Follow recommendation? True
01:11:24,268 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
01:11:24,269 graphrag.llm.base.rate_limiting_llm WARNING summarize failed to invoke LLM 3/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 8 seconds. Follow recommendation? True
01:11:24,879 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
01:11:24,880 graphrag.llm.base.rate_limiting_llm WARNING summarize failed to invoke LLM 3/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 8 seconds. Follow recommendation? True
01:11:25,393 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 0.6625302319880575. input_tokens=193, output_tokens=61
01:11:26,90 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
01:11:26,92 graphrag.llm.base.rate_limiting_llm WARNING summarize failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 7 seconds. Follow recommendation? True
01:11:26,700 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
01:11:26,702 graphrag.llm.base.rate_limiting_llm WARNING summarize failed to invoke LLM 2/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 6 seconds. Follow recommendation? True
01:11:27,215 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 0.6373731549829245. input_tokens=169, output_tokens=59
01:11:27,912 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
01:11:27,913 graphrag.llm.base.rate_limiting_llm WARNING summarize failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 5 seconds. Follow recommendation? True
01:11:28,426 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 0.6425064199138433. input_tokens=181, output_tokens=71
01:11:29,123 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
01:11:29,125 graphrag.llm.base.rate_limiting_llm WARNING summarize failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 4 seconds. Follow recommendation? True
01:11:29,483 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 0.5515275350771844. input_tokens=161, output_tokens=48
01:11:30,183 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
01:11:30,184 graphrag.llm.base.rate_limiting_llm WARNING summarize failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 3 seconds. Follow recommendation? True
01:11:30,800 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
01:11:30,801 graphrag.llm.base.rate_limiting_llm WARNING summarize failed to invoke LLM 2/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 2 seconds. Follow recommendation? True
01:11:31,410 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
01:11:31,411 graphrag.llm.base.rate_limiting_llm WARNING summarize failed to invoke LLM 2/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 1 seconds. Follow recommendation? True
01:11:31,923 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.0290411410387605. input_tokens=281, output_tokens=93
01:11:33,71 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
01:11:33,657 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
01:11:33,749 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 0.8453001000452787. input_tokens=269, output_tokens=98
01:11:35,566 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 0.4185700921807438. input_tokens=161, output_tokens=22
01:11:35,795 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
01:11:36,15 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
01:11:36,940 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
01:11:37,155 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
01:11:37,334 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 5 retries took 0.4435067989397794. input_tokens=176, output_tokens=43
01:11:38,395 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
01:11:38,546 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 5 retries took 0.8528091488406062. input_tokens=202, output_tokens=101
01:11:39,758 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 0.8047652980312705. input_tokens=194, output_tokens=67
01:11:39,823 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
01:11:40,933 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
01:11:40,936 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 0.5765751439612359. input_tokens=159, output_tokens=54
01:11:42,114 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
01:11:42,117 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 0.5792342009954154. input_tokens=165, output_tokens=49
01:11:43,285 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 0.5485731631051749. input_tokens=172, output_tokens=49
01:11:43,505 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
01:11:44,314 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
01:11:44,506 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 0.488984048133716. input_tokens=172, output_tokens=40
01:11:45,524 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
01:11:45,718 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 3 retries took 0.5249494849704206. input_tokens=173, output_tokens=60
01:11:46,814 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
01:11:47,380 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
01:11:48,56 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
01:11:48,923 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
01:11:49,711 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
01:11:50,454 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
01:11:51,75 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
01:11:51,83 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
01:11:51,297 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
01:11:51,298 graphrag.llm.base.rate_limiting_llm WARNING summarize failed to invoke LLM 2/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 1 seconds. Follow recommendation? True
01:11:52,517 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
01:11:52,518 graphrag.llm.base.rate_limiting_llm WARNING summarize failed to invoke LLM 3/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 1 seconds. Follow recommendation? True
01:11:52,746 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
01:11:52,887 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 1 retries took 2.3232675089966506. input_tokens=180, output_tokens=57
01:11:54,129 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
01:11:54,493 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
01:11:55,244 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
01:11:55,319 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 0.8410176050383598. input_tokens=176, output_tokens=57
01:11:56,529 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 1 retries took 1.6702968669123948. input_tokens=158, output_tokens=34
01:11:56,589 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
01:11:57,225 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
01:11:57,226 graphrag.llm.base.rate_limiting_llm WARNING summarize failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 4 seconds. Follow recommendation? True
01:11:57,688 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 2 retries took 0.48642918397672474. input_tokens=178, output_tokens=42
01:11:58,386 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
01:11:58,388 graphrag.llm.base.rate_limiting_llm WARNING summarize failed to invoke LLM 4/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 3 seconds. Follow recommendation? True
01:11:58,900 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 0.7744205959606916. input_tokens=186, output_tokens=72
01:11:59,596 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
01:11:59,598 graphrag.llm.base.rate_limiting_llm WARNING summarize failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 2 seconds. Follow recommendation? True
01:12:00,206 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
01:12:00,207 graphrag.llm.base.rate_limiting_llm WARNING summarize failed to invoke LLM 4/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 1 seconds. Follow recommendation? True
01:12:00,720 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 3 retries took 0.4324157170485705. input_tokens=163, output_tokens=32
01:12:01,780 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
01:12:01,932 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 0.4620340799447149. input_tokens=192, output_tokens=49
01:12:03,79 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
01:12:03,144 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 0.6768446380738169. input_tokens=208, output_tokens=84
01:12:04,256 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
01:12:04,354 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 0.7891531710047275. input_tokens=270, output_tokens=84
01:12:05,567 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 0.42380366614088416. input_tokens=156, output_tokens=23
01:12:06,179 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
01:12:06,780 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 0.4187250859104097. input_tokens=157, output_tokens=25
01:12:07,57 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
01:12:07,993 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.2236898220144212. input_tokens=234, output_tokens=101
01:12:08,96 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
01:12:08,595 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 0.49728994397446513. input_tokens=166, output_tokens=43
01:12:09,90 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 0.5477964039891958. input_tokens=158, output_tokens=54
01:12:09,692 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 1 retries took 0.47465211688540876. input_tokens=185, output_tokens=40
01:12:10,294 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 1 retries took 0.5166004179045558. input_tokens=156, output_tokens=24
01:12:11,505 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 1 retries took 0.45227027288638055. input_tokens=162, output_tokens=43
01:12:11,535 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
01:12:12,108 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 1 retries took 0.7732230159454048. input_tokens=198, output_tokens=76
01:12:12,709 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 1 retries took 0.34097218909300864. input_tokens=159, output_tokens=24
01:12:13,311 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 1 retries took 0.9372295588254929. input_tokens=190, output_tokens=93
01:12:13,912 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 2 retries took 0.6421444469597191. input_tokens=185, output_tokens=61
01:12:14,515 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 1 retries took 0.39725013985298574. input_tokens=187, output_tokens=38
01:12:15,550 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
01:12:15,726 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 2 retries took 0.5381035171449184. input_tokens=168, output_tokens=45
01:12:16,328 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 0.6708167351316661. input_tokens=172, output_tokens=52
01:12:17,540 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 0.46126879402436316. input_tokens=152, output_tokens=35
01:12:17,562 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
01:12:18,610 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
01:12:19,206 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
01:12:19,363 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 0.512394858058542. input_tokens=167, output_tokens=37
01:12:19,965 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 0.8900778130628169. input_tokens=163, output_tokens=46
01:12:20,566 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 0.716978101991117. input_tokens=189, output_tokens=74
01:12:21,167 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 0.6406186241656542. input_tokens=161, output_tokens=58
01:12:21,768 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 3 retries took 0.6336379209533334. input_tokens=158, output_tokens=52
01:12:23,511 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 2 retries took 0.4356803309638053. input_tokens=170, output_tokens=25
01:12:23,878 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
01:12:24,113 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 1 retries took 0.46974554006010294. input_tokens=182, output_tokens=32
01:12:24,714 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 1 retries took 0.45397232309915125. input_tokens=161, output_tokens=42
01:12:25,316 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 4 retries took 0.9790825140662491. input_tokens=165, output_tokens=54
01:12:28,128 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
01:12:28,131 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 4 retries took 5.838825689163059. input_tokens=235, output_tokens=80
01:12:28,183 graphrag.index.emit.parquet_table_emitter INFO emitting parquet table create_summarized_entities.parquet
01:12:28,479 graphrag.index.run.workflow INFO dependencies for create_base_entity_graph: ['create_summarized_entities']
01:12:28,480 graphrag.utils.storage INFO read table from storage: create_summarized_entities.parquet
01:12:28,503 datashaper.workflow.workflow INFO executing verb cluster_graph
01:12:28,717 datashaper.workflow.workflow INFO executing verb select
01:12:28,725 graphrag.index.emit.parquet_table_emitter INFO emitting parquet table create_base_entity_graph.parquet
01:12:28,964 graphrag.index.run.workflow INFO dependencies for create_final_entities: ['create_base_entity_graph']
01:12:28,965 graphrag.utils.storage INFO read table from storage: create_base_entity_graph.parquet
01:12:29,20 datashaper.workflow.workflow INFO executing verb unpack_graph
01:12:29,96 datashaper.workflow.workflow INFO executing verb rename
01:12:29,104 datashaper.workflow.workflow INFO executing verb select
01:12:29,112 datashaper.workflow.workflow INFO executing verb dedupe
01:12:29,120 datashaper.workflow.workflow INFO executing verb rename
01:12:29,128 datashaper.workflow.workflow INFO executing verb filter
01:12:29,152 datashaper.workflow.workflow INFO executing verb text_split
01:12:29,164 datashaper.workflow.workflow INFO executing verb drop
01:12:29,173 datashaper.workflow.workflow INFO executing verb merge
01:12:29,232 datashaper.workflow.workflow INFO executing verb text_embed
01:12:29,235 graphrag.llm.openai.create_openai_client INFO Creating Azure OpenAI client api_base=https://affine-project-us-east.openai.azure.com, deployment_name=text-embedding-3-small
01:12:29,243 graphrag.index.llm.load_llm INFO create TPM/RPM limiter for text-embedding-3-small: TPM=10000, RPM=50
01:12:29,243 graphrag.index.llm.load_llm INFO create concurrency limiter for text-embedding-3-small: 25
01:12:29,268 graphrag.index.verbs.text.embed.strategies.openai INFO embedding 346 inputs via 346 snippets using 22 batches. max_batch_size=16, max_tokens=8191
01:12:29,744 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2023-05-15 "HTTP/1.1 200 OK"
01:12:29,749 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2023-05-15 "HTTP/1.1 200 OK"
01:12:29,750 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2023-05-15 "HTTP/1.1 200 OK"
01:12:29,752 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2023-05-15 "HTTP/1.1 200 OK"
01:12:29,753 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2023-05-15 "HTTP/1.1 200 OK"
01:12:29,759 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2023-05-15 "HTTP/1.1 200 OK"
01:12:29,765 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2023-05-15 "HTTP/1.1 200 OK"
01:12:29,769 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2023-05-15 "HTTP/1.1 200 OK"
01:12:29,778 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2023-05-15 "HTTP/1.1 200 OK"
01:12:29,779 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2023-05-15 "HTTP/1.1 200 OK"
01:12:29,788 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2023-05-15 "HTTP/1.1 200 OK"
01:12:29,869 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2023-05-15 "HTTP/1.1 200 OK"
01:12:29,887 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2023-05-15 "HTTP/1.1 200 OK"
01:12:29,998 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.7169527930673212. input_tokens=827, output_tokens=0
01:12:30,21 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.7294547581113875. input_tokens=421, output_tokens=0
01:12:30,40 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.7500348561443388. input_tokens=400, output_tokens=0
01:12:30,59 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.769661032827571. input_tokens=809, output_tokens=0
01:12:30,78 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.7985203261487186. input_tokens=609, output_tokens=0
01:12:30,97 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.8147202930413187. input_tokens=1030, output_tokens=0
01:12:30,117 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.8284196308813989. input_tokens=1191, output_tokens=0
01:12:30,145 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.8608482729177922. input_tokens=754, output_tokens=0
01:12:30,165 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.874063465045765. input_tokens=937, output_tokens=0
01:12:30,184 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.898866114905104. input_tokens=768, output_tokens=0
01:12:30,206 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.9130711578764021. input_tokens=632, output_tokens=0
01:12:30,228 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.9407182009890676. input_tokens=1146, output_tokens=0
01:12:30,250 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.9666704458650202. input_tokens=395, output_tokens=0
01:12:31,17 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2023-05-15 "HTTP/1.1 200 OK"
01:12:31,105 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.22146667377091944. input_tokens=264, output_tokens=0
01:12:34,885 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2023-05-15 "HTTP/1.1 200 OK"
01:12:34,978 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.24234772799536586. input_tokens=641, output_tokens=0
01:12:38,47 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2023-05-15 "HTTP/1.1 200 OK"
01:12:38,136 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.23201498505659401. input_tokens=478, output_tokens=0
01:12:41,22 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2023-05-15 "HTTP/1.1 200 OK"
01:12:41,113 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.23842152510769665. input_tokens=482, output_tokens=0
01:12:44,237 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2023-05-15 "HTTP/1.1 200 OK"
01:12:44,328 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.24363753199577332. input_tokens=534, output_tokens=0
01:12:48,44 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2023-05-15 "HTTP/1.1 200 OK"
01:12:48,136 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.23432514094747603. input_tokens=775, output_tokens=0
01:12:52,674 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2023-05-15 "HTTP/1.1 200 OK"
01:12:52,763 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.23528392892330885. input_tokens=645, output_tokens=0
01:12:58,960 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2023-05-15 "HTTP/1.1 200 OK"
01:12:59,219 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.7008404550142586. input_tokens=997, output_tokens=0
01:13:03,37 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2023-05-15 "HTTP/1.1 200 OK"
01:13:03,128 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.250254058977589. input_tokens=725, output_tokens=0
01:13:03,178 datashaper.workflow.workflow INFO executing verb drop
01:13:03,188 datashaper.workflow.workflow INFO executing verb filter
01:13:03,212 graphrag.index.emit.parquet_table_emitter INFO emitting parquet table create_final_entities.parquet
01:13:03,550 graphrag.index.run.workflow INFO dependencies for create_final_nodes: ['create_base_entity_graph']
01:13:03,552 graphrag.utils.storage INFO read table from storage: create_base_entity_graph.parquet
01:13:03,590 datashaper.workflow.workflow INFO executing verb layout_graph
01:13:03,860 datashaper.workflow.workflow INFO executing verb unpack_graph
01:13:03,951 datashaper.workflow.workflow INFO executing verb unpack_graph
01:13:04,42 datashaper.workflow.workflow INFO executing verb drop
01:13:04,54 datashaper.workflow.workflow INFO executing verb filter
01:13:04,91 datashaper.workflow.workflow INFO executing verb select
01:13:04,103 datashaper.workflow.workflow INFO executing verb rename
01:13:04,114 datashaper.workflow.workflow INFO executing verb join
01:13:04,135 datashaper.workflow.workflow INFO executing verb convert
01:13:04,173 datashaper.workflow.workflow INFO executing verb rename
01:13:04,209 graphrag.index.emit.parquet_table_emitter INFO emitting parquet table create_final_nodes.parquet
01:13:04,479 graphrag.index.run.workflow INFO dependencies for create_final_communities: ['create_base_entity_graph']
01:13:04,491 graphrag.utils.storage INFO read table from storage: create_base_entity_graph.parquet
01:13:04,545 datashaper.workflow.workflow INFO executing verb create_final_communities
01:13:04,733 graphrag.index.emit.parquet_table_emitter INFO emitting parquet table create_final_communities.parquet
01:13:04,992 graphrag.index.run.workflow INFO dependencies for create_final_relationships: ['create_final_nodes', 'create_base_entity_graph']
01:13:04,993 graphrag.utils.storage INFO read table from storage: create_final_nodes.parquet
01:13:05,16 graphrag.utils.storage INFO read table from storage: create_base_entity_graph.parquet
01:13:05,63 datashaper.workflow.workflow INFO executing verb create_final_relationships_pre_embedding
01:13:05,155 datashaper.workflow.workflow INFO executing verb create_final_relationships_post_embedding
01:13:05,168 graphrag.index.emit.parquet_table_emitter INFO emitting parquet table create_final_relationships.parquet
01:13:05,405 graphrag.index.run.workflow INFO dependencies for create_final_text_units: ['create_base_text_units', 'create_final_entities', 'create_final_relationships']
01:13:05,406 graphrag.utils.storage INFO read table from storage: create_base_text_units.parquet
01:13:05,420 graphrag.utils.storage INFO read table from storage: create_final_entities.parquet
01:13:05,484 graphrag.utils.storage INFO read table from storage: create_final_relationships.parquet
01:13:05,558 datashaper.workflow.workflow INFO executing verb create_final_text_units_pre_embedding
01:13:05,589 datashaper.workflow.workflow INFO executing verb select
01:13:05,595 graphrag.index.emit.parquet_table_emitter INFO emitting parquet table create_final_text_units.parquet
01:13:05,855 graphrag.index.run.workflow INFO dependencies for create_final_community_reports: ['create_final_nodes', 'create_final_relationships']
01:13:05,856 graphrag.utils.storage INFO read table from storage: create_final_nodes.parquet
01:13:05,870 graphrag.utils.storage INFO read table from storage: create_final_relationships.parquet
01:13:05,909 datashaper.workflow.workflow INFO executing verb prepare_community_reports_nodes
01:13:05,934 datashaper.workflow.workflow INFO executing verb prepare_community_reports_edges
01:13:05,955 datashaper.workflow.workflow INFO executing verb restore_community_hierarchy
01:13:05,977 datashaper.workflow.workflow INFO executing verb prepare_community_reports
01:13:05,978 graphrag.index.verbs.graph.report.prepare_community_reports INFO Number of nodes at level=2 => 346
01:13:06,12 graphrag.index.verbs.graph.report.prepare_community_reports INFO Number of nodes at level=1 => 346
01:13:06,136 graphrag.index.verbs.graph.report.prepare_community_reports INFO Number of nodes at level=0 => 346
01:13:06,225 datashaper.workflow.workflow INFO executing verb create_community_reports
01:13:10,246 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
01:13:10,250 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 4.010345812188461. input_tokens=2020, output_tokens=540
01:13:11,963 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
01:13:11,967 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 5.71560088195838. input_tokens=2796, output_tokens=674
01:13:12,482 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
01:13:12,486 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 6.2283396071288735. input_tokens=4832, output_tokens=901
01:13:13,325 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
01:13:13,329 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 7.081755738938227. input_tokens=6262, output_tokens=802
01:13:14,752 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
01:13:14,754 graphrag.llm.base.rate_limiting_llm WARNING create_community_report failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 52 seconds. Follow recommendation? True
01:13:21,146 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
01:13:21,147 graphrag.llm.base.rate_limiting_llm WARNING create_community_report failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 3 seconds. Follow recommendation? True
01:13:29,460 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
01:13:29,464 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 1 retries took 3.9037529670167714. input_tokens=2073, output_tokens=544
01:13:33,423 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
01:13:33,424 graphrag.llm.base.rate_limiting_llm WARNING create_community_report failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 34 seconds. Follow recommendation? True
01:13:40,247 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
01:13:40,248 graphrag.llm.base.rate_limiting_llm WARNING create_community_report failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 27 seconds. Follow recommendation? True
01:13:47,373 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
01:13:47,375 graphrag.llm.base.rate_limiting_llm WARNING create_community_report failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 20 seconds. Follow recommendation? True
01:13:54,74 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
01:13:54,76 graphrag.llm.base.rate_limiting_llm WARNING create_community_report failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 13 seconds. Follow recommendation? True
01:14:00,867 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
01:14:00,868 graphrag.llm.base.rate_limiting_llm WARNING create_community_report failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 6 seconds. Follow recommendation? True
01:14:12,806 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
01:14:12,812 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 1 retries took 4.67328594205901. input_tokens=2188, output_tokens=700
01:14:20,527 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
01:14:20,531 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 1 retries took 5.408021193929017. input_tokens=2173, output_tokens=680
01:14:28,735 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
01:14:28,740 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 4.17450101999566. input_tokens=2333, output_tokens=664
01:14:37,539 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
01:14:37,544 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 3.802332989871502. input_tokens=2399, output_tokens=567
01:14:44,550 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
01:14:44,554 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 1 retries took 3.8653463090304285. input_tokens=2087, output_tokens=625
01:14:53,238 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
01:14:53,242 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 3.98596596904099. input_tokens=2254, output_tokens=628
01:15:00,147 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
01:15:00,149 graphrag.llm.base.rate_limiting_llm WARNING create_community_report failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 9 seconds. Follow recommendation? True
01:15:06,507 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
01:15:06,509 graphrag.llm.base.rate_limiting_llm WARNING create_community_report failed to invoke LLM 2/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 3 seconds. Follow recommendation? True
01:15:18,402 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
01:15:18,407 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 6.389193524140865. input_tokens=2447, output_tokens=699
01:15:23,820 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
01:15:23,824 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 1 retries took 3.042872428195551. input_tokens=2164, output_tokens=539
01:15:33,464 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
01:15:33,468 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 4.289857775904238. input_tokens=2243, output_tokens=689
01:15:43,82 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
01:15:43,86 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 2 retries took 5.373612952185795. input_tokens=2108, output_tokens=601
01:15:50,570 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
01:15:50,590 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 1 retries took 4.355135543039069. input_tokens=2338, output_tokens=695
01:16:00,362 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
01:16:00,366 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 4.070211278041825. input_tokens=2246, output_tokens=645
01:16:06,752 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
01:16:06,754 graphrag.llm.base.rate_limiting_llm WARNING create_community_report failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 6 seconds. Follow recommendation? True
01:16:21,417 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
01:16:21,422 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 5.17997149983421. input_tokens=3364, output_tokens=790
01:16:34,766 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
01:16:34,771 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 6.022178994957358. input_tokens=2814, output_tokens=656
01:16:43,16 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
01:16:43,20 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 4.873206197982654. input_tokens=2827, output_tokens=777
01:16:55,292 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
01:16:55,297 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 4.792167773935944. input_tokens=3129, output_tokens=723
01:17:08,631 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
01:17:08,635 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 1 retries took 6.661234081955627. input_tokens=3180, output_tokens=794
01:17:15,123 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
01:17:15,124 graphrag.llm.base.rate_limiting_llm WARNING create_community_report failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 2 seconds. Follow recommendation? True
01:17:33,153 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
01:17:33,158 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 1 retries took 4.594650459010154. input_tokens=3201, output_tokens=692
01:17:45,324 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
01:17:45,328 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 6.45891424594447. input_tokens=3388, output_tokens=787
01:17:57,74 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
01:17:57,78 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 1 retries took 4.845049815019593. input_tokens=3388, output_tokens=703
01:18:13,462 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
01:18:13,466 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 5.71135589806363. input_tokens=5429, output_tokens=800
01:18:41,824 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
01:18:41,828 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 4.604361611884087. input_tokens=6326, output_tokens=738
01:19:17,755 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
01:19:17,760 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 8.188135492848232. input_tokens=9237, output_tokens=980
01:19:54,90 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
01:19:54,97 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 6.688337716041133. input_tokens=9879, output_tokens=968
01:19:54,674 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
01:19:54,676 graphrag.llm.base.rate_limiting_llm WARNING create_community_report failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 16 seconds. Follow recommendation? True
01:19:59,583 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
01:19:59,587 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 5.3781429240480065. input_tokens=2226, output_tokens=692
01:20:00,63 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
01:20:00,68 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 5.849087245995179. input_tokens=2370, output_tokens=715
01:20:11,91 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
01:20:11,96 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 4.287405050126836. input_tokens=2096, output_tokens=593
01:20:16,518 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
01:20:16,521 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 3.1959628218319267. input_tokens=2122, output_tokens=500
01:20:28,346 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
01:20:28,348 graphrag.llm.base.rate_limiting_llm WARNING create_community_report failed to invoke LLM 2/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 20 seconds. Follow recommendation? True
01:20:37,421 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 429 Too Many Requests"
01:20:37,422 graphrag.llm.base.rate_limiting_llm WARNING create_community_report failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 11 seconds. Follow recommendation? True
01:20:55,683 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
01:20:55,688 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 1 retries took 5.995753918075934. input_tokens=2849, output_tokens=730
01:20:55,779 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
01:20:55,784 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 2 retries took 5.005732724908739. input_tokens=2569, output_tokens=762
01:21:26,826 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
01:21:26,831 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 6.4189084731042385. input_tokens=5744, output_tokens=1009
01:21:47,607 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
01:21:47,612 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 5.929370200028643. input_tokens=5968, output_tokens=978
01:22:11,197 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
01:22:11,202 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 5.626224830979481. input_tokens=7295, output_tokens=824
01:22:46,156 httpx INFO HTTP Request: POST https://affine-project-us-east.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2023-03-15-preview "HTTP/1.1 200 OK"
01:22:46,161 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 6.600485113915056. input_tokens=9442, output_tokens=972
01:22:46,218 datashaper.workflow.workflow INFO executing verb window
01:22:46,227 graphrag.index.emit.parquet_table_emitter INFO emitting parquet table create_final_community_reports.parquet
01:22:46,587 graphrag.index.run.workflow INFO dependencies for create_base_documents: ['create_final_text_units']
01:22:46,589 graphrag.utils.storage INFO read table from storage: create_final_text_units.parquet
01:22:46,683 datashaper.workflow.workflow INFO executing verb unroll
01:22:46,706 datashaper.workflow.workflow INFO executing verb select
01:22:46,722 datashaper.workflow.workflow INFO executing verb rename
01:22:46,739 datashaper.workflow.workflow INFO executing verb join
01:22:46,761 datashaper.workflow.workflow INFO executing verb aggregate_override
01:22:46,780 datashaper.workflow.workflow INFO executing verb join
01:22:46,835 datashaper.workflow.workflow INFO executing verb rename
01:22:46,853 datashaper.workflow.workflow INFO executing verb convert
01:22:46,904 graphrag.index.emit.parquet_table_emitter INFO emitting parquet table create_base_documents.parquet
01:22:47,154 graphrag.index.run.workflow INFO dependencies for create_final_documents: ['create_base_documents']
01:22:47,155 graphrag.utils.storage INFO read table from storage: create_base_documents.parquet
01:22:47,209 datashaper.workflow.workflow INFO executing verb rename
01:22:47,223 graphrag.index.emit.parquet_table_emitter INFO emitting parquet table create_final_documents.parquet
01:22:47,330 graphrag.index.cli INFO All workflows completed successfully.
